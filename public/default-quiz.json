{
  "name": "Algorithms and Data Structures MCQ Review",
  "description": "A comprehensive set of MCQs covering core concepts in algorithms, complexity, sorting, formal languages, and computability, designed for deep understanding and exam preparation.",
  "chapters": [
    {
      "id": "ch_fundamentals_1",
      "name": "Chapter 1: Fundamentals of Algorithms & Complexity",
      "description": "Focuses on the definition of algorithms, their properties, methods of description, and basic concepts of computational complexity.",
      "questions": [
        {
          "questionId": "ch_fundamentals_1_q1",
          "questionText": "Among the classical properties of an algorithm (e.g., by Knuth or Markov), which property specifically ensures that an algorithm must always terminate after a finite number of steps?",
          "options": [
            {
              "optionId": "ch_fundamentals_1_q1_opt1",
              "optionText": "**Finiteness**: An algorithm must always terminate after a finite number of steps."
            },
            {
              "optionId": "ch_fundamentals_1_q1_opt2",
              "optionText": "**Definiteness**: Each step must be precisely defined."
            },
            {
              "optionId": "ch_fundamentals_1_q1_opt3",
              "optionText": "**Input**: An algorithm has zero or more quantities that are externally supplied."
            },
            {
              "optionId": "ch_fundamentals_1_q1_opt4",
              "optionText": "**Output**: An algorithm has at least one quantity that is produced."
            },
            {
              "optionId": "ch_fundamentals_1_q1_opt5",
              "optionText": "**Effectiveness**: All operations must be sufficiently basic to be done exactly."
            },
            {
              "optionId": "ch_fundamentals_1_q1_opt6",
              "optionText": "**Optimality**: An algorithm must always provide the most efficient solution."
            },
            {
              "optionId": "ch_fundamentals_1_q1_opt7",
              "optionText": "**Clarity**: The algorithm should be easy to understand."
            },
            {
              "optionId": "ch_fundamentals_1_q1_opt8",
              "optionText": "**Generality**: The algorithm should apply to a broad range of inputs."
            },
            {
              "optionId": "ch_fundamentals_1_q1_opt9",
              "optionText": "**Determinism**: For a given input, an algorithm must always produce the same output (excluding randomized algorithms)."
            },
            {
              "optionId": "ch_fundamentals_1_q1_opt10",
              "optionText": "**Correctness**: The algorithm must produce the correct output for all valid inputs."
            }
          ],
          "correctOptionIds": ["ch_fundamentals_1_q1_opt1"],
          "explanationText": "The property that ensures an algorithm must always terminate after a finite number of steps is **Finiteness**. While Definiteness (unambiguous steps) and Effectiveness (basic, executable operations) are also foundational properties, Finiteness specifically addresses the termination requirement. Input and Output define its interface, and Optimality, Clarity, Generality, Determinism, and Correctness are other important characteristics or goals but not the one specifically about termination.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_fundamentals_1_q2",
          "questionText": "When describing algorithms, `pseudocode` is often preferred over a specific programming language. Which statement _best encapsulates the primary benefit_ of using pseudocode for algorithm description?",
          "options": [
            {
              "optionId": "ch_fundamentals_1_q2_opt1",
              "optionText": "It abstracts away from specific programming language syntax, focusing on logic."
            },
            {
              "optionId": "ch_fundamentals_1_q2_opt2",
              "optionText": "It is easier for a wider audience (including those not proficient in a particular language) to understand."
            },
            {
              "optionId": "ch_fundamentals_1_q2_opt3",
              "optionText": "It can be directly compiled and executed by any computer."
            },
            {
              "optionId": "ch_fundamentals_1_q2_opt4",
              "optionText": "It enforces strict type checking, reducing logical errors during design."
            },
            {
              "optionId": "ch_fundamentals_1_q2_opt5",
              "optionText": "It typically has less syntactic noise than full programming languages."
            },
            {
              "optionId": "ch_fundamentals_1_q2_opt6",
              "optionText": "It always results in the most time-efficient algorithm design."
            },
            {
              "optionId": "ch_fundamentals_1_q2_opt7",
              "optionText": "It automatically generates test cases for the algorithm."
            },
            {
              "optionId": "ch_fundamentals_1_q2_opt8",
              "optionText": "It is formally defined by an international standards body, ensuring consistency."
            },
            {
              "optionId": "ch_fundamentals_1_q2_opt9",
              "optionText": "It forces the use of object-oriented principles."
            },
            {
              "optionId": "ch_fundamentals_1_q2_opt10",
              "optionText": "It is primarily used for describing hardware designs, not software."
            }
          ],
          "correctOptionIds": ["ch_fundamentals_1_q2_opt1"],
          "explanationText": "The primary benefit of pseudocode is that **it abstracts away from specific programming language syntax, allowing the description to focus purely on the algorithm's logic**. This abstraction directly contributes to its other advantages, such as being easier for a wider audience (including those not proficient in a particular programming language) to understand and typically having less syntactic noise. Pseudocode is not directly compilable and does not enforce strict type checking like a programming language.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_fundamentals_1_q3",
          "questionText": "What does the term **time complexity** of an algorithm primarily refer to? What is the _most fundamental characteristic_ that time complexity analysis aims to capture?",
          "options": [
            {
              "optionId": "ch_fundamentals_1_q3_opt1",
              "optionText": "The actual wall-clock time (e.g., in seconds) it takes for the algorithm to run on a specific computer."
            },
            {
              "optionId": "ch_fundamentals_1_q3_opt2",
              "optionText": "How the number of fundamental operations performed by the algorithm grows as the size of the input increases."
            },
            {
              "optionId": "ch_fundamentals_1_q3_opt3",
              "optionText": "The amount of memory (RAM) the algorithm uses during its execution."
            },
            {
              "optionId": "ch_fundamentals_1_q3_opt4",
              "optionText": "The number of lines of code in the algorithm's implementation."
            },
            {
              "optionId": "ch_fundamentals_1_q3_opt5",
              "optionText": "The complexity of understanding the algorithm's logic."
            },
            {
              "optionId": "ch_fundamentals_1_q3_opt6",
              "optionText": "The speed of the processor on which the algorithm is run."
            },
            {
              "optionId": "ch_fundamentals_1_q3_opt7",
              "optionText": "A measure of how difficult it is to program the algorithm."
            },
            {
              "optionId": "ch_fundamentals_1_q3_opt8",
              "optionText": "The best-case execution time of the algorithm for the smallest possible input."
            },
            {
              "optionId": "ch_fundamentals_1_q3_opt9",
              "optionText": "A machine-independent measure of the algorithm's efficiency in terms of execution steps relative to input size."
            },
            {
              "optionId": "ch_fundamentals_1_q3_opt10",
              "optionText": "The maximum possible input size the algorithm can handle."
            }
          ],
          "correctOptionIds": ["ch_fundamentals_1_q3_opt2"],
          "explanationText": "Time complexity primarily refers to **how the number of fundamental operations performed by the algorithm grows as the size of the input increases**. This focus on growth relative to input size allows for a machine-independent measure of an algorithm's efficiency (as described by the concept of being a 'machine-independent measure'), abstracting away from specific hardware or exact clock times. It's distinct from space complexity (memory usage) or lines of code.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_fundamentals_1_q4",
          "questionText": "When analyzing algorithms, why is the **worst-case complexity** _often the most crucial consideration_?",
          "options": [
            {
              "optionId": "ch_fundamentals_1_q4_opt1",
              "optionText": "It provides an upper bound on the algorithm's running time, guaranteeing performance will not be worse."
            },
            {
              "optionId": "ch_fundamentals_1_q4_opt2",
              "optionText": "The worst-case scenario occurs most frequently in real-world applications."
            },
            {
              "optionId": "ch_fundamentals_1_q4_opt3",
              "optionText": "Average-case complexity is often much harder to determine mathematically."
            },
            {
              "optionId": "ch_fundamentals_1_q4_opt4",
              "optionText": "Best-case complexity is not useful as it rarely happens."
            },
            {
              "optionId": "ch_fundamentals_1_q4_opt5",
              "optionText": "It is generally analyzed as a function of input size, abstracting from specific data values."
            },
            {
              "optionId": "ch_fundamentals_1_q4_opt6",
              "optionText": "It simplifies the analysis by allowing us to ignore constant factors."
            },
            {
              "optionId": "ch_fundamentals_1_q4_opt7",
              "optionText": "For many algorithms, the average case is often close to the worst case."
            },
            {
              "optionId": "ch_fundamentals_1_q4_opt8",
              "optionText": "It's easier to find test data that triggers worst-case behavior for debugging."
            },
            {
              "optionId": "ch_fundamentals_1_q4_opt9",
              "optionText": "Regulatory compliance in some fields requires guarantees based on worst-case performance."
            },
            {
              "optionId": "ch_fundamentals_1_q4_opt10",
              "optionText": "Worst-case complexity is always a polynomial function."
            }
          ],
          "correctOptionIds": ["ch_fundamentals_1_q4_opt1"],
          "explanationText": "The primary reason for focusing on worst-case complexity is that **it provides an upper bound on the algorithm's running time, guaranteeing performance will not be worse**. This guarantee is critical for many applications, especially real-time systems or those requiring predictable performance. While it's also true that average-case analysis can be much harder (as mentioned in one of the options) and that for some algorithms the average case is often close to the worst case, the performance guarantee is the most fundamental advantage. The option stating it's 'analyzed as a function of input size, abstracting from specific data values' describes a general aspect of complexity analysis, not unique to worst-case being crucial. Worst-case complexity is not always polynomial (e.g., it can be $O(2^n)$).",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_fundamentals_1_q5",
          "questionText": "Consider the following pseudocode to find the sum of an array $a$ of $n$ numbers:\n```pseudocode\ntotal ← 0\ni ← 0\nWHILE i < n\n  total ← total + a[i]\n  i ← i + 1\nRETURN total\n```\nWhen tracing this algorithm for an array like $a = [6, 9, 3]$ (so $n=3$), which statement _most accurately describes the state change after the very first complete pass_ through the loop body?",
          "options": [
            {
              "optionId": "ch_fundamentals_1_q5_opt1",
              "optionText": "The variable $i$ will take values 0, 1, 2, 3."
            },
            {
              "optionId": "ch_fundamentals_1_q5_opt2",
              "optionText": "The variable $total$ will be 0, 6, 15, 18 at the top of each loop iteration (including before the first)."
            },
            {
              "optionId": "ch_fundamentals_1_q5_opt3",
              "optionText": "The loop `WHILE i < n` executes exactly $n$ times."
            },
            {
              "optionId": "ch_fundamentals_1_q5_opt4",
              "optionText": "The value of $total$ before the first loop iteration is undefined."
            },
            {
              "optionId": "ch_fundamentals_1_q5_opt5",
              "optionText": "After the first iteration ($i=0$), $total$ is 6 and $i$ becomes 1."
            },
            {
              "optionId": "ch_fundamentals_1_q5_opt6",
              "optionText": "The algorithm returns the value of the last element, $a[n-1]$."
            },
            {
              "optionId": "ch_fundamentals_1_q5_opt7",
              "optionText": "The condition $i < n$ becomes false when $i$ equals $n$."
            },
            {
              "optionId": "ch_fundamentals_1_q5_opt8",
              "optionText": "The array $a$ is modified during the execution of this algorithm."
            },
            {
              "optionId": "ch_fundamentals_1_q5_opt9",
              "optionText": "At the top of the loop when $i=2$, $total$ holds the sum $a[0]+a[1]$."
            },
            {
              "optionId": "ch_fundamentals_1_q5_opt10",
              "optionText": "The final value returned for $a = [6, 9, 3]$ is 18."
            }
          ],
          "correctOptionIds": ["ch_fundamentals_1_q5_opt5"],
          "explanationText": "When tracing the algorithm with $a = [6, 9, 3]$: Initially, $total = 0$ and $i = 0$. In the first loop iteration (when $i$ is 0): $total$ becomes $0 + a[0]$ which is $0 + 6 = 6$. Then $i$ becomes $0 + 1 = 1$. Thus, **after the first iteration, $total$ is 6 and $i$ becomes 1**. The loop executes $n$ times in total, and for this specific input, the final returned value is 18.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null,
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": []
        },
        {
          "questionId": "ch_fundamentals_1_q6",
          "questionText": "What is **space complexity** primarily concerned with in the analysis of algorithms?",
          "options": [
            {
              "optionId": "ch_fundamentals_1_q6_opt1",
              "optionText": "The total amount of disk space required to store the algorithm's source code."
            },
            {
              "optionId": "ch_fundamentals_1_q6_opt2",
              "optionText": "The amount of memory used by the input data itself."
            },
            {
              "optionId": "ch_fundamentals_1_q6_opt3",
              "optionText": "The amount of **additional** memory (auxiliary space) an algorithm uses, apart from the space occupied by the input, as a function of input size."
            },
            {
              "optionId": "ch_fundamentals_1_q6_opt4",
              "optionText": "The number of variables declared in the algorithm."
            },
            {
              "optionId": "ch_fundamentals_1_q6_opt5",
              "optionText": "The physical size of the computer needed to run the algorithm."
            },
            {
              "optionId": "ch_fundamentals_1_q6_opt6",
              "optionText": "The growth of the call stack depth for recursive algorithms as a function of input size."
            },
            {
              "optionId": "ch_fundamentals_1_q6_opt7",
              "optionText": "The time it takes to allocate memory for the algorithm."
            },
            {
              "optionId": "ch_fundamentals_1_q6_opt8",
              "optionText": "The sum of memory for input and auxiliary space."
            },
            {
              "optionId": "ch_fundamentals_1_q6_opt9",
              "optionText": "How efficiently the algorithm uses CPU cache memory."
            },
            {
              "optionId": "ch_fundamentals_1_q6_opt10",
              "optionText": "The complexity of the data structures used by the algorithm."
            }
          ],
          "correctOptionIds": ["ch_fundamentals_1_q6_opt3"],
          "explanationText": "Space complexity is primarily concerned with **the amount of additional memory (auxiliary space) an algorithm uses, apart from the space occupied by the input itself, as this auxiliary space requirement grows with the input size**. For recursive algorithms, the space used by the call stack (due to recursive calls storing activation records) is a significant component of this auxiliary space. It's distinct from the memory for source code or input data alone.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_fundamentals_1_q7",
          "questionText": "Which of the following is an example of a common problem type encountered in the study of algorithms? (Select any one of the fundamental problem types.)",
          "options": [
            {
              "optionId": "ch_fundamentals_1_q7_opt1",
              "optionText": "**Decision Problems**: Problems that require a yes/no answer."
            },
            {
              "optionId": "ch_fundamentals_1_q7_opt2",
              "optionText": "**Search Problems**: Problems that require finding a solution that satisfies certain criteria, if one exists."
            },
            {
              "optionId": "ch_fundamentals_1_q7_opt3",
              "optionText": "**Optimization Problems**: Problems that require finding the best solution among all possible solutions, according to some objective function."
            },
            {
              "optionId": "ch_fundamentals_1_q7_opt4",
              "optionText": "**Compilation Problems**: Problems related to translating source code into machine code."
            },
            {
              "optionId": "ch_fundamentals_1_q7_opt5",
              "optionText": "**Debugging Problems**: Problems related to finding and fixing errors in code."
            },
            {
              "optionId": "ch_fundamentals_1_q7_opt6",
              "optionText": "**Philosophical Problems**: Problems concerning the nature of computation itself."
            },
            {
              "optionId": "ch_fundamentals_1_q7_opt7",
              "optionText": "**User Interface Problems**: Problems related to designing effective user interactions."
            },
            {
              "optionId": "ch_fundamentals_1_q7_opt8",
              "optionText": "**Hardware Design Problems**: Problems related to the physical construction of computer components."
            },
            {
              "optionId": "ch_fundamentals_1_q7_opt9",
              "optionText": "**Network Routing Problems**: A specific type of optimization or search problem."
            },
            {
              "optionId": "ch_fundamentals_1_q7_opt10",
              "optionText": "**Natural Language Processing Problems**: A broad area that includes various decision, search, and optimization sub-problems."
            }
          ],
          "correctOptionIds": [
            "ch_fundamentals_1_q7_opt1",
            "ch_fundamentals_1_q7_opt2",
            "ch_fundamentals_1_q7_opt3"
          ],
          "explanationText": "The fundamental types of computational problems often categorized are **Decision Problems** (e.g., 'Does a path exist?'), **Search Problems** (e.g., 'Find a path if one exists.'), and **Optimization Problems** (e.g., 'Find the shortest path.'). Selecting any one of these identifies a common problem type. While areas like compilation, debugging, UI, hardware, networking, and NLP involve algorithms, they are application domains or process types rather than the primary abstract classifications of computational problems themselves based on their output requirements. Network routing can be an optimization problem, and NLP involves many types of problems.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_fundamentals_1_q8",
          "questionText": "The 'effectiveness' property of an algorithm, as described by Knuth, means that all operations must be sufficiently basic to be practically executable. Which statement _best illustrates_ this concept?",
          "options": [
            {
              "optionId": "ch_fundamentals_1_q8_opt1",
              "optionText": "The algorithm must solve the problem correctly for all valid inputs."
            },
            {
              "optionId": "ch_fundamentals_1_q8_opt2",
              "optionText": "The algorithm must be the most efficient one possible for the given problem."
            },
            {
              "optionId": "ch_fundamentals_1_q8_opt3",
              "optionText": "Each step of the algorithm must be sufficiently basic and feasible to be carried out in practice."
            },
            {
              "optionId": "ch_fundamentals_1_q8_opt4",
              "optionText": "The algorithm must terminate within a reasonable amount of time."
            },
            {
              "optionId": "ch_fundamentals_1_q8_opt5",
              "optionText": "The algorithm should be easy to understand and implement."
            },
            {
              "optionId": "ch_fundamentals_1_q8_opt6",
              "optionText": "The operations are so clear they could, in principle, be done by a human with pencil and paper in finite time."
            },
            {
              "optionId": "ch_fundamentals_1_q8_opt7",
              "optionText": "The algorithm effectively uses all available system resources."
            },
            {
              "optionId": "ch_fundamentals_1_q8_opt8",
              "optionText": "The algorithm effectively communicates its results to the user."
            },
            {
              "optionId": "ch_fundamentals_1_q8_opt9",
              "optionText": "The algorithm can handle an effective range of input sizes."
            },
            {
              "optionId": "ch_fundamentals_1_q8_opt10",
              "optionText": "The algorithm must be written in an effective programming language."
            }
          ],
          "correctOptionIds": ["ch_fundamentals_1_q8_opt6"],
          "explanationText": "The 'effectiveness' property means each step of an algorithm must be sufficiently basic and feasible to be carried out in practice. The statement that **the operations are so clear they could, in principle, be done by a human with pencil and paper in finite time** best illustrates this. It emphasizes that each operation must be primitive and executable, distinguishing it from correctness (a separate goal), efficiency, or termination time (which is the Finiteness property).",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_fundamentals_1_q9",
          "questionText": "When evaluating an algorithm's efficiency, which primary dimension specifically refers to how fast the algorithm runs, typically measured by its growth rate of operations relative to input size?",
          "options": [
            {
              "optionId": "ch_fundamentals_1_q9_opt1",
              "optionText": "**Time efficiency**"
            },
            {
              "optionId": "ch_fundamentals_1_q9_opt2",
              "optionText": "**Space efficiency**"
            },
            {
              "optionId": "ch_fundamentals_1_q9_opt3",
              "optionText": "**Simplicity**"
            },
            {
              "optionId": "ch_fundamentals_1_q9_opt4",
              "optionText": "**Correctness**"
            },
            {
              "optionId": "ch_fundamentals_1_q9_opt5",
              "optionText": "**Scalability**"
            },
            {
              "optionId": "ch_fundamentals_1_q9_opt6",
              "optionText": "**Robustness**"
            },
            {
              "optionId": "ch_fundamentals_1_q9_opt7",
              "optionText": "**Energy efficiency**"
            },
            {
              "optionId": "ch_fundamentals_1_q9_opt8",
              "optionText": "**Maintainability**"
            },
            {
              "optionId": "ch_fundamentals_1_q9_opt9",
              "optionText": "**Generality**"
            },
            {
              "optionId": "ch_fundamentals_1_q9_opt10",
              "optionText": "**Portability**"
            }
          ],
          "correctOptionIds": ["ch_fundamentals_1_q9_opt1"],
          "explanationText": "Algorithmic efficiency is primarily concerned with two dimensions: time and space. **Time efficiency** specifically refers to how fast the algorithm runs, which is typically characterized by its time complexity (e.g., $O(n)$, $O(n \\log n)$, $O(n^2)$), indicating how the number of operations grows with input size. Space efficiency, the other primary dimension, concerns memory usage.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_fundamentals_1_q10",
          "questionText": "In the context of analyzing an algorithm's time complexity, what is the _most defining characteristic_ of a 'fundamental step' or 'basic operation'?",
          "options": [
            {
              "optionId": "ch_fundamentals_1_q10_opt1",
              "optionText": "An operation whose execution time is considered constant and does not depend significantly on the input values (though it contributes to the overall count)."
            },
            {
              "optionId": "ch_fundamentals_1_q10_opt2",
              "optionText": "The most complex operation in the algorithm."
            },
            {
              "optionId": "ch_fundamentals_1_q10_opt3",
              "optionText": "Any line of pseudocode."
            },
            {
              "optionId": "ch_fundamentals_1_q10_opt4",
              "optionText": "Operations that are directly related to the problem's core logic, such as comparisons in sorting or arithmetic operations in numerical algorithms."
            },
            {
              "optionId": "ch_fundamentals_1_q10_opt5",
              "optionText": "Only operations that access memory."
            },
            {
              "optionId": "ch_fundamentals_1_q10_opt6",
              "optionText": "The operation that is executed the most number of times for typical inputs."
            },
            {
              "optionId": "ch_fundamentals_1_q10_opt7",
              "optionText": "A function call within the algorithm."
            },
            {
              "optionId": "ch_fundamentals_1_q10_opt8",
              "optionText": "An operation that can be mapped to a single machine instruction on most processors."
            },
            {
              "optionId": "ch_fundamentals_1_q10_opt9",
              "optionText": "Loop control operations (initialization, condition check, increment)."
            },
            {
              "optionId": "ch_fundamentals_1_q10_opt10",
              "optionText": "The operation whose time cost is independent of the size of the input $n$."
            }
          ],
          "correctOptionIds": ["ch_fundamentals_1_q10_opt10"],
          "explanationText": "The most defining characteristic of a 'basic operation' for time complexity analysis is that **its time cost is independent of the size of the input $n$**. Such operations (e.g., an integer comparison, an assignment) take a constant amount of time. These operations are also typically chosen because they are **directly related to the problem's core logic** (like comparisons in sorting) and can often be **mapped to a small, constant number of machine instructions**. The key is their constant-time nature relative to $n$.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "questionId": "ch_fundamentals_1_q7_partA",
          "questionText": "In the study of algorithms, what type of computational problem is characterized by requiring a 'yes' or 'no' answer?",
          "options": [
            {
              "optionId": "ch_fundamentals_1_q7_partA_opt1",
              "optionText": "**Decision Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partA_opt2",
              "optionText": "**Search Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partA_opt3",
              "optionText": "**Optimization Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partA_opt4",
              "optionText": "**Enumeration Problems** (listing all solutions)"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partA_opt5",
              "optionText": "**Counting Problems** (determining the number of solutions)"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partA_opt6",
              "optionText": "**Functional Problems** (computing an output function)"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partA_opt7",
              "optionText": "**Debugging Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partA_opt8",
              "optionText": "**User Interface Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partA_opt9",
              "optionText": "**Sorting Problems** (a specific type of functional or search problem)"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partA_opt10",
              "optionText": "**Implementation Problems**"
            }
          ],
          "correctOptionIds": ["ch_fundamentals_1_q7_partA_opt1"],
          "explanationText": "**Decision Problems** are a fundamental type of computational problem that specifically require a 'yes' or 'no' answer. For example, 'Does a path exist between two nodes in this graph?' is a decision problem. Search problems aim to find a solution if one exists, and optimization problems aim to find the best solution.",
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "questionId": "ch_fundamentals_1_q7_partB",
          "questionText": "Which category of computational problems primarily involves finding a solution that meets certain criteria, if such a solution exists?",
          "options": [
            {
              "optionId": "ch_fundamentals_1_q7_partB_opt1",
              "optionText": "**Decision Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partB_opt2",
              "optionText": "**Search Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partB_opt3",
              "optionText": "**Optimization Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partB_opt4",
              "optionText": "**Verification Problems** (a type of decision problem)"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partB_opt5",
              "optionText": "**Philosophical Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partB_opt6",
              "optionText": "**Hardware Design Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partB_opt7",
              "optionText": "**Network Routing Problems** (can be search or optimization)"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partB_opt8",
              "optionText": "**Ranking Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partB_opt9",
              "optionText": "**Data Storage Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partB_opt10",
              "optionText": "**Resource Allocation Problems** (often optimization)"
            }
          ],
          "correctOptionIds": ["ch_fundamentals_1_q7_partB_opt2"],
          "explanationText": "**Search Problems** are primarily concerned with finding a solution that satisfies certain criteria, if one exists. For example, 'Find a path from node A to node B'. This differs from decision problems (yes/no) and optimization problems (find the best solution).",
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "questionId": "ch_fundamentals_1_q7_partC",
          "questionText": "What class of computational problems focuses on finding the 'best' solution from all possible solutions, according to a specific objective function?",
          "options": [
            {
              "optionId": "ch_fundamentals_1_q7_partC_opt1",
              "optionText": "**Decision Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partC_opt2",
              "optionText": "**Search Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partC_opt3",
              "optionText": "**Optimization Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partC_opt4",
              "optionText": "**Approximation Problems** (finding near-optimal solutions)"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partC_opt5",
              "optionText": "**Compilation Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partC_opt6",
              "optionText": "**Theoretical Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partC_opt7",
              "optionText": "**Satisfiability Problems** (a type of decision or search problem)"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partC_opt8",
              "optionText": "**Constraint Satisfaction Problems** (often search or optimization)"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partC_opt9",
              "optionText": "**Pattern Recognition Problems**"
            },
            {
              "optionId": "ch_fundamentals_1_q7_partC_opt10",
              "optionText": "**Game Theory Problems**"
            }
          ],
          "correctOptionIds": ["ch_fundamentals_1_q7_partC_opt3"],
          "explanationText": "**Optimization Problems** focus on finding the best solution among all possible solutions, according to some objective function (e.g., finding the shortest path, the maximum flow, or the minimum cost). This distinguishes them from decision problems (yes/no) and search problems (find any valid solution).",
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        }
      ],
      "totalQuestions": 13,
      "answeredQuestions": 0,
      "correctAnswers": 0,
      "isCompleted": false
    },
    {
      "id": "ch_iterative_bigo_2",
      "name": "Chapter 2: Iterative Algorithms & Big O Notation",
      "description": "Covers loop invariants, loop control variables, detailed analysis of iterative algorithms, and the application of Big O notation for polynomial complexities.",
      "questions": [
        {
          "questionId": "ch_iterative_bigo_2_q1",
          "questionText": "Consider an algorithm with a time complexity function $f(n) = 5n^3 + 100n^2 + 500n + 2000$. What is its Big O complexity?",
          "options": [
            {
              "optionId": "ch_iterative_bigo_2_q1_opt1",
              "optionText": "$O(n^3)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q1_opt2",
              "optionText": "$O(5n^3)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q1_opt3",
              "optionText": "$O(n^2)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q1_opt4",
              "optionText": "$O(n)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q1_opt5",
              "optionText": "$O(1)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q1_opt6",
              "optionText": "$O(n^3 + n^2 + n)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q1_opt7",
              "optionText": "$O(2000)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q1_opt8",
              "optionText": "Its complexity is determined by the dominant term, which is $n^3$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q1_opt9",
              "optionText": "Constant factors like 5 are ignored in Big O notation."
            },
            {
              "optionId": "ch_iterative_bigo_2_q1_opt10",
              "optionText": "$O(n^3 \\log n)$"
            }
          ],
          "correctOptionIds": ["ch_iterative_bigo_2_q1_opt1"],
          "explanationText": "In Big O notation, we are interested in the asymptotic upper bound. For the function $f(n) = 5n^3 + 100n^2 + 500n + 2000$, we identify the **dominant term** (the term that grows fastest as $n$ becomes large), which is $5n^3$. Then, we **ignore constant factors** (like the 5) and lower-order terms ($100n^2, 500n, 2000$). Therefore, the Big O complexity is $O(n^3)$.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_iterative_bigo_2_q9",
          "questionText": "What is the _most fundamental definition_ of an algorithm having $O(1)$ time complexity?",
          "options": [
            {
              "optionId": "ch_iterative_bigo_2_q9_opt1",
              "optionText": "The algorithm takes exactly 1 second to run."
            },
            {
              "optionId": "ch_iterative_bigo_2_q9_opt2",
              "optionText": "The algorithm performs exactly one operation."
            },
            {
              "optionId": "ch_iterative_bigo_2_q9_opt3",
              "optionText": "The algorithm's execution time is constant and does not depend on the input size $n$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q9_opt4",
              "optionText": "The algorithm is extremely fast for all inputs."
            },
            {
              "optionId": "ch_iterative_bigo_2_q9_opt5",
              "optionText": "The algorithm does not involve any loops that depend on $n$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q9_opt6",
              "optionText": "The number of operations is primarily characterized by a fixed upper limit, irrespective of $n$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q9_opt7",
              "optionText": "The algorithm only works for inputs of size 1."
            },
            {
              "optionId": "ch_iterative_bigo_2_q9_opt8",
              "optionText": "It's the most efficient complexity class possible."
            },
            {
              "optionId": "ch_iterative_bigo_2_q9_opt9",
              "optionText": "Accessing an element in an array by its index is an example of an $O(1)$ operation."
            },
            {
              "optionId": "ch_iterative_bigo_2_q9_opt10",
              "optionText": "The algorithm uses constant extra space."
            }
          ],
          "correctOptionIds": ["ch_iterative_bigo_2_q9_opt3"],
          "explanationText": "The most fundamental definition of $O(1)$ (constant time) complexity is that **the algorithm's execution time is constant and does not depend on the input size $n$**. This implies that the number of operations performed by the algorithm is bounded above by some constant $C$, regardless of the value of $n$. While 'The number of operations is primarily characterized by a fixed upper limit, irrespective of $n$.' is a consequence and accurate description, the definition focuses on the execution time's independence from input size. Accessing an array element by its index is a classic example of an $O(1)$ operation.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_iterative_bigo_2_q3",
          "questionText": "Consider the algorithm to find the largest element in an array `a` of size `n`:\n```pseudocode\nmax ← a[0]\ni ← 1\nWHILE i < n\n  IF a[i] > max THEN\n    max ← a[i]\n  i ← i + 1\nRETURN max\n```\nFor this algorithm, which statement _best describes the primary loop invariant concerning the variable `max`_ just before the loop condition `i < n` is checked (assuming `1 ≤ i ≤ n`, where `i=n` represents the state just after the loop terminates)?",
          "options": [
            {
              "optionId": "ch_iterative_bigo_2_q3_opt1",
              "optionText": "`max` is the largest element in `a[0...n-1]`."
            },
            {
              "optionId": "ch_iterative_bigo_2_q3_opt2",
              "optionText": "`max` is the largest element in `a[0...i-1]`."
            },
            {
              "optionId": "ch_iterative_bigo_2_q3_opt3",
              "optionText": "`max` is equal to `a[i-1]`."
            },
            {
              "optionId": "ch_iterative_bigo_2_q3_opt4",
              "optionText": "`i` is always less than `n`."
            },
            {
              "optionId": "ch_iterative_bigo_2_q3_opt5",
              "optionText": "`max` contains the element `a[0]`."
            },
            {
              "optionId": "ch_iterative_bigo_2_q3_opt6",
              "optionText": "All elements in `a[0...i-1]` have been compared with `max`."
            },
            {
              "optionId": "ch_iterative_bigo_2_q3_opt7",
              "optionText": "`max` is greater than or equal to all elements in `a[0...i-1]`."
            },
            {
              "optionId": "ch_iterative_bigo_2_q3_opt8",
              "optionText": "`i` represents the index of the next element to be considered for comparison against `max`."
            },
            {
              "optionId": "ch_iterative_bigo_2_q3_opt9",
              "optionText": "The array `a` is sorted up to index `i-1`."
            },
            {
              "optionId": "ch_iterative_bigo_2_q3_opt10",
              "optionText": "`max` is the smallest element in `a[0...i-1]`."
            }
          ],
          "correctOptionIds": ["ch_iterative_bigo_2_q3_opt2"],
          "explanationText": "A crucial loop invariant for this algorithm, concerning the variable `max`, is that _**max is the largest element in the subarray `a[0...i-1]`**_. This property is established before the loop (when `i=1`, `max = a[0]`, so it's true for `a[0...0]`). Each iteration maintains this: if `a[i]` (the current element being considered) is larger than `max`, `max` is updated to `a[i]`; otherwise, `max` (which was largest in `a[0...i-1]`) remains the largest. After `a[i]` is processed and `i` is incremented, `max` holds the largest value in `a[0...(new i)-1]`. Another invariant concerns the loop counter `i`, which represents the index of the next element to be considered. Upon termination (when `i=n`), the invariant regarding `max` implies that `max` is the largest element in the entire array `a[0...n-1]`.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_iterative_bigo_2_q4",
          "questionText": "What is the Big O time complexity of an algorithm that has a single loop iterating $n$ times, and inside the loop, it performs a constant number of operations (e.g., 3 assignments and 2 comparisons)?",
          "options": [
            {
              "optionId": "ch_iterative_bigo_2_q4_opt1",
              "optionText": "$O(1)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q4_opt2",
              "optionText": "$O(\\log n)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q4_opt3",
              "optionText": "$O(n)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q4_opt4",
              "optionText": "$O(n \\log n)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q4_opt5",
              "optionText": "$O(n^2)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q4_opt6",
              "optionText": "$O(5n)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q4_opt7",
              "optionText": "The number of operations inside the loop ($c$) is summed across iterations."
            },
            {
              "optionId": "ch_iterative_bigo_2_q4_opt8",
              "optionText": "The total number of operations is roughly $c + n$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q4_opt9",
              "optionText": "$O(c \\cdot n)$, which implies the algorithm's runtime is exactly $c$ times $n$ operations."
            },
            {
              "optionId": "ch_iterative_bigo_2_q4_opt10",
              "optionText": "$O(n^c)$"
            }
          ],
          "correctOptionIds": ["ch_iterative_bigo_2_q4_opt3"],
          "explanationText": "If a loop iterates $n$ times, and inside each iteration, a constant number of operations, say $c$ (e.g., $3+2=5$ operations), are performed, then the total number of operations is $c \\times n$. In Big O notation, constant factors are ignored. Thus, the time complexity is **$O(n)$**, which is linear time complexity. While $O(5n)$ or $O(c \\cdot n)$ describe the number of operations before simplification, $O(n)$ is the standard Big O representation. Big O describes an asymptotic upper bound, not an exact count.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_iterative_bigo_2_q5",
          "questionText": "An algorithm consists of two independent (non-nested) loops. The first loop runs $n$ times, and the second loop also runs $n$ times (each performing constant work per iteration). What is the overall Big O time complexity?",
          "options": [
            {
              "optionId": "ch_iterative_bigo_2_q5_opt1",
              "optionText": "$O(n^2)$ because there are two loops."
            },
            {
              "optionId": "ch_iterative_bigo_2_q5_opt2",
              "optionText": "$O(n)$ because the loops are sequential, not nested."
            },
            {
              "optionId": "ch_iterative_bigo_2_q5_opt3",
              "optionText": "$O(2n)$ which simplifies to $O(n)$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q5_opt4",
              "optionText": "$O(\\log n)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q5_opt5",
              "optionText": "$O(n + n)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q5_opt6",
              "optionText": "It depends on what operations are inside the loops."
            },
            {
              "optionId": "ch_iterative_bigo_2_q5_opt7",
              "optionText": "$O(n \\times n)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q5_opt8",
              "optionText": "The complexities are added: $O(n) + O(n) = O(n)$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q5_opt9",
              "optionText": "$O(\\max(n, n)) = O(n)$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q5_opt10",
              "optionText": "$O(n!)$"
            }
          ],
          "correctOptionIds": ["ch_iterative_bigo_2_q5_opt3"],
          "explanationText": "When an algorithm consists of two independent, sequential loops, and each runs $n$ times (performing constant work per iteration), their individual complexities are $O(n)$. For sequential blocks of code, their complexities are added. Thus, the total time is $O(n) + O(n) = O(n+n)$, which is $O(2n)$. In Big O notation, constant factors are ignored, so this simplifies to **$O(n)$**. Therefore, the statement '$O(2n)$ which simplifies to $O(n)$' best describes this calculation and result. The fact that the loops are sequential, not nested, is key to this addition rule.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_iterative_bigo_2_q6",
          "questionText": "What is the Big O time complexity of an algorithm with nested loops where the outer loop runs $n$ times and the inner loop runs $m$ times for each iteration of the outer loop (assuming constant work inside the inner loop)?",
          "options": [
            {
              "optionId": "ch_iterative_bigo_2_q6_opt1",
              "optionText": "$O(n+m)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q6_opt2",
              "optionText": "$O(n \\times m)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q6_opt3",
              "optionText": "$O(n)$ if $n > m$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q6_opt4",
              "optionText": "$O(m)$ if $m > n$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q6_opt5",
              "optionText": "$O(n^2)$ if $n=m$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q6_opt6",
              "optionText": "$O(\\max(n,m))$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q6_opt7",
              "optionText": "The inner loop operations are performed $n \\times m$ times."
            },
            {
              "optionId": "ch_iterative_bigo_2_q6_opt8",
              "optionText": "$O(n \\log m)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q6_opt9",
              "optionText": "$O(m \\log n)$"
            },
            {
              "optionId": "ch_iterative_bigo_2_q6_opt10",
              "optionText": "$O(n^m)$"
            }
          ],
          "correctOptionIds": ["ch_iterative_bigo_2_q6_opt2"],
          "explanationText": "For nested loops, the number of times the inner loop's body executes is the product of the number of iterations of the outer loop and the number of iterations of the inner loop (per outer iteration). So, if the outer loop runs $n$ times and for each of those iterations, the inner loop runs $m$ times, the total operations performed by the inner loop's body will be proportional to $n \\times m$. Thus, the Big O complexity is **$O(n \\times m)$**. If $n$ and $m$ are the same (i.e., $n=m$), this complexity becomes $O(n \\times n) = O(n^2)$.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_iterative_bigo_2_q7",
          "questionText": "A loop control variable is central to managing loop execution. Which of its characteristics is _most directly involved in the decision to continue or terminate_ the loop's iterations?",
          "options": [
            {
              "optionId": "ch_iterative_bigo_2_q7_opt1",
              "optionText": "It is initialized before the loop starts."
            },
            {
              "optionId": "ch_iterative_bigo_2_q7_opt2",
              "optionText": "It is used in the test condition that determines whether the loop continues or terminates."
            },
            {
              "optionId": "ch_iterative_bigo_2_q7_opt3",
              "optionText": "It is modified (e.g., incremented or decremented) inside the body of the loop."
            },
            {
              "optionId": "ch_iterative_bigo_2_q7_opt4",
              "optionText": "Its value must always be an integer."
            },
            {
              "optionId": "ch_iterative_bigo_2_q7_opt5",
              "optionText": "It is used to directly access array elements."
            },
            {
              "optionId": "ch_iterative_bigo_2_q7_opt6",
              "optionText": "There can only be one loop control variable per loop."
            },
            {
              "optionId": "ch_iterative_bigo_2_q7_opt7",
              "optionText": "Its modification ensures progress towards the loop's termination condition."
            },
            {
              "optionId": "ch_iterative_bigo_2_q7_opt8",
              "optionText": "It cannot be modified by any nested loops."
            },
            {
              "optionId": "ch_iterative_bigo_2_q7_opt9",
              "optionText": "It is declared as a constant (`final` in Java)."
            },
            {
              "optionId": "ch_iterative_bigo_2_q7_opt10",
              "optionText": "It is only used in `for` loops, not `while` loops."
            }
          ],
          "correctOptionIds": ["ch_iterative_bigo_2_q7_opt2"],
          "explanationText": "While a loop control variable must be initialized before the loop (Initialization) and modified within its body to ensure progress (Modification), its characteristic of being **used in the test condition that determines whether the loop continues or terminates** (Test) is most directly involved in the decision-making process of loop execution at each step. These three aspects (Initialize, Test, Modify) together define its fundamental structural role in controlling the loop.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_iterative_bigo_2_q8",
          "questionText": "If an algorithm has a worst-case time complexity of $O(n^2)$ and another algorithm for the same problem has $O(n^3)$, what is the _most significant difference in their long-term performance characteristics_ as $n$ becomes very large?",
          "options": [
            {
              "optionId": "ch_iterative_bigo_2_q8_opt1",
              "optionText": "The $O(n^2)$ algorithm will always be faster than the $O(n^3)$ algorithm for any $n > 0$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q8_opt2",
              "optionText": "The $O(n^2)$ algorithm is asymptotically faster than the $O(n^3)$ algorithm."
            },
            {
              "optionId": "ch_iterative_bigo_2_q8_opt3",
              "optionText": "For small values of $n$, the $O(n^3)$ algorithm might be faster due to smaller constant factors or simpler operations in its implementation."
            },
            {
              "optionId": "ch_iterative_bigo_2_q8_opt4",
              "optionText": "The $O(n^3)$ algorithm will eventually (for large enough $n$) take significantly more time than the $O(n^2)$ algorithm."
            },
            {
              "optionId": "ch_iterative_bigo_2_q8_opt5",
              "optionText": "The growth rate of the $O(n^2)$ algorithm is lower than that of the $O(n^3)$ algorithm."
            },
            {
              "optionId": "ch_iterative_bigo_2_q8_opt6",
              "optionText": "Both algorithms are considered polynomial time, which is generally categorized as tractable."
            },
            {
              "optionId": "ch_iterative_bigo_2_q8_opt7",
              "optionText": "The $O(n^2)$ algorithm is always preferred, regardless of $n$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q8_opt8",
              "optionText": "The difference in their actual run times will be exactly a factor of $n$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q8_opt9",
              "optionText": "It's impossible to compare them without knowing the exact constant factors."
            },
            {
              "optionId": "ch_iterative_bigo_2_q8_opt10",
              "optionText": "If $n=10$, the $O(n^2)$ algorithm takes 100 steps and the $O(n^3)$ algorithm takes 1000 steps, ignoring constants."
            }
          ],
          "correctOptionIds": ["ch_iterative_bigo_2_q8_opt2"],
          "explanationText": "The most significant difference for large $n$ is that **the $O(n^2)$ algorithm is asymptotically faster than the $O(n^3)$ algorithm**; its running time grows at a slower rate. This means that as $n$ becomes very large, the $O(n^2)$ algorithm will eventually outperform the $O(n^3)$ algorithm, regardless of constant factors. It's important to note that for small values of $n$, the $O(n^3)$ algorithm could be faster if its constant factors or the cost of its elementary operations are significantly smaller. Both $O(n^2)$ and $O(n^3)$ complexities represent polynomial time, which is generally considered tractable.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_iterative_bigo_2_q10",
          "questionText": "What is the _most fundamental definition_ of an algorithm having $O(1)$ time complexity?",
          "options": [
            {
              "optionId": "ch_iterative_bigo_2_q10_opt1",
              "optionText": "The algorithm takes exactly 1 second to run."
            },
            {
              "optionId": "ch_iterative_bigo_2_q10_opt2",
              "optionText": "The algorithm performs exactly one operation."
            },
            {
              "optionId": "ch_iterative_bigo_2_q10_opt3",
              "optionText": "The algorithm's execution time is constant and does not depend on the input size $n$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q10_opt4",
              "optionText": "The algorithm is extremely fast for all inputs."
            },
            {
              "optionId": "ch_iterative_bigo_2_q10_opt5",
              "optionText": "The algorithm does not involve any loops that depend on $n$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q10_opt6",
              "optionText": "The number of operations is primarily characterized by a fixed upper limit, irrespective of $n$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q10_opt7",
              "optionText": "The algorithm only works for inputs of size 1."
            },
            {
              "optionId": "ch_iterative_bigo_2_q10_opt8",
              "optionText": "It's the most efficient complexity class possible."
            },
            {
              "optionId": "ch_iterative_bigo_2_q10_opt9",
              "optionText": "Accessing an element in an array by its index is an example of an $O(1)$ operation."
            },
            {
              "optionId": "ch_iterative_bigo_2_q10_opt10",
              "optionText": "The algorithm uses constant extra space."
            }
          ],
          "correctOptionIds": ["ch_iterative_bigo_2_q10_opt3"],
          "explanationText": "The most fundamental definition of $O(1)$ (constant time) complexity is that **the algorithm's execution time is constant and does not depend on the input size $n$**. This implies that the number of operations performed by the algorithm is bounded above by some constant $C$, regardless of the value of $n$. While 'The number of operations is primarily characterized by a fixed upper limit, irrespective of $n$.' is a consequence and accurate description, the definition focuses on the execution time's independence from input size. Accessing an array element by its index is a classic example of an $O(1)$ operation.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_iterative_bigo_2_q2",
          "questionText": "Which statement _best defines the primary purpose_ of Big O notation in algorithm analysis?",
          "options": [
            {
              "optionId": "ch_iterative_bigo_2_q2_opt1",
              "optionText": "An algorithm with complexity $O(n)$ has a faster rate of growth than an algorithm with $O(n^2)$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q2_opt2",
              "optionText": "An algorithm with complexity $O(n^2)$ has a faster rate of growth than an algorithm with $O(n)$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q2_opt3",
              "optionText": "Big O notation provides an exact count of operations."
            },
            {
              "optionId": "ch_iterative_bigo_2_q2_opt4",
              "optionText": "Big O notation describes the asymptotic upper bound of an algorithm's growth rate."
            },
            {
              "optionId": "ch_iterative_bigo_2_q2_opt5",
              "optionText": "Constant factors are significant in Big O notation (e.g., $O(2n)$ is different from $O(n)$)."
            },
            {
              "optionId": "ch_iterative_bigo_2_q2_opt6",
              "optionText": "Lower-order terms are significant in Big O notation (e.g., $O(n^2 + n)$ is different from $O(n^2)$)."
            },
            {
              "optionId": "ch_iterative_bigo_2_q2_opt7",
              "optionText": "If $f(n) = O(g(n))$, then $g(n)$ grows at least as fast as $f(n)$ for large $n$ (up to a constant factor)."
            },
            {
              "optionId": "ch_iterative_bigo_2_q2_opt8",
              "optionText": "$100n + 500 = O(n)$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q2_opt9",
              "optionText": "$n^2 / 2 + n/2 = O(n^2)$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q2_opt10",
              "optionText": "Big O notation is only used for time complexity, not space complexity."
            }
          ],
          "correctOptionIds": ["ch_iterative_bigo_2_q2_opt4"],
          "explanationText": "The primary purpose of Big O notation is that it **describes the asymptotic upper bound of an algorithm's growth rate** as the input size $n$ tends towards infinity. This means if an algorithm's resource usage (time or space) is $f(n)$, and we say $f(n) = O(g(n))$, then $g(n)$ serves as an upper bound for $f(n)$ for sufficiently large $n$, implying $g(n)$ grows at least as fast as $f(n)$ (ignoring constant factors and lower-order terms). For example, a function $100n + 500$ is $O(n)$, and $n^2/2 + n/2$ is $O(n^2)$. Big O notation is used for both time and space complexity. An algorithm with $O(n)$ complexity has a _slower_ (more desirable) rate of growth of its complexity function than one with $O(n^2)$ complexity (where $n^2$ grows faster than $n$).",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_iterative_bigo_2_q11",
          "questionText": "Consider the sequential search algorithm for an array of $n$ elements. In the **average case** (assuming the element is present and equally likely to be at any position), approximately how many comparisons are typically performed?",
          "options": [
            {
              "optionId": "ch_iterative_bigo_2_q11_opt1",
              "optionText": "1 comparison."
            },
            {
              "optionId": "ch_iterative_bigo_2_q11_opt2",
              "optionText": "$n$ comparisons."
            },
            {
              "optionId": "ch_iterative_bigo_2_q11_opt3",
              "optionText": "$n/2$ comparisons (approximately)."
            },
            {
              "optionId": "ch_iterative_bigo_2_q11_opt4",
              "optionText": "$O(\\log n)$ comparisons."
            },
            {
              "optionId": "ch_iterative_bigo_2_q11_opt5",
              "optionText": "$n^2$ comparisons."
            },
            {
              "optionId": "ch_iterative_bigo_2_q11_opt6",
              "optionText": "The number of comparisons is $(1+2+...+n)/n = (n(n+1)/2)/n = (n+1)/2$."
            },
            {
              "optionId": "ch_iterative_bigo_2_q11_opt7",
              "optionText": "The complexity is still $O(n)$ in the average case."
            },
            {
              "optionId": "ch_iterative_bigo_2_q11_opt8",
              "optionText": "It is always the same as the worst case."
            },
            {
              "optionId": "ch_iterative_bigo_2_q11_opt9",
              "optionText": "It is the same as the best case if the element is found at the first position."
            },
            {
              "optionId": "ch_iterative_bigo_2_q11_opt10",
              "optionText": "It depends on whether the array is sorted or not."
            }
          ],
          "correctOptionIds": ["ch_iterative_bigo_2_q11_opt3"],
          "explanationText": "For sequential search in the average case (assuming the element is present and equally likely to be at any position), the number of comparisons is approximately **$n/2$**. This is derived by summing the number of comparisons needed if the element is at the first position (1), second (2), ..., up to the $n$-th position ($n$), and then dividing by $n$. This sum is $(1+2+...+n) = n(n+1)/2$. So the average is $(n(n+1)/2)/n = (n+1)/2$, which is close to $n/2$ for large $n$. In Big O notation, this average-case performance is still $O(n)$.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_iterative_bigo_2_q12",
          "questionText": "What is the primary purpose of using a loop control variable in conjunction with a loop termination condition in an iterative algorithm?",
          "options": [
            {
              "optionId": "ch_iterative_bigo_2_q12_opt1",
              "optionText": "To ensure the loop performs a fixed number of iterations, known at compile time."
            },
            {
              "optionId": "ch_iterative_bigo_2_q12_opt2",
              "optionText": "To ensure the loop eventually terminates and avoids an infinite loop."
            },
            {
              "optionId": "ch_iterative_bigo_2_q12_opt3",
              "optionText": "To make the loop run as fast as possible."
            },
            {
              "optionId": "ch_iterative_bigo_2_q12_opt4",
              "optionText": "To make the loop invariant easier to prove."
            },
            {
              "optionId": "ch_iterative_bigo_2_q12_opt5",
              "optionText": "To provide a way to count the number of operations for complexity analysis."
            },
            {
              "optionId": "ch_iterative_bigo_2_q12_opt6",
              "optionText": "To allow the loop to process each element of a data structure (like an array)."
            },
            {
              "optionId": "ch_iterative_bigo_2_q12_opt7",
              "optionText": "The loop control variable is modified within the loop body to make progress towards making the termination condition false."
            },
            {
              "optionId": "ch_iterative_bigo_2_q12_opt8",
              "optionText": "The termination condition is checked before each iteration."
            },
            {
              "optionId": "ch_iterative_bigo_2_q12_opt9",
              "optionText": "To define the scope of variables used within the loop."
            },
            {
              "optionId": "ch_iterative_bigo_2_q12_opt10",
              "optionText": "To allow for early exit from the loop using a `break` statement."
            }
          ],
          "correctOptionIds": ["ch_iterative_bigo_2_q12_opt2"],
          "explanationText": "The primary purpose of using a loop control variable in conjunction with a loop termination condition is **to ensure the loop eventually terminates and avoids an infinite loop**. This is achieved by systematically modifying the loop control variable within the loop body, thereby making progress towards a state where the termination condition (which is typically checked before each iteration in `WHILE` or `FOR` loops) becomes false, causing the loop to exit. While it often facilitates processing data structures or aids in complexity analysis, its fundamental role is controlling the loop's finite execution.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        }
      ],
      "totalQuestions": 12,
      "answeredQuestions": 0,
      "correctAnswers": 0,
      "isCompleted": false
    },
    {
      "id": "ch_simple_sorting_3",
      "name": "Chapter 3: Simple Sorting Algorithms",
      "description": "Explores Selection Sort and Insertion Sort, including their mechanisms, tracing, complexity, stability, and adaptivity.",
      "questions": [
        {
          "questionId": "ch_simple_sorting_3_q1",
          "questionText": "Which statement _best summarises the core operational mechanic_ of the **Selection Sort** algorithm?",
          "options": [
            {
              "optionId": "ch_simple_sorting_3_q1_opt1",
              "optionText": "In each pass, it finds the smallest element in the unsorted portion and swaps it with the first element of the unsorted portion."
            },
            {
              "optionId": "ch_simple_sorting_3_q1_opt2",
              "optionText": "It builds the sorted array one element at a time by inserting the current element into its correct position in the already sorted part."
            },
            {
              "optionId": "ch_simple_sorting_3_q1_opt3",
              "optionText": "It has a time complexity of $O(n \\log n)$ in the average case."
            },
            {
              "optionId": "ch_simple_sorting_3_q1_opt4",
              "optionText": "It has a time complexity of $O(n^2)$ in the worst, average, and best cases."
            },
            {
              "optionId": "ch_simple_sorting_3_q1_opt5",
              "optionText": "It is a stable sorting algorithm."
            },
            {
              "optionId": "ch_simple_sorting_3_q1_opt6",
              "optionText": "It is not a stable sorting algorithm because swaps can change the relative order of equal elements."
            },
            {
              "optionId": "ch_simple_sorting_3_q1_opt7",
              "optionText": "It is an adaptive sorting algorithm (performs better on partially sorted data)."
            },
            {
              "optionId": "ch_simple_sorting_3_q1_opt8",
              "optionText": "It is not an adaptive sorting algorithm; the number of comparisons is always the same regardless of initial order."
            },
            {
              "optionId": "ch_simple_sorting_3_q1_opt9",
              "optionText": "It requires $O(n)$ auxiliary space."
            },
            {
              "optionId": "ch_simple_sorting_3_q1_opt10",
              "optionText": "It requires $O(1)$ auxiliary space (in-place sort)."
            }
          ],
          "correctOptionIds": ["ch_simple_sorting_3_q1_opt1"],
          "explanationText": "The core operational mechanic of Selection Sort is that **in each pass, it finds the smallest (or largest, depending on sort order) element in the remaining unsorted portion of the array and swaps it with the element at the beginning of that unsorted portion**. This process is repeated for the subsequent smaller unsorted portions until the entire array is sorted. Its time complexity is consistently $O(n^2)$ in all cases (worst, average, and best) because it always makes roughly $n^2/2$ comparisons. It is not a stable sort due to the long-range swaps, but it is an in-place sort requiring $O(1)$ auxiliary space.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_simple_sorting_3_q2",
          "questionText": "Which statement _best describes the fundamental operation_ of the **Insertion Sort** algorithm?",
          "options": [
            {
              "optionId": "ch_simple_sorting_3_q2_opt1",
              "optionText": "In each pass, it finds the smallest element in the unsorted portion and swaps it with the first element of the unsorted portion."
            },
            {
              "optionId": "ch_simple_sorting_3_q2_opt2",
              "optionText": "It builds the sorted array one element at a time by taking the current element from the unsorted part and inserting it into its correct position within the already sorted part."
            },
            {
              "optionId": "ch_simple_sorting_3_q2_opt3",
              "optionText": "It has a time complexity of $O(n^2)$ in the worst case (e.g., reverse sorted array)."
            },
            {
              "optionId": "ch_simple_sorting_3_q2_opt4",
              "optionText": "It has a time complexity of $O(n)$ in the best case (e.g., already sorted array)."
            },
            {
              "optionId": "ch_simple_sorting_3_q2_opt5",
              "optionText": "It is a stable sorting algorithm."
            },
            {
              "optionId": "ch_simple_sorting_3_q2_opt6",
              "optionText": "It is not a stable sorting algorithm."
            },
            {
              "optionId": "ch_simple_sorting_3_q2_opt7",
              "optionText": "It is an adaptive sorting algorithm (performs better on partially sorted data)."
            },
            {
              "optionId": "ch_simple_sorting_3_q2_opt8",
              "optionText": "It is not an adaptive sorting algorithm."
            },
            {
              "optionId": "ch_simple_sorting_3_q2_opt9",
              "optionText": "It requires $O(n)$ auxiliary space for the insertions."
            },
            {
              "optionId": "ch_simple_sorting_3_q2_opt10",
              "optionText": "It requires $O(1)$ auxiliary space (in-place sort)."
            }
          ],
          "correctOptionIds": ["ch_simple_sorting_3_q2_opt2"],
          "explanationText": "The fundamental operation of Insertion Sort is that **it builds the sorted array one element at a time by taking the current element from the unsorted part and inserting it into its correct position within the already sorted part** by shifting larger elements to the right. This algorithm is stable (preserves relative order of equal elements), adaptive (performs efficiently on nearly sorted data with $O(n)$ best-case complexity), and in-place (requires $O(1)$ auxiliary space). Its worst-case time complexity is $O(n^2)$ (e.g., for a reverse-sorted array).",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_simple_sorting_3_q3",
          "questionText": "When tracing Selection Sort on the array `[27, 14, 77, 34]`, what is the state of the array after the **first pass** (i.e., after the first smallest element is placed in its correct position)?",
          "options": [
            {
              "optionId": "ch_simple_sorting_3_q3_opt1",
              "optionText": "`[27, 14, 77, 34]` (no change)"
            },
            {
              "optionId": "ch_simple_sorting_3_q3_opt2",
              "optionText": "`[14, 27, 77, 34]`"
            },
            {
              "optionId": "ch_simple_sorting_3_q3_opt3",
              "optionText": "`[14, 77, 27, 34]`"
            },
            {
              "optionId": "ch_simple_sorting_3_q3_opt4",
              "optionText": "`[14, 34, 77, 27]`"
            },
            {
              "optionId": "ch_simple_sorting_3_q3_opt5",
              "optionText": "`[27, 14, 34, 77]`"
            },
            {
              "optionId": "ch_simple_sorting_3_q3_opt6",
              "optionText": "The smallest element is 14 at index 1."
            },
            {
              "optionId": "ch_simple_sorting_3_q3_opt7",
              "optionText": "14 is swapped with the element at index 0 (which is 27)."
            },
            {
              "optionId": "ch_simple_sorting_3_q3_opt8",
              "optionText": "`[34, 14, 77, 27]`"
            },
            {
              "optionId": "ch_simple_sorting_3_q3_opt9",
              "optionText": "`[77, 14, 27, 34]`"
            },
            {
              "optionId": "ch_simple_sorting_3_q3_opt10",
              "optionText": "`[14, 27, 34, 77]` (fully sorted)"
            }
          ],
          "correctOptionIds": ["ch_simple_sorting_3_q3_opt2"],
          "explanationText": "Original array: `[27, 14, 77, 34]`.<br>**First pass (i=0):**<br>1. Find the smallest element in `a[0...3]`. The smallest is 14, located at index 1.<br>2. Swap `a[0]` (which is 27) with `a[1]` (which is 14).<br>The array becomes **`[14, 27, 77, 34]`**. This is the state after the first pass.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_simple_sorting_3_q4",
          "questionText": "When tracing Insertion Sort on the array `[27, 14, 77, 34]`, what is the _state of the array after the element `14` (originally at index 1) has been processed and inserted_ into its correct position in the sorted portion?",
          "options": [
            {
              "optionId": "ch_simple_sorting_3_q4_opt1",
              "optionText": "`[27, 14, 77, 34]` (no change yet as 14 is the first element to be inserted)"
            },
            {
              "optionId": "ch_simple_sorting_3_q4_opt2",
              "optionText": "`[14, 27, 77, 34]`"
            },
            {
              "optionId": "ch_simple_sorting_3_q4_opt3",
              "optionText": "The element `a[0]=27` is considered sorted initially."
            },
            {
              "optionId": "ch_simple_sorting_3_q4_opt4",
              "optionText": "The element `14` is compared with `27`. Since `14 < 27`, `27` is shifted right."
            },
            {
              "optionId": "ch_simple_sorting_3_q4_opt5",
              "optionText": "`14` is placed at index 0."
            },
            {
              "optionId": "ch_simple_sorting_3_q4_opt6",
              "optionText": "`[27, 77, 14, 34]`"
            },
            {
              "optionId": "ch_simple_sorting_3_q4_opt7",
              "optionText": "`[14, 77, 27, 34]`"
            },
            {
              "optionId": "ch_simple_sorting_3_q4_opt8",
              "optionText": "This occurs during the pass when `i=1`."
            },
            {
              "optionId": "ch_simple_sorting_3_q4_opt9",
              "optionText": "`[14, 27, 34, 77]` (fully sorted)"
            },
            {
              "optionId": "ch_simple_sorting_3_q4_opt10",
              "optionText": "`[27, 14, 34, 77]`"
            }
          ],
          "correctOptionIds": ["ch_simple_sorting_3_q4_opt2"],
          "explanationText": "Original array: `[27, 14, 77, 34]`. Insertion Sort considers `a[0]=27` as initially sorted. The pass to insert `a[1]=14` (which occurs when the outer loop index, say `i`, is 1) involves taking `14` and comparing it with elements in the sorted portion `[27]`. Since `14 < 27`, `27` is shifted to the right (to index 1), and `14` is placed at index 0. So, after `14` is inserted, **the array becomes `[14, 27, 77, 34]`**.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_simple_sorting_3_q5",
          "questionText": "What does it _most fundamentally mean_ for a sorting algorithm to be **stable**?",
          "options": [
            {
              "optionId": "ch_simple_sorting_3_q5_opt1",
              "optionText": "It always produces the same sorted output for a given input, even if run multiple times."
            },
            {
              "optionId": "ch_simple_sorting_3_q5_opt2",
              "optionText": "It maintains the relative order of records with equal sort keys."
            },
            {
              "optionId": "ch_simple_sorting_3_q5_opt3",
              "optionText": "Its time complexity is the same for all types of input (worst, average, best)."
            },
            {
              "optionId": "ch_simple_sorting_3_q5_opt4",
              "optionText": "It does not crash or enter an infinite loop for any input."
            },
            {
              "optionId": "ch_simple_sorting_3_q5_opt5",
              "optionText": "It uses a stable amount of memory, i.e., $O(1)$ space complexity."
            },
            {
              "optionId": "ch_simple_sorting_3_q5_opt6",
              "optionText": "If two elements `x` and `y` have the same key, and `x` appears before `y` in the input, then `x` will appear before `y` in the output."
            },
            {
              "optionId": "ch_simple_sorting_3_q5_opt7",
              "optionText": "It can sort data that is constantly changing."
            },
            {
              "optionId": "ch_simple_sorting_3_q5_opt8",
              "optionText": "It is not affected by the initial order of the elements."
            },
            {
              "optionId": "ch_simple_sorting_3_q5_opt9",
              "optionText": "It is suitable for sorting data stored on stable storage like hard disks."
            },
            {
              "optionId": "ch_simple_sorting_3_q5_opt10",
              "optionText": "It is guaranteed to terminate."
            }
          ],
          "correctOptionIds": ["ch_simple_sorting_3_q5_opt2"],
          "explanationText": "The most fundamental meaning of a stable sorting algorithm is that **it maintains the relative order of records with equal sort keys**. This means if two elements have the same value (key) used for sorting, and one appears before the other in the original input array, it will also appear before the other in the sorted output array. The statement 'If two elements x and y have the same key, and x appears before y in the input, then x will appear before y in the output' is a more formal way of expressing this same core concept. Other options describe properties like determinism (always same output), performance consistency, or general algorithm correctness, which are distinct from stability.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_simple_sorting_3_q6",
          "questionText": "What does it _most accurately mean_ for a sorting algorithm to be **adaptive**?",
          "options": [
            {
              "optionId": "ch_simple_sorting_3_q6_opt1",
              "optionText": "It can adapt to different data types (integers, strings, objects)."
            },
            {
              "optionId": "ch_simple_sorting_3_q6_opt2",
              "optionText": "Its performance improves (e.g., runs faster) if the input data is already partially sorted."
            },
            {
              "optionId": "ch_simple_sorting_3_q6_opt3",
              "optionText": "It adapts its memory usage based on the input size."
            },
            {
              "optionId": "ch_simple_sorting_3_q6_opt4",
              "optionText": "It automatically chooses the best pivot element in algorithms like Quicksort."
            },
            {
              "optionId": "ch_simple_sorting_3_q6_opt5",
              "optionText": "It uses adaptive data structures internally."
            },
            {
              "optionId": "ch_simple_sorting_3_q6_opt6",
              "optionText": "If the input is already sorted, an adaptive algorithm might achieve its best-case time complexity, which is better than its average or worst-case."
            },
            {
              "optionId": "ch_simple_sorting_3_q6_opt7",
              "optionText": "It requires the user to adapt the algorithm's parameters for optimal performance."
            },
            {
              "optionId": "ch_simple_sorting_3_q6_opt8",
              "optionText": "It is always an in-place sorting algorithm."
            },
            {
              "optionId": "ch_simple_sorting_3_q6_opt9",
              "optionText": "Its stability adapts based on the input data."
            },
            {
              "optionId": "ch_simple_sorting_3_q6_opt10",
              "optionText": "Insertion sort is an example of an adaptive algorithm."
            }
          ],
          "correctOptionIds": ["ch_simple_sorting_3_q6_opt2"],
          "explanationText": "An **adaptive** sorting algorithm is one whose **performance (typically run time) improves if the input data is already partially sorted or exhibits some existing order**. A key consequence is that if the input is already sorted, such an algorithm might achieve its best-case time complexity, which is often better than its average or worst-case complexity (e.g., Insertion Sort achieves $O(n)$ on sorted data). Insertion Sort is a well-known example of an adaptive algorithm. Selection Sort is not adaptive as its performance remains $O(n^2)$ regardless of input order.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_simple_sorting_3_q7",
          "questionText": "Which statement _most accurately characterizes the number of comparisons_ performed by Selection Sort on an array of $n$ elements?",
          "options": [
            {
              "optionId": "ch_simple_sorting_3_q7_opt1",
              "optionText": "$O(n)$"
            },
            {
              "optionId": "ch_simple_sorting_3_q7_opt2",
              "optionText": "$O(n \\log n)$"
            },
            {
              "optionId": "ch_simple_sorting_3_q7_opt3",
              "optionText": "$O(n^2)$"
            },
            {
              "optionId": "ch_simple_sorting_3_q7_opt4",
              "optionText": "Exactly $n-1$ comparisons."
            },
            {
              "optionId": "ch_simple_sorting_3_q7_opt5",
              "optionText": "Exactly $n(n-1)/2$ comparisons."
            },
            {
              "optionId": "ch_simple_sorting_3_q7_opt6",
              "optionText": "The number of comparisons is $(n-1) + (n-2) + ... + 1$."
            },
            {
              "optionId": "ch_simple_sorting_3_q7_opt7",
              "optionText": "It depends on the initial order of the array."
            },
            {
              "optionId": "ch_simple_sorting_3_q7_opt8",
              "optionText": "$O(1)$"
            },
            {
              "optionId": "ch_simple_sorting_3_q7_opt9",
              "optionText": "The number of comparisons is the same in the best, average, and worst cases."
            },
            {
              "optionId": "ch_simple_sorting_3_q7_opt10",
              "optionText": "$O(n!)$"
            }
          ],
          "correctOptionIds": ["ch_simple_sorting_3_q7_opt5"],
          "explanationText": "Selection Sort performs **exactly $n(n-1)/2$ comparisons** on an array of $n$ elements. This is because in the first pass it makes $n-1$ comparisons to find the minimum, in the second pass $n-2$ comparisons, and so on, until the last pass makes 1 comparison. The sum $(n-1) + (n-2) + ... + 1$ equals $n(n-1)/2$. Consequently, the number of comparisons is always the same regardless of the input data's initial order (best, average, and worst cases are identical in terms of comparisons), and its time complexity is $O(n^2)$.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_simple_sorting_3_q8",
          "questionText": "What is the best-case time complexity for Insertion Sort, and what type of input _primarily_ triggers this best case?",
          "options": [
            {
              "optionId": "ch_simple_sorting_3_q8_opt1",
              "optionText": "$O(n^2)$, for a reverse-sorted array."
            },
            {
              "optionId": "ch_simple_sorting_3_q8_opt2",
              "optionText": "$O(n)$, for an already sorted array."
            },
            {
              "optionId": "ch_simple_sorting_3_q8_opt3",
              "optionText": "$O(n \\log n)$, for a randomly ordered array."
            },
            {
              "optionId": "ch_simple_sorting_3_q8_opt4",
              "optionText": "$O(1)$, if the array has only one element."
            },
            {
              "optionId": "ch_simple_sorting_3_q8_opt5",
              "optionText": "$O(n^2)$, for an already sorted array."
            },
            {
              "optionId": "ch_simple_sorting_3_q8_opt6",
              "optionText": "$O(n)$, for a reverse-sorted array."
            },
            {
              "optionId": "ch_simple_sorting_3_q8_opt7",
              "optionText": "When the input array is already sorted, each element only needs to be compared with the last element of the sorted portion (and no shifts occur)."
            },
            {
              "optionId": "ch_simple_sorting_3_q8_opt8",
              "optionText": "In the best case, the inner loop (shifting elements) executes at most once (for comparison) and performs no shifts."
            },
            {
              "optionId": "ch_simple_sorting_3_q8_opt9",
              "optionText": "$O(\\log n)$, for an array with many duplicate values."
            },
            {
              "optionId": "ch_simple_sorting_3_q8_opt10",
              "optionText": "The best case also occurs when all elements are identical."
            }
          ],
          "correctOptionIds": ["ch_simple_sorting_3_q8_opt2"],
          "explanationText": "The best-case time complexity for Insertion Sort is **$O(n)$, and this occurs when the input array is already sorted** (or nearly sorted, including when all elements are identical). In this scenario, when considering each element to insert, it only needs to be compared with the last element of the already sorted portion to confirm it's in the correct place, and no (or very few) shifts of elements are required. This results in approximately $n-1$ comparisons and no shifts, leading to linear time performance.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_simple_sorting_3_q9",
          "questionText": "What is the _primary reason_ why the standard Selection Sort algorithm is **not stable**?",
          "options": [
            {
              "optionId": "ch_simple_sorting_3_q9_opt1",
              "optionText": "It uses too many comparisons."
            },
            {
              "optionId": "ch_simple_sorting_3_q9_opt2",
              "optionText": "The inner loop always iterates through the entire unsorted portion."
            },
            {
              "optionId": "ch_simple_sorting_3_q9_opt3",
              "optionText": "Elements with equal keys might be swapped over long distances, changing their original relative order."
            },
            {
              "optionId": "ch_simple_sorting_3_q9_opt4",
              "optionText": "It is an in-place sorting algorithm."
            },
            {
              "optionId": "ch_simple_sorting_3_q9_opt5",
              "optionText": "It is not adaptive."
            },
            {
              "optionId": "ch_simple_sorting_3_q9_opt6",
              "optionText": "It only performs a limited number of swaps ($O(n)$ swaps)."
            },
            {
              "optionId": "ch_simple_sorting_3_q9_opt7",
              "optionText": "If an element `X` (equal to another element `Y`) is the minimum in the unsorted part, and `Y` is currently at the swap position, `X` might be swapped past `Y` if `X` was originally after `Y`."
            },
            {
              "optionId": "ch_simple_sorting_3_q9_opt8",
              "optionText": "It requires finding the absolute minimum in each pass."
            },
            {
              "optionId": "ch_simple_sorting_3_q9_opt9",
              "optionText": "It is difficult to implement correctly."
            },
            {
              "optionId": "ch_simple_sorting_3_q9_opt10",
              "optionText": "Its $O(n^2)$ complexity makes it unstable for large datasets."
            }
          ],
          "correctOptionIds": ["ch_simple_sorting_3_q9_opt3"],
          "explanationText": "Selection Sort is not stable primarily because **elements with equal keys might be swapped over long distances, potentially changing their original relative order**. When the algorithm finds the minimum element in the unsorted portion, it swaps this minimum with the element at the current first position of that unsorted portion. If the minimum element found was originally positioned after another element with the same key, this swap can move it before that other identical element, thus violating stability. For example, in `[3A, 2, 3B, 1]` (where 3A and 3B are equal but distinct items), if 3A is at index 0 and 3B is at index 2, and 1 is found as the minimum, swapping 1 with 3A changes the order. The next passes might also change the relative order of 3A and 3B.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_simple_sorting_3_q10",
          "questionText": "When implementing Selection Sort, the outer loop typically iterates from `i = 0` to `n-2` (not `n-1`). What is the _most direct reason_ this is sufficient?",
          "options": [
            {
              "optionId": "ch_simple_sorting_3_q10_opt1",
              "optionText": "To avoid an array index out of bounds error."
            },
            {
              "optionId": "ch_simple_sorting_3_q10_opt2",
              "optionText": "Because the last element `a[n-1]` is always the largest by default."
            },
            {
              "optionId": "ch_simple_sorting_3_q10_opt3",
              "optionText": "When the first `n-1` elements are sorted and in their correct places, the `n`-th (last) element must also be in its correct place."
            },
            {
              "optionId": "ch_simple_sorting_3_q10_opt4",
              "optionText": "It's an optimization that significantly improves its Big O complexity."
            },
            {
              "optionId": "ch_simple_sorting_3_q10_opt5",
              "optionText": "The inner loop handles finding the minimum for the `n-1` position."
            },
            {
              "optionId": "ch_simple_sorting_3_q10_opt6",
              "optionText": "This is only true for arrays with an even number of elements."
            },
            {
              "optionId": "ch_simple_sorting_3_q10_opt7",
              "optionText": "If all other $n-1$ elements are correctly placed, the final element has nowhere else to go but its correct sorted position."
            },
            {
              "optionId": "ch_simple_sorting_3_q10_opt8",
              "optionText": "Stopping at `n-2` makes the algorithm stable."
            },
            {
              "optionId": "ch_simple_sorting_3_q10_opt9",
              "optionText": "It's a common convention but iterating to `n-1` would also work, just with an unnecessary final pass."
            },
            {
              "optionId": "ch_simple_sorting_3_q10_opt10",
              "optionText": "The loop invariant ensures the last element is sorted by the time `i` reaches `n-2`."
            }
          ],
          "correctOptionIds": ["ch_simple_sorting_3_q10_opt3"],
          "explanationText": "The outer loop of Selection Sort iterates $n-1$ times. If it runs from `i = 0` to `n-2`, this covers $n-1$ iterations. The most direct reason this is sufficient is that **when the first $n-1$ elements have been selected and placed in their correct sorted positions, the $n$-th (and last) element must also be in its correct place**. There's no other position for it to go if the preceding $n-1$ elements are correctly sorted. Iterating the outer loop up to `n-1` would result in a final pass where the inner loop searches for the minimum in a subarray of size 1 (i.e., `a[n-1...n-1]`), which is trivial and unnecessary. This optimization saves one outer loop iteration but does not change the overall $O(n^2)$ complexity.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        }
      ],
      "totalQuestions": 10,
      "answeredQuestions": 0,
      "correctAnswers": 0,
      "isCompleted": false
    },
    {
      "id": "ch_exp_log_search_4",
      "name": "Chapter 4: Exponential, Logarithmic Time, and Binary Search",
      "description": "Delves into algorithms with exponential or logarithmic time complexities, with a focus on the Binary Search algorithm, its properties, and applications.",
      "questions": [
        {
          "questionId": "ch_exp_log_search_4_q1",
          "questionText": "Which statement _best describes the characteristic behavior_ of algorithms with logarithmic time complexity, such as $O(\\log n)$?",
          "options": [
            {
              "optionId": "ch_exp_log_search_4_q1_opt1",
              "optionText": "Logarithmic time complexity means the algorithm's runtime increases very slowly as the input size $n$ grows."
            },
            {
              "optionId": "ch_exp_log_search_4_q1_opt2",
              "optionText": "Algorithms with $O(\\log n)$ complexity typically divide the problem size by a constant factor at each step."
            },
            {
              "optionId": "ch_exp_log_search_4_q1_opt3",
              "optionText": "$O(\\log n)$ grows faster than $O(n)$."
            },
            {
              "optionId": "ch_exp_log_search_4_q1_opt4",
              "optionText": "$O(\\log n)$ grows slower than $O(1)$ (constant time)."
            },
            {
              "optionId": "ch_exp_log_search_4_q1_opt5",
              "optionText": "Binary search is a classic example of an algorithm with $O(\\log n)$ time complexity."
            },
            {
              "optionId": "ch_exp_log_search_4_q1_opt6",
              "optionText": "If an algorithm has $O(\\log n)$ complexity, doubling the input size $n$ roughly adds a constant amount of time to the execution."
            },
            {
              "optionId": "ch_exp_log_search_4_q1_opt7",
              "optionText": "$O(n \\log n)$ grows faster than $O(\\log n)$ but slower than $O(n^2)$."
            },
            {
              "optionId": "ch_exp_log_search_4_q1_opt8",
              "optionText": "The base of the logarithm (e.g., $\\log_2 n$, $\\log_{10} n$) significantly changes its Big O classification."
            },
            {
              "optionId": "ch_exp_log_search_4_q1_opt9",
              "optionText": "$O(\\log n)$ is considered highly efficient for large datasets."
            },
            {
              "optionId": "ch_exp_log_search_4_q1_opt10",
              "optionText": "An algorithm that processes each element of a tree level by level might exhibit logarithmic behavior if the tree is balanced."
            }
          ],
          "correctOptionIds": ["ch_exp_log_search_4_q1_opt1"],
          "explanationText": "The characteristic behavior of algorithms with $O(\\log n)$ complexity is that their **runtime increases very slowly as the input size $n$ grows**. This makes them highly efficient for large datasets. This slow growth is typically achieved because such algorithms divide the problem size by a constant factor at each step (e.g., binary search halves the search space). Consequently, doubling the input size only adds a constant amount of work. The base of the logarithm does not affect the Big O classification, as different bases only differ by a constant factor.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_exp_log_search_4_q2",
          "questionText": "Exponential time complexity, such as $O(2^n)$, signifies what about an algorithm's performance, _particularly for large inputs_?",
          "options": [
            {
              "optionId": "ch_exp_log_search_4_q2_opt1",
              "optionText": "The algorithm is generally considered very efficient for large $n$."
            },
            {
              "optionId": "ch_exp_log_search_4_q2_opt2",
              "optionText": "The algorithm's runtime roughly doubles with each single increment in input size $n$ (for base 2 exponential)."
            },
            {
              "optionId": "ch_exp_log_search_4_q2_opt3",
              "optionText": "It is often associated with brute-force algorithms that explore all possible combinations or subsets (e.g., $2^n$ subsets)."
            },
            {
              "optionId": "ch_exp_log_search_4_q2_opt4",
              "optionText": "$O(2^n)$ grows slower than $O(n!)$."
            },
            {
              "optionId": "ch_exp_log_search_4_q2_opt5",
              "optionText": "Problems solvable in $O(2^n)$ time are generally considered intractable for anything but small $n$."
            },
            {
              "optionId": "ch_exp_log_search_4_q2_opt6",
              "optionText": "Polynomial time algorithms, like $O(n^k)$ for a fixed $k$, are always faster than $O(2^n)$ for sufficiently large $n$."
            },
            {
              "optionId": "ch_exp_log_search_4_q2_opt7",
              "optionText": "The Satisfiability (SAT) problem for $n$ variables has a naive brute-force solution of $O(n \\cdot 2^n)$."
            },
            {
              "optionId": "ch_exp_log_search_4_q2_opt8",
              "optionText": "$O(k^n)$ for a constant $k > 1$ is also an exponential time complexity."
            },
            {
              "optionId": "ch_exp_log_search_4_q2_opt9",
              "optionText": "Finding all subsets of a set of $n$ elements can lead to $O(2^n)$ behavior due to the number of subsets."
            },
            {
              "optionId": "ch_exp_log_search_4_q2_opt10",
              "optionText": "$O(2^n)$ is a type of polynomial time complexity."
            }
          ],
          "correctOptionIds": ["ch_exp_log_search_4_q2_opt5"],
          "explanationText": "Exponential time complexity, such as $O(2^n)$ or $O(k^n)$ for $k>1$, signifies that **problems solvable in such time are generally considered intractable for anything but small input sizes $n$**. This is because the runtime grows extremely rapidly; for instance, with $O(2^n)$, each increment in $n$ can roughly double the runtime. Such complexities often arise from brute-force approaches that explore an exponentially large number of possibilities (e.g., all subsets of a set, all truth assignments for SAT). For large $n$, polynomial algorithms are always significantly faster.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_exp_log_search_4_q3",
          "questionText": "Which of the following is the _most critical precondition_ for the Binary Search algorithm to function correctly and achieve its efficiency?",
          "options": [
            {
              "optionId": "ch_exp_log_search_4_q3_opt1",
              "optionText": "It compares the target key with every element in the array sequentially."
            },
            {
              "optionId": "ch_exp_log_search_4_q3_opt2",
              "optionText": "It requires the input array to be sorted."
            },
            {
              "optionId": "ch_exp_log_search_4_q3_opt3",
              "optionText": "In each step, it divides the search space (the portion of the array where the key might be) approximately in half."
            },
            {
              "optionId": "ch_exp_log_search_4_q3_opt4",
              "optionText": "It uses a hash function to directly locate the element."
            },
            {
              "optionId": "ch_exp_log_search_4_q3_opt5",
              "optionText": "It compares the target key with the middle element of the current search space."
            },
            {
              "optionId": "ch_exp_log_search_4_q3_opt6",
              "optionText": "Based on the comparison, it eliminates the half of the search space where the key cannot possibly lie."
            },
            {
              "optionId": "ch_exp_log_search_4_q3_opt7",
              "optionText": "Its worst-case time complexity is $O(n)$."
            },
            {
              "optionId": "ch_exp_log_search_4_q3_opt8",
              "optionText": "It can efficiently find elements in an unsorted array."
            },
            {
              "optionId": "ch_exp_log_search_4_q3_opt9",
              "optionText": "It involves swapping elements to bring the target key to the middle."
            },
            {
              "optionId": "ch_exp_log_search_4_q3_opt10",
              "optionText": "Its space complexity is $O(\\log n)$ due to recursive calls in a naive implementation."
            }
          ],
          "correctOptionIds": ["ch_exp_log_search_4_q3_opt2"],
          "explanationText": "The most critical precondition for Binary Search is that **it requires the input array to be sorted**. This sorted property allows the algorithm to, in each step, compare the target key with the middle element of the current search space and then eliminate half of that space based on whether the target is smaller or larger than the middle element. Without a sorted array, this elimination strategy would not be valid, and binary search could not guarantee finding the element or achieve its $O(\\log n)$ efficiency.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_exp_log_search_4_q4",
          "questionText": "What is the _fundamental reason_ why the time complexity of Binary Search is $O(\\log n)$?",
          "options": [
            {
              "optionId": "ch_exp_log_search_4_q4_opt1",
              "optionText": "Because it performs $\\log n$ comparisons in the best case."
            },
            {
              "optionId": "ch_exp_log_search_4_q4_opt2",
              "optionText": "Because at each step, the size of the problem (the search interval) is reduced by approximately half."
            },
            {
              "optionId": "ch_exp_log_search_4_q4_opt3",
              "optionText": "If the array has $n$ elements, after $k$ steps, the search space is roughly $n/2^k$. The search stops when $n/2^k \\approx 1$."
            },
            {
              "optionId": "ch_exp_log_search_4_q4_opt4",
              "optionText": "Solving $n/2^k = 1$ for $k$ gives $2^k = n$, so $k = \\log_2 n$."
            },
            {
              "optionId": "ch_exp_log_search_4_q4_opt5",
              "optionText": "Because it uses a logarithmic amount of extra memory."
            },
            {
              "optionId": "ch_exp_log_search_4_q4_opt6",
              "optionText": "Because it only works on arrays whose size $n$ is a power of 2."
            },
            {
              "optionId": "ch_exp_log_search_4_q4_opt7",
              "optionText": "It involves a loop that runs, in the worst case, a number of times proportional to $\\log n$."
            },
            {
              "optionId": "ch_exp_log_search_4_q4_opt8",
              "optionText": "The number of comparisons in the worst case is proportional to $\\log_2 n$."
            },
            {
              "optionId": "ch_exp_log_search_4_q4_opt9",
              "optionText": "The logarithm reflects the number of times you can halve $n$ until you reach 1."
            },
            {
              "optionId": "ch_exp_log_search_4_q4_opt10",
              "optionText": "Because it is faster than linear search which is $O(n)$."
            }
          ],
          "correctOptionIds": ["ch_exp_log_search_4_q4_opt2"],
          "explanationText": "The fundamental reason for Binary Search's $O(\\log n)$ time complexity is that **at each step, the size of the problem (the search interval) is reduced by approximately half**. This repeated halving means that the number of steps ($k$) required to reduce the search space from $n$ elements down to 1 (or 0) is such that $n/2^k \\approx 1$, which implies $2^k \\approx n$, or $k \\approx \\log_2 n$. Thus, the number of operations is proportional to the logarithm of the input size. The best case for binary search is $O(1)$ (if the element is found at the very first middle check).",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_exp_log_search_4_q5",
          "questionText": "Consider the array `A = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]`. If you perform a Binary Search for the key `35` (which is not present), what is the _value of the last element examined_ by `A[mid]` before the search concludes that the key is not found? (Assume `mid = floor((lo+hi)/2)`, 0-based indexing).",
          "options": [
            {
              "optionId": "ch_exp_log_search_4_q5_opt1",
              "optionText": "`A[mid] = 50`"
            },
            {
              "optionId": "ch_exp_log_search_4_q5_opt2",
              "optionText": "`A[mid] = 20`"
            },
            {
              "optionId": "ch_exp_log_search_4_q5_opt3",
              "optionText": "`A[mid] = 30`"
            },
            {
              "optionId": "ch_exp_log_search_4_q5_opt4",
              "optionText": "`A[mid] = 40`"
            },
            {
              "optionId": "ch_exp_log_search_4_q5_opt5",
              "optionText": "The search examines `A[4]=50`, then `A[1]=20`, then `A[2]=30`, then `A[3]=40`."
            },
            {
              "optionId": "ch_exp_log_search_4_q5_opt6",
              "optionText": "The search concludes when `lo` becomes greater than `hi`."
            },
            {
              "optionId": "ch_exp_log_search_4_q5_opt7",
              "optionText": "The value `A[mid] = 10` is examined."
            },
            {
              "optionId": "ch_exp_log_search_4_q5_opt8",
              "optionText": "The value `A[mid] = 60` is examined."
            },
            {
              "optionId": "ch_exp_log_search_4_q5_opt9",
              "optionText": "The key 35 is found at index 2.5."
            },
            {
              "optionId": "ch_exp_log_search_4_q5_opt10",
              "optionText": "The search never examines A[2]=30."
            }
          ],
          "correctOptionIds": ["ch_exp_log_search_4_q5_opt4"],
          "explanationText": "Tracing Binary Search for key 35 in `A = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]` (indices 0-9):\n1. $lo=0, hi=9 \\rightarrow mid=(0+9)//2 = 4$. $A[4]=50$. (Since $35 < 50$, set $hi=mid-1=3$)\n2. $lo=0, hi=3 \\rightarrow mid=(0+3)//2 = 1$. $A[1]=20$. (Since $35 > 20$, set $lo=mid+1=2$)\n3. $lo=2, hi=3 \\rightarrow mid=(2+3)//2 = 2$. $A[2]=30$. (Since $35 > 30$, set $lo=mid+1=3$)\n4. $lo=3, hi=3 \\rightarrow mid=(3+3)//2 = 3$. $A[3]=40$. (Since $35 < 40$, set $hi=mid-1=2$)\nNow, $lo=3$ and $hi=2$. Since $lo > hi$, the loop terminates and the key 35 is not found. The last element examined by $A[mid]$ was **$A[3]=40$**.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_exp_log_search_4_q6",
          "questionText": "Which of the following problems is a classic example known for often having naive brute-force solutions with $O(2^n)$ complexity due to exploring all subsets or combinations of $n$ items?",
          "options": [
            {
              "optionId": "ch_exp_log_search_4_q6_opt1",
              "optionText": "Sorting an array of $n$ elements using Mergesort."
            },
            {
              "optionId": "ch_exp_log_search_4_q6_opt2",
              "optionText": "The Boolean Satisfiability Problem (SAT) when considering only 2 variables."
            },
            {
              "optionId": "ch_exp_log_search_4_q6_opt3",
              "optionText": "The Subset Sum Problem by checking all $2^n$ possible subsets of $n$ numbers."
            },
            {
              "optionId": "ch_exp_log_search_4_q6_opt4",
              "optionText": "Searching for an element in a sorted array using Binary Search."
            },
            {
              "optionId": "ch_exp_log_search_4_q6_opt5",
              "optionText": "The Traveling Salesperson Problem (TSP) by checking all $n^2$ pairs of cities."
            },
            {
              "optionId": "ch_exp_log_search_4_q6_opt6",
              "optionText": "Finding the maximum element in an unsorted array."
            },
            {
              "optionId": "ch_exp_log_search_4_q6_opt7",
              "optionText": "Multiplying two $n \\times n$ matrices using the standard algorithm."
            },
            {
              "optionId": "ch_exp_log_search_4_q6_opt8",
              "optionText": "Generating all permutations of $n$ items (which has $O(n!)$ complexity)."
            },
            {
              "optionId": "ch_exp_log_search_4_q6_opt9",
              "optionText": "The Knapsack problem (0-1 variant) by using dynamic programming."
            },
            {
              "optionId": "ch_exp_log_search_4_q6_opt10",
              "optionText": "Calculating $n$-th Fibonacci number using iteration."
            }
          ],
          "correctOptionIds": ["ch_exp_log_search_4_q6_opt3"],
          "explanationText": "The **Subset Sum Problem** is a classic example where a naive brute-force solution involves checking all $2^n$ possible subsets of $n$ numbers, leading to an $O(2^n)$ time complexity. Other problems like SAT and the 0-1 Knapsack problem also have similar naive exponential solutions due to exploring all combinations. Mergesort, Binary Search, finding max, and standard matrix multiplication have polynomial complexities. Naive TSP is $O(n!)$, and dynamic programming or iterative Fibonacci are more efficient than brute-force exponential approaches for those specific problems.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_exp_log_search_4_q7",
          "questionText": "If an algorithm has $O(n)$ time complexity and another has $O(\\log n)$ complexity, what is the approximate number of operations the $O(\\log n)$ algorithm would perform if $n = 1,000,000$ (assuming $\\log$ is base 2 and ignoring constant factors)?",
          "options": [
            {
              "optionId": "ch_exp_log_search_4_q7_opt1",
              "optionText": "Operations proportional to 1,000,000."
            },
            {
              "optionId": "ch_exp_log_search_4_q7_opt2",
              "optionText": "Operations proportional to $\\log_2(1,000,000) \\approx 20$."
            },
            {
              "optionId": "ch_exp_log_search_4_q7_opt3",
              "optionText": "The $O(\\log n)$ algorithm will be significantly faster."
            },
            {
              "optionId": "ch_exp_log_search_4_q7_opt4",
              "optionText": "The $O(n)$ algorithm will be slightly faster due to simpler logic."
            },
            {
              "optionId": "ch_exp_log_search_4_q7_opt5",
              "optionText": "Their performance will be roughly comparable for this input size."
            },
            {
              "optionId": "ch_exp_log_search_4_q7_opt6",
              "optionText": "The difference in the order of magnitude of operations is approximately $1,000,000$ versus $20$ (ignoring constant factors)."
            },
            {
              "optionId": "ch_exp_log_search_4_q7_opt7",
              "optionText": "The $O(\\log n)$ algorithm is roughly 50,000 times faster ($1,000,000 / 20$) in terms of operation counts."
            },
            {
              "optionId": "ch_exp_log_search_4_q7_opt8",
              "optionText": "The actual time difference depends heavily on the constant factors hidden by Big O."
            },
            {
              "optionId": "ch_exp_log_search_4_q7_opt9",
              "optionText": "$O(n)$ is linear, $O(\\log n)$ is logarithmic."
            },
            {
              "optionId": "ch_exp_log_search_4_q7_opt10",
              "optionText": "Both are considered efficient polynomial time algorithms."
            }
          ],
          "correctOptionIds": ["ch_exp_log_search_4_q7_opt2"],
          "explanationText": "For an input size $n = 1,000,000$:<br>An $O(n)$ algorithm will perform operations proportional to 1,000,000.<br>An $O(\\log n)$ algorithm (assuming base 2 logarithm, common in computer science) will perform operations proportional to $\\log_2(1,000,000)$. Since $2^{10} = 1024 \\approx 10^3$, then $2^{20} = (2^{10})^2 \\approx (10^3)^2 = 10^6 = 1,000,000$. So, $\\log_2(1,000,000)$ is approximately 20. Thus, the $O(\\log n)$ algorithm performs operations proportional to roughly **20**. This highlights the significant efficiency of logarithmic algorithms for large inputs compared to linear ones.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_exp_log_search_4_q8",
          "questionText": "A common loop invariant for iterative Binary Search includes the condition that if the `key` exists in the original array, it must currently reside within the search interval `a[lo..hi]`. What is the _primary purpose_ of maintaining this specific part of the invariant?",
          "options": [
            {
              "optionId": "ch_exp_log_search_4_q8_opt1",
              "optionText": "That the array `a` remains sorted throughout the search."
            },
            {
              "optionId": "ch_exp_log_search_4_q8_opt2",
              "optionText": "That the loop will always terminate in $O(\\log n)$ steps."
            },
            {
              "optionId": "ch_exp_log_search_4_q8_opt3",
              "optionText": "To ensure that if the `key` is in the original array, it is always confined to the current search interval `a[lo..hi]`, preventing its accidental exclusion."
            },
            {
              "optionId": "ch_exp_log_search_4_q8_opt4",
              "optionText": "That `lo` is always less than or equal to `hi` during the active search."
            },
            {
              "optionId": "ch_exp_log_search_4_q8_opt5",
              "optionText": "That the `mid` point is always calculated correctly."
            },
            {
              "optionId": "ch_exp_log_search_4_q8_opt6",
              "optionText": "The partial correctness of the algorithm: if the loop terminates, the outcome (key found/not found) is correct based on whether the key was in the initial valid search space."
            },
            {
              "optionId": "ch_exp_log_search_4_q8_opt7",
              "optionText": "The part `a[0..lo-1] < key` confirms all elements before the current window are correctly eliminated as too small."
            },
            {
              "optionId": "ch_exp_log_search_4_q8_opt8",
              "optionText": "The part `key < a[hi+1..n-1]` confirms all elements after the current window are correctly eliminated as too large."
            },
            {
              "optionId": "ch_exp_log_search_4_q8_opt9",
              "optionText": "It helps in proving that the search space is correctly narrowed down in each iteration."
            },
            {
              "optionId": "ch_exp_log_search_4_q8_opt10",
              "optionText": "It guarantees that `lo` and `hi` remain valid array indices when accessing `a[mid]`."
            }
          ],
          "correctOptionIds": ["ch_exp_log_search_4_q8_opt3"],
          "explanationText": "The primary purpose of the invariant part 'if the `key` is in the original array, it must be within the current search interval `a[lo..hi]`' is **to ensure that the target key, if present, is never accidentally discarded as the search space is narrowed**. This invariant, along with the correct narrowing of `lo` and `hi` based on comparisons, underpins the algorithm's correctness. If this invariant holds and the loop terminates (e.g., because `lo > hi` and the key wasn't found at `a[mid]`), it means the key was not in the original array. It's a core component of proving partial correctness and that the search space is correctly reduced.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_exp_log_search_4_q9",
          "questionText": "When comparing $O(n^k)$ (polynomial for fixed $k>0$) and $O(c^n)$ (exponential, for fixed $c>1$) complexities, which statement _most accurately describes their relationship_ for sufficiently large $n$?",
          "options": [
            {
              "optionId": "ch_exp_log_search_4_q9_opt1",
              "optionText": "$O(n^k)$ always grows faster than $O(c^n)$."
            },
            {
              "optionId": "ch_exp_log_search_4_q9_opt2",
              "optionText": "$O(c^n)$ always grows faster than $O(n^k)$."
            },
            {
              "optionId": "ch_exp_log_search_4_q9_opt3",
              "optionText": "For small $n$, $n^k$ might be larger than $c^n$ depending on $k, c,$ and hidden constant factors."
            },
            {
              "optionId": "ch_exp_log_search_4_q9_opt4",
              "optionText": "$n^{100}$ is asymptotically slower growing (i.e. more efficient for large n) than $1.01^n$."
            },
            {
              "optionId": "ch_exp_log_search_4_q9_opt5",
              "optionText": "An algorithm with $O(c^n)$ complexity is generally preferred over one with $O(n^k)$ complexity if $k$ is very large (e.g., $k=100$)."
            },
            {
              "optionId": "ch_exp_log_search_4_q9_opt6",
              "optionText": "The function $n^2$ grows slower than $2^n$."
            },
            {
              "optionId": "ch_exp_log_search_4_q9_opt7",
              "optionText": "The function $n^{10}$ grows slower than $1.1^n$ for large $n$."
            },
            {
              "optionId": "ch_exp_log_search_4_q9_opt8",
              "optionText": "Logarithmic factors do not change this relationship; e.g., $n^k \\log n$ is still asymptotically slower growing than $c^n$."
            },
            {
              "optionId": "ch_exp_log_search_4_q9_opt9",
              "optionText": "Polynomial time is considered 'tractable', while exponential time is generally 'intractable' for large $n$."
            },
            {
              "optionId": "ch_exp_log_search_4_q9_opt10",
              "optionText": "$1000n^3$ is asymptotically faster growing (less efficient) than $2^{n/100}$."
            }
          ],
          "correctOptionIds": ["ch_exp_log_search_4_q9_opt2"],
          "explanationText": "For sufficiently large $n$, **any exponential function $O(c^n)$ (where $c > 1$) will always grow faster than any polynomial function $O(n^k)$ (where $k > 0$)**. This is a fundamental result in the analysis of algorithms. This means that algorithms with polynomial complexity are asymptotically much more efficient than those with exponential complexity. Even if $k$ is very large (e.g., $n^{100}$) and $c$ is only slightly greater than 1 (e.g., $1.01^n$), the exponential function will eventually dominate. Logarithmic factors do not alter this essential relationship (e.g., $n^k \\log n$ still grows slower than $c^n$). Because of this, polynomial time is generally considered 'tractable', while exponential time is 'intractable' for large inputs.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_exp_log_search_4_q10",
          "questionText": "A variation of binary search (often called `AltBinarySearch` or 'binary search for insertion point') omits the equality test (`a[mid] == key`) inside the main loop. What is a _primary advantage_ of this variant?",
          "options": [
            {
              "optionId": "ch_exp_log_search_4_q10_opt1",
              "optionText": "It makes the algorithm significantly faster by reducing comparisons overall."
            },
            {
              "optionId": "ch_exp_log_search_4_q10_opt2",
              "optionText": "The loop always runs for the maximum number of iterations ($\\approx \\log n$), even if an element matching the key could have been found earlier."
            },
            {
              "optionId": "ch_exp_log_search_4_q10_opt3",
              "optionText": "Upon termination, the loop index (e.g., `lo`) directly indicates the correct insertion point for the key to maintain sorted order, regardless of whether the key was found."
            },
            {
              "optionId": "ch_exp_log_search_4_q10_opt4",
              "optionText": "It cannot find the key if it is present in the array because it never checks for equality."
            },
            {
              "optionId": "ch_exp_log_search_4_q10_opt5",
              "optionText": "It simplifies the loop body to typically involve only one comparison (e.g., `a[mid] < key` or `a[mid] <= key`) to decide which half to discard."
            },
            {
              "optionId": "ch_exp_log_search_4_q10_opt6",
              "optionText": "The standard binary search (with an equality test) can terminate earlier if the key is found in the middle, potentially making it faster on average for successful searches when only presence is needed."
            },
            {
              "optionId": "ch_exp_log_search_4_q10_opt7",
              "optionText": "This variant is particularly useful for finding the first or last occurrence of a key in an array with duplicates, or for finding the smallest element greater than the key."
            },
            {
              "optionId": "ch_exp_log_search_4_q10_opt8",
              "optionText": "Its worst-case time complexity remains $O(\\log n)$."
            },
            {
              "optionId": "ch_exp_log_search_4_q10_opt9",
              "optionText": "The invariant used for this variant usually ensures that the key, if present, is always between `lo` and `hi`, and the loop continues until `lo` and `hi` converge or cross."
            },
            {
              "optionId": "ch_exp_log_search_4_q10_opt10",
              "optionText": "It is more complex to implement than the standard binary search."
            }
          ],
          "correctOptionIds": ["ch_exp_log_search_4_q10_opt3"],
          "explanationText": "A primary advantage of the binary search variant that omits the equality test within the loop is that **upon termination, the loop index (often `lo` or `low`) directly indicates the correct insertion point for the key to maintain sorted order**. This is useful whether the key was originally present or not. The loop typically runs for the full $\\approx \\log n$ iterations, narrowing the search interval [lo..hi] until it identifies a single position. After the loop, a separate check can be made at `a[lo]` (if `lo` is a valid index) to see if the key is actually present. This variant is particularly useful for tasks like finding the first/last occurrence of an element or finding the position for insertion, making it more versatile than a simple presence check.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        }
      ],
      "totalQuestions": 10,
      "answeredQuestions": 0,
      "correctAnswers": 0,
      "isCompleted": false
    },
    {
      "id": "ch_recursion_5",
      "name": "Chapter 5: Recursive Algorithms",
      "description": "Covers the principles of recursion, base cases, recursive steps, the role of the call stack, and the divide-and-conquer strategy with examples.",
      "questions": [
        {
          "questionId": "ch_recursion_5_q1",
          "questionText": "Which essential component of a recursive algorithm defines the condition under which the algorithm ceases further recursive calls and solves a subproblem directly?",
          "options": [
            {
              "optionId": "ch_recursion_5_q1_opt1",
              "optionText": "A **base case(s)**"
            },
            {
              "optionId": "ch_recursion_5_q1_opt2",
              "optionText": "A **recursive step(s)**"
            },
            {
              "optionId": "ch_recursion_5_q1_opt3",
              "optionText": "A loop structure (e.g., `WHILE` or `FOR`)."
            },
            {
              "optionId": "ch_recursion_5_q1_opt4",
              "optionText": "The use of global variables to store state between calls."
            },
            {
              "optionId": "ch_recursion_5_q1_opt5",
              "optionText": "A mechanism for combining results from recursive calls."
            },
            {
              "optionId": "ch_recursion_5_q1_opt6",
              "optionText": "An explicit check for stack overflow."
            },
            {
              "optionId": "ch_recursion_5_q1_opt7",
              "optionText": "Memoization to store results of subproblems."
            },
            {
              "optionId": "ch_recursion_5_q1_opt8",
              "optionText": "The problem must be divisible into smaller, independent subproblems."
            },
            {
              "optionId": "ch_recursion_5_q1_opt9",
              "optionText": "At least two recursive calls in the recursive step for efficiency."
            },
            {
              "optionId": "ch_recursion_5_q1_opt10",
              "optionText": "Parameter modification to ensure progress."
            }
          ],
          "correctOptionIds": ["ch_recursion_5_q1_opt1"],
          "explanationText": "The essential component of a recursive algorithm that defines the condition for stopping further recursion and solving a subproblem directly is the **base case(s)**. Without a base case, a recursive algorithm would continue calling itself indefinitely (or until a stack overflow). The recursive step, conversely, is where the algorithm calls itself with a modified input that progresses towards a base case.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_recursion_5_q2",
          "questionText": "Which of the following statements _best describes what is stored in an activation record (or stack frame)_ during a recursive function call?",
          "options": [
            {
              "optionId": "ch_recursion_5_q2_opt1",
              "optionText": "It stores the input array being processed by the recursive function."
            },
            {
              "optionId": "ch_recursion_5_q2_opt2",
              "optionText": "For each active function call (including recursive calls), an **activation record** (or stack frame) is pushed onto the stack."
            },
            {
              "optionId": "ch_recursion_5_q2_opt3",
              "optionText": "The activation record typically stores parameters, local variables, and the return address for that specific call."
            },
            {
              "optionId": "ch_recursion_5_q2_opt4",
              "optionText": "When a function call returns, its activation record is popped off the stack, and control returns to the caller."
            },
            {
              "optionId": "ch_recursion_5_q2_opt5",
              "optionText": "It is used to implement loops in recursive languages."
            },
            {
              "optionId": "ch_recursion_5_q2_opt6",
              "optionText": "The size of the call stack is always constant, regardless of recursion depth."
            },
            {
              "optionId": "ch_recursion_5_q2_opt7",
              "optionText": "It primarily manages heap memory allocation for recursive objects."
            },
            {
              "optionId": "ch_recursion_5_q2_opt8",
              "optionText": "A **stack overflow error** can occur if the recursion depth becomes too large, exceeding the stack's capacity."
            },
            {
              "optionId": "ch_recursion_5_q2_opt9",
              "optionText": "Tail call optimization can eliminate the need for new stack frames in some recursive calls."
            },
            {
              "optionId": "ch_recursion_5_q2_opt10",
              "optionText": "It ensures that recursive functions are always more space-efficient than iterative ones."
            }
          ],
          "correctOptionIds": ["ch_recursion_5_q2_opt3"],
          "explanationText": "During a recursive function call, an activation record (or stack frame) is created for that specific call. This record is crucial for managing the execution context of the call. The statement that **the activation record typically stores parameters, local variables, and the return address for that specific call** best describes its contents. This allows each instance of the recursive function to have its own set of variables and to know where to return control once it finishes. While it is true that an activation record is pushed onto the stack for each call (as mentioned in another option) and that stack overflow can occur (another option), the question asks what _best describes what is stored_.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_recursion_5_q3",
          "questionText": "Consider the recursive algorithm for calculating $x^k$:<br>`Power(x, k):`<br>`  IF k \\le 0 THEN RETURN 1`<br>`  ELSE RETURN x * Power(x, k-1)`<br>What is the space complexity of this algorithm due to the call stack?",
          "options": [
            {
              "optionId": "ch_recursion_5_q3_opt1",
              "optionText": "$O(1)$, because it only uses a few variables."
            },
            {
              "optionId": "ch_recursion_5_q3_opt2",
              "optionText": "$O(k)$, because there will be approximately $k$ recursive calls on the stack in the deepest case."
            },
            {
              "optionId": "ch_recursion_5_q3_opt3",
              "optionText": "$O(\\log k)$, because the problem size is reduced logarithmically."
            },
            {
              "optionId": "ch_recursion_5_q3_opt4",
              "optionText": "$O(x^k)$, because that's the value being computed."
            },
            {
              "optionId": "ch_recursion_5_q3_opt5",
              "optionText": "$O(k^2)$, due to nested multiplications."
            },
            {
              "optionId": "ch_recursion_5_q3_opt6",
              "optionText": "Each recursive call adds one activation record to the stack."
            },
            {
              "optionId": "ch_recursion_5_q3_opt7",
              "optionText": "The maximum depth of recursion is $k$ (when $k$ reaches 0)."
            },
            {
              "optionId": "ch_recursion_5_q3_opt8",
              "optionText": "This particular recursive structure is not tail-recursive because a multiplication happens after the recursive call returns."
            },
            {
              "optionId": "ch_recursion_5_q3_opt9",
              "optionText": "The `IterativePower` version would have $O(1)$ space complexity."
            },
            {
              "optionId": "ch_recursion_5_q3_opt10",
              "optionText": "$O(k \\log x)$."
            }
          ],
          "correctOptionIds": ["ch_recursion_5_q3_opt2"],
          "explanationText": "The space complexity of this recursive `Power(x, k)` algorithm, due to the call stack, is **$O(k)$__. This is because each call to `Power(x, k-1)` makes a new recursive call, adding an activation record to the call stack. This continues until $k$ is reduced to 0. Thus, in the worst case (for $k > 0$), there will be approximately $k$ activation records on the stack simultaneously. This particular recursive structure is not tail-recursive because the multiplication `x _ ...` occurs _after_ the recursive call returns, meaning the current stack frame cannot be reused. An iterative version would typically have $O(1)$ space complexity.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_recursion_5_q4",
          "questionText": "When tracing `FastPower(x=2, k=5)` using the algorithm:<br>`IF k = 0 THEN RETURN 1`<br>`y ← FastPower(x, k DIV 2)`<br>`IF k is even THEN RETURN y_y`<br>`ELSE RETURN y_y_x`<br>What is the _final computed result* of `FastPower(2,5)`?",
          "options": [
            {
              "optionId": "ch_recursion_5_q4_opt1",
              "optionText": "The innermost `y` is result of `FastPower(2,0)` which is 1."
            },
            {
              "optionId": "ch_recursion_5_q4_opt2",
              "optionText": "The value of `y` in the frame for `k=1` becomes 1."
            },
            {
              "optionId": "ch_recursion_5_q4_opt3",
              "optionText": "The value of `y` in the frame for `k=2` becomes 2."
            },
            {
              "optionId": "ch_recursion_5_q4_opt4",
              "optionText": "The value of `y` in the frame for `k=5` becomes 4."
            },
            {
              "optionId": "ch_recursion_5_q4_opt5",
              "optionText": "The sequence of `k` in calls is $5 \\rightarrow 2 \\rightarrow 1 \\rightarrow 0$."
            },
            {
              "optionId": "ch_recursion_5_q4_opt6",
              "optionText": "The call sequence is `FP(2,5)` then `FP(2,2)` then `FP(2,1)` then `FP(2,0)`."
            },
            {
              "optionId": "ch_recursion_5_q4_opt7",
              "optionText": "The result returned from `FP(2,2)` is $2 \\cdot 2 = 4$."
            },
            {
              "optionId": "ch_recursion_5_q4_opt8",
              "optionText": "The final result computed by `FastPower(2,5)` is 32."
            },
            {
              "optionId": "ch_recursion_5_q4_opt9",
              "optionText": "The sequence of values assigned to `y` across returning frames is $1, 2, 4$."
            },
            {
              "optionId": "ch_recursion_5_q4_opt10",
              "optionText": "The result returned from `FP(2,1)` is $1 \\cdot 1 \\cdot 2 = 2$."
            }
          ],
          "correctOptionIds": ["ch_recursion_5_q4_opt8"],
          "explanationText": "Tracing `FastPower(2, 5)`:<br>1. `FastPower(2,5)` calls `FastPower(2, 5 DIV 2)` which is `FastPower(2,2)`.<br>2. `FastPower(2,2)` calls `FastPower(2, 2 DIV 2)` which is `FastPower(2,1)`.<br>3. `FastPower(2,1)` calls `FastPower(2, 1 DIV 2)` which is `FastPower(2,0)`.<br>4. `FastPower(2,0)` is a base case and returns 1.<br>5. In `FastPower(2,1)`, `y` becomes 1. Since $k=1$ is odd, it returns $y \\cdot y \\cdot x = 1 \\cdot 1 \\cdot 2 = 2$.<br>6. In `FastPower(2,2)`, `y` becomes 2. Since $k=2$ is even, it returns $y \\cdot y = 2 \\cdot 2 = 4$.<br>7. In `FastPower(2,5)`, `y` becomes 4. Since $k=5$ is odd, it returns $y \\cdot y \\cdot x = 4 \\cdot 4 \\cdot 2 = 32$.<br>Thus, the final computed result is **32**.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_recursion_5_q5",
          "questionText": "The **Divide-and-Conquer** strategy is a powerful algorithmic paradigm. Which of the following options _best describes the 'Divide' step_ in this strategy?",
          "options": [
            {
              "optionId": "ch_recursion_5_q5_opt1",
              "optionText": "**Divide**: Break the problem into several smaller, independent subproblems of the same type."
            },
            {
              "optionId": "ch_recursion_5_q5_opt2",
              "optionText": "**Conquer**: Solve the subproblems recursively. If subproblems are small enough, solve them directly (base case)."
            },
            {
              "optionId": "ch_recursion_5_q5_opt3",
              "optionText": "**Combine**: Combine the solutions of the subproblems to form the solution to the original problem."
            },
            {
              "optionId": "ch_recursion_5_q5_opt4",
              "optionText": "**Iterate**: Use a loop to process each subproblem sequentially."
            },
            {
              "optionId": "ch_recursion_5_q5_opt5",
              "optionText": "**Memoize**: Store the results of subproblems to avoid recomputation."
            },
            {
              "optionId": "ch_recursion_5_q5_opt6",
              "optionText": "**Greedy Choice**: Make a locally optimal choice at each step."
            },
            {
              "optionId": "ch_recursion_5_q5_opt7",
              "optionText": "Mergesort and Quicksort are classic examples of divide-and-conquer algorithms."
            },
            {
              "optionId": "ch_recursion_5_q5_opt8",
              "optionText": "The efficiency often comes from the 'divide' step being cheap and the 'combine' step also being relatively efficient."
            },
            {
              "optionId": "ch_recursion_5_q5_opt9",
              "optionText": "The subproblems must overlap significantly for this strategy to be effective."
            },
            {
              "optionId": "ch_recursion_5_q5_opt10",
              "optionText": "The 'conquer' step always involves exactly two recursive calls."
            }
          ],
          "correctOptionIds": ["ch_recursion_5_q5_opt1"],
          "explanationText": "The Divide-and-Conquer strategy consists of three general steps. The 'Divide' step involves **breaking the original problem into several smaller, ideally independent, subproblems of the same type as the original problem**. The 'Conquer' step involves solving these subproblems, usually recursively, until they become simple enough to solve directly (base case). Finally, the 'Combine' step merges the solutions of the subproblems to form the solution to the original problem. Mergesort and Quicksort are classic examples.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_recursion_5_q6",
          "questionText": "What is the _defining characteristic_ of a **tail-recursive** call within a function?",
          "options": [
            {
              "optionId": "ch_recursion_5_q6_opt1",
              "optionText": "A recursive call that occurs as the very last operation in a function, where its result is immediately returned without further computation by the calling frame."
            },
            {
              "optionId": "ch_recursion_5_q6_opt2",
              "optionText": "A recursive function that has no base case."
            },
            {
              "optionId": "ch_recursion_5_q6_opt3",
              "optionText": "Compilers can often optimize tail-recursive calls into iterative loops, effectively reusing the current stack frame (Tail Call Optimization - TCO)."
            },
            {
              "optionId": "ch_recursion_5_q6_opt4",
              "optionText": "This optimization (TCO) can prevent stack overflow errors for deep tail recursions by avoiding new stack frame allocation for each tail call."
            },
            {
              "optionId": "ch_recursion_5_q6_opt5",
              "optionText": "All recursive functions are tail-recursive."
            },
            {
              "optionId": "ch_recursion_5_q6_opt6",
              "optionText": "The function `Power(x, k) { ... RETURN x * Power(x, k-1); }` is tail-recursive."
            },
            {
              "optionId": "ch_recursion_5_q6_opt7",
              "optionText": "A function like `factorial(n) { ... return n * factorial(n-1); }` is not tail-recursive because of the multiplication after the recursive call returns."
            },
            {
              "optionId": "ch_recursion_5_q6_opt8",
              "optionText": "Tail recursion always leads to $O(1)$ space complexity in all programming languages."
            },
            {
              "optionId": "ch_recursion_5_q6_opt9",
              "optionText": "Java compilers are required by the language specification to perform tail call optimization."
            },
            {
              "optionId": "ch_recursion_5_q6_opt10",
              "optionText": "It is a recursive call made to the 'tail' or last element of a data structure."
            }
          ],
          "correctOptionIds": ["ch_recursion_5_q6_opt1"],
          "explanationText": "A recursive call is defined as tail-recursive if **it is the very last operation performed in the function, and the result of this recursive call is immediately returned by the calling function without any further computation**. For example, `return helper(n-1, acc_n);` could be a tail call, while `return n _ factorial(n-1);` is not, because the multiplication by `n` happens _after_ `factorial(n-1)` returns. The significance of tail recursion is that compilers supporting Tail Call Optimization (TCO) can transform such calls into iterations, avoiding the creation of new stack frames and thus preventing stack overflow for deep recursions.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_recursion_5_q7",
          "questionText": "The naive recursive Fibonacci algorithm, $F(n) = F(n-1) + F(n-2)$ (with $F(0)=0, F(1)=1$), is known for its inefficiency. What is the _primary reason_ for this inefficiency?",
          "options": [
            {
              "optionId": "ch_recursion_5_q7_opt1",
              "optionText": "$O(n)$"
            },
            {
              "optionId": "ch_recursion_5_q7_opt2",
              "optionText": "$O(n^2)$"
            },
            {
              "optionId": "ch_recursion_5_q7_opt3",
              "optionText": "$O(\\log n)$"
            },
            {
              "optionId": "ch_recursion_5_q7_opt4",
              "optionText": "Exponential, approximately $O(\\phi^n)$ where $\\phi \\approx 1.618$ (the golden ratio), often simplified to $O(2^n)$."
            },
            {
              "optionId": "ch_recursion_5_q7_opt5",
              "optionText": "Because it repeatedly recomputes the same Fibonacci numbers multiple times (overlapping subproblems)."
            },
            {
              "optionId": "ch_recursion_5_q7_opt6",
              "optionText": "The number of calls grows very rapidly, forming a tree of calls where, for example, F(n-2) is computed independently by the call for F(n) and as part of computing F(n-1)."
            },
            {
              "optionId": "ch_recursion_5_q7_opt7",
              "optionText": "$O(1)$"
            },
            {
              "optionId": "ch_recursion_5_q7_opt8",
              "optionText": "Its time complexity can be improved to $O(n)$ using iteration or memoization (dynamic programming)."
            },
            {
              "optionId": "ch_recursion_5_q7_opt9",
              "optionText": "Its space complexity due to recursion depth is $O(n)$."
            },
            {
              "optionId": "ch_recursion_5_q7_opt10",
              "optionText": "It is an efficient way to calculate Fibonacci numbers for large $n$."
            }
          ],
          "correctOptionIds": ["ch_recursion_5_q7_opt5"],
          "explanationText": "The primary reason for the inefficiency of the naive recursive Fibonacci algorithm is that **it repeatedly recomputes the same Fibonacci numbers multiple times** due to overlapping subproblems in its recursion tree. For example, to compute $F(5)$, it computes $F(4)$ and $F(3)$. Computing $F(4)$ involves computing $F(3)$ and $F(2)$. Thus, $F(3)$ is computed twice. This redundancy leads to an exponential time complexity (approximately $O(\\phi^n)$ or $O(2^n)$). This inefficiency can be overcome by using iteration or memoization (dynamic programming) to store and reuse the results of subproblems, achieving an $O(n)$ time complexity.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_recursion_5_q8",
          "questionText": "When comparing typical recursive (`fact(n) = n _ fact(n-1)`) and iterative solutions for computing factorial $n!$, what is a _key advantage of the iterative solution* regarding resource usage?",
          "options": [
            {
              "optionId": "ch_recursion_5_q8_opt1",
              "optionText": "A standard recursive solution is: `fact(n) = IF n≤1 THEN 1 ELSE n * fact(n-1)`."
            },
            {
              "optionId": "ch_recursion_5_q8_opt2",
              "optionText": "The standard recursive solution mentioned has $O(n)$ time complexity."
            },
            {
              "optionId": "ch_recursion_5_q8_opt3",
              "optionText": "The standard recursive solution mentioned has $O(n)$ space complexity due to the call stack."
            },
            {
              "optionId": "ch_recursion_5_q8_opt4",
              "optionText": "An iterative solution can compute factorial in $O(n)$ time and $O(1)$ space using a loop."
            },
            {
              "optionId": "ch_recursion_5_q8_opt5",
              "optionText": "The standard recursive solution is an example of tail recursion."
            },
            {
              "optionId": "ch_recursion_5_q8_opt6",
              "optionText": "The iterative solution is generally more efficient in terms of space for this problem."
            },
            {
              "optionId": "ch_recursion_5_q8_opt7",
              "optionText": "For very large $n$, both recursive and iterative solutions might suffer from integer overflow if using standard integer types."
            },
            {
              "optionId": "ch_recursion_5_q8_opt8",
              "optionText": "Converting the standard recursive factorial to a tail-recursive form is straightforward by using an accumulator parameter."
            },
            {
              "optionId": "ch_recursion_5_q8_opt9",
              "optionText": "The recursive solution is always easier to understand than the iterative one."
            },
            {
              "optionId": "ch_recursion_5_q8_opt10",
              "optionText": "The iterative solution avoids the overhead of function calls."
            }
          ],
          "correctOptionIds": ["ch_recursion_5_q8_opt4"],
          "explanationText": "A key advantage of the iterative solution for factorial is its resource usage: **an iterative solution can compute factorial in $O(n)$ time and $O(1)$ space using a loop__. In contrast, the standard recursive solution `fact(n) = IF n≤1 THEN 1 ELSE n _ fact(n-1)` also has $O(n)$ time complexity but incurs $O(n)$ space complexity due to the call stack frames created for each recursive call (unless tail call optimization is applied, which is not possible for this specific non-tail-recursive form without an accumulator). The iterative solution also avoids the overhead associated with function calls.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_recursion_5_q9",
          "questionText": "A recursive algorithm for the 'Closest Pair of Points' problem is a key example of divide-and-conquer. Which of the following descriptions best characterizes the 'Combine' phase of this algorithm, where results from subproblems are integrated?",
          "options": [
            {
              "optionId": "ch_recursion_5_q9_opt1",
              "optionText": "The set of points $P$ is divided into two halves, $P_L$ and $P_R$, based on their x-coordinates (e.g., by a median x-coordinate)."
            },
            {
              "optionId": "ch_recursion_5_q9_opt2",
              "optionText": "The closest pair is found recursively in $P_L$ (let distance be $d_L$) and in $P_R$ (let distance be $d_R$)."
            },
            {
              "optionId": "ch_recursion_5_q9_opt3",
              "optionText": "The minimum of $d_L$ and $d_R$ (let $d = \\min(d_L, d_R)$) is found. Then, a crucial step checks for a closer pair with one point in $P_L$ and one in $P_R$, within a 'strip' of width $2d$ around the dividing line."
            },
            {
              "optionId": "ch_recursion_5_q9_opt4",
              "optionText": "The brute-force approach of checking all pairs takes $O(n^2)$ time."
            },
            {
              "optionId": "ch_recursion_5_q9_opt5",
              "optionText": "The divide-and-conquer algorithm achieves $O(n \\log n)$ time complexity."
            },
            {
              "optionId": "ch_recursion_5_q9_opt6",
              "optionText": "Sorting points by y-coordinate within the strip helps to efficiently check for closer pairs across the divide."
            },
            {
              "optionId": "ch_recursion_5_q9_opt7",
              "optionText": "The base case for recursion is when the number of points is small (e.g., 2 or 3), where the closest pair is found by brute force."
            },
            {
              "optionId": "ch_recursion_5_q9_opt8",
              "optionText": "The algorithm requires pre-sorting the points by x-coordinate to efficiently divide."
            },
            {
              "optionId": "ch_recursion_5_q9_opt9",
              "optionText": "The 'strip check' only needs to consider a constant number of points near each point in the strip, due to geometric properties."
            },
            {
              "optionId": "ch_recursion_5_q9_opt10",
              "optionText": "Its space complexity is $O(n)$ due to storing sorted lists or recursive calls."
            }
          ],
          "correctOptionIds": ["ch_recursion_5_q9_opt3"],
          "explanationText": "In the divide-and-conquer algorithm for the Closest Pair of Points problem, the 'Divide' step partitions points. The 'Conquer' step recursively finds distances $d_L$ and $d_R$. The **'Combine' phase is best described by option `ch_recursion_5_q9_opt3`**: it takes $d = \\min(d_L, d_R)$ and then critically checks for any pair of points, one from each half, that are closer than $d$. This check is efficiently performed by considering only points within a narrow 'strip' of width $2d$ around the dividing line. This strip check is the core of the combine step and essential for achieving the algorithm's $O(n \\log n)$ efficiency.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_recursion_5_q10",
          "questionText": "Which of the following is the _most direct and common_ disadvantage related to the execution mechanism of recursive functions?",
          "options": [
            {
              "optionId": "ch_recursion_5_q10_opt1",
              "optionText": "**Stack Overflow**: If the recursion is too deep, the call stack may run out of memory."
            },
            {
              "optionId": "ch_recursion_5_q10_opt2",
              "optionText": "**Performance Overhead**: Function calls (including recursive ones) can have more overhead (e.g., setting up stack frames, parameter passing) than simple loop iterations."
            },
            {
              "optionId": "ch_recursion_5_q10_opt3",
              "optionText": "**Redundant Computations**: Some recursive algorithms (like naive Fibonacci) can recompute the same subproblems multiple times, leading to inefficiency if not handled (e.g., by memoization)."
            },
            {
              "optionId": "ch_recursion_5_q10_opt4",
              "optionText": "Recursive solutions are always harder to read and understand than iterative ones."
            },
            {
              "optionId": "ch_recursion_5_q10_opt5",
              "optionText": "Not all problems can be solved recursively."
            },
            {
              "optionId": "ch_recursion_5_q10_opt6",
              "optionText": "Debugging recursive code can sometimes be more challenging due to the multiple call contexts."
            },
            {
              "optionId": "ch_recursion_5_q10_opt7",
              "optionText": "Missing or incorrect base cases can lead to infinite recursion (until a stack overflow)."
            },
            {
              "optionId": "ch_recursion_5_q10_opt8",
              "optionText": "Recursive algorithms inherently use more memory than their iterative counterparts due to stack usage (unless optimized, e.g., TCO)."
            },
            {
              "optionId": "ch_recursion_5_q10_opt9",
              "optionText": "Converting any iterative algorithm to a recursive one is trivial and always beneficial."
            },
            {
              "optionId": "ch_recursion_5_q10_opt10",
              "optionText": "Recursion is only suitable for mathematical functions like factorial or Fibonacci."
            }
          ],
          "correctOptionIds": ["ch_recursion_5_q10_opt1"],
          "explanationText": "The most direct and common disadvantage related to the execution mechanism of recursive functions is the risk of **Stack Overflow**. Each recursive call adds a new frame to the call stack to store its local variables, parameters, and return address. If the recursion depth is too large (e.g., due to a missing or incorrect base case, or processing a very large input in a way that leads to deep recursion), the finite space allocated for the call stack can be exhausted, leading to a stack overflow error and program termination. While performance overhead from function calls and potential for redundant computations are also disadvantages, stack overflow is a hard limit imposed by the execution environment.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_recursion_5_q4_partA_calls",
          "questionText": "When tracing `FastPower(x=2, k=5)` using the algorithm:<br>`IF k = 0 THEN RETURN 1`<br>`y ← FastPower(x, k DIV 2)`<br>`IF k is even THEN RETURN y_y`<br>`ELSE RETURN y_y*x`<br>What is the sequence of recursive calls made, showing the value of `k` at each call?",
          "options": [
            {
              "optionId": "ch_recursion_5_q4_partA_opt1",
              "optionText": "$k=5 \\rightarrow k=2 \\rightarrow k=1 \\rightarrow k=0$"
            },
            {
              "optionId": "ch_recursion_5_q4_partA_opt2",
              "optionText": "$k=5 \\rightarrow k=3 \\rightarrow k=1 \\rightarrow k=0$"
            },
            {
              "optionId": "ch_recursion_5_q4_partA_opt3",
              "optionText": "$k=5 \\rightarrow k=4 \\rightarrow k=2 \\rightarrow k=0$"
            },
            {
              "optionId": "ch_recursion_5_q4_partA_opt4",
              "optionText": "$k=5 \\rightarrow k=2.5$ (error, k DIV 2 is integer division)"
            },
            {
              "optionId": "ch_recursion_5_q4_partA_opt5",
              "optionText": "Only one call: `FastPower(2,5)`"
            },
            {
              "optionId": "ch_recursion_5_q4_partA_opt6",
              "optionText": "$k=5 \\rightarrow k=1$ (incorrect halving)"
            },
            {
              "optionId": "ch_recursion_5_q4_partA_opt7",
              "optionText": "The function calls `FastPower(2,0)` directly from `FastPower(2,5)`."
            },
            {
              "optionId": "ch_recursion_5_q4_partA_opt8",
              "optionText": "$k=5 \\rightarrow k=2 \\rightarrow k=0$ (skips $k=1$)"
            },
            {
              "optionId": "ch_recursion_5_q4_partA_opt9",
              "optionText": "The sequence of calls depends on whether $k$ is even or odd at each step."
            },
            {
              "optionId": "ch_recursion_5_q4_partA_opt10",
              "optionText": "The recursion stops when $k=1$."
            }
          ],
          "correctOptionIds": ["ch_recursion_5_q4_partA_opt1"],
          "explanationText": "Tracing the recursive calls for `FastPower(2, 5)` based on $k \\text{ DIV } 2$: <br>1. Initial call: $k=5$. Recursive call with $k = 5 \\text{ DIV } 2 = 2$.<br>2. Call with $k=2$. Recursive call with $k = 2 \\text{ DIV } 2 = 1$.<br>3. Call with $k=1$. Recursive call with $k = 1 \\text{ DIV } 2 = 0$.<br>4. Call with $k=0$. This is the base case, returns 1.<br>So, the sequence of $k$ values in the calls is $5 \\rightarrow 2 \\rightarrow 1 \\rightarrow 0$.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_recursion_5_q4_partB_y_values",
          "questionText": "When tracing `FastPower(x=2, k=5)` (algorithm in previous question), what is the sequence of values assigned to the variable `y` in the respective call frames as the recursive calls return and computations proceed?",
          "options": [
            {
              "optionId": "ch_recursion_5_q4_partB_opt1",
              "optionText": "$y=1$ (in frame for $k=1$), then $y=2$ (in frame for $k=2$), then $y=4$ (in frame for $k=5$)"
            },
            {
              "optionId": "ch_recursion_5_q4_partB_opt2",
              "optionText": "$y=1$ (for $k=0$), $y=1$ (for $k=1$), $y=2$ (for $k=2$), $y=4$ (for $k=5$)"
            },
            {
              "optionId": "ch_recursion_5_q4_partB_opt3",
              "optionText": "$y=4$ (for $k=5$), then $y=2$ (for $k=2$), then $y=1$ (for $k=1$)"
            },
            {
              "optionId": "ch_recursion_5_q4_partB_opt4",
              "optionText": "$y$ is always 1."
            },
            {
              "optionId": "ch_recursion_5_q4_partB_opt5",
              "optionText": "$y$ is assigned 32 in the outermost call."
            },
            {
              "optionId": "ch_recursion_5_q4_partB_opt6",
              "optionText": "The value of $y$ is the final result of `FastPower(x, k DIV 2)`."
            },
            {
              "optionId": "ch_recursion_5_q4_partB_opt7",
              "optionText": "$y=1$ (in frame for $k=0$ call result), then $y=1*1*2=2$ (in frame for $k=1$), then $y=2_2=4$ (in frame for $k=2$), then $y=4_4*2=32$ (in frame for $k=5$, this is final result, not $y$)."
            },
            {
              "optionId": "ch_recursion_5_q4_partB_opt8",
              "optionText": "$y$ gets assigned the result of $y_y$ or $y_y*x$."
            },
            {
              "optionId": "ch_recursion_5_q4_partB_opt9",
              "optionText": "$y=0$ initially in all frames."
            },
            {
              "optionId": "ch_recursion_5_q4_partB_opt10",
              "optionText": "$y=2$ (in frame for $k=1$), then $y=4$ (in frame for $k=2$), then $y=16$ (in frame for $k=5$)"
            }
          ],
          "correctOptionIds": ["ch_recursion_5_q4_partB_opt1"],
          "explanationText": "Let's trace assignments to $y$ as calls return: <br>1. `FastPower(2,0)` returns 1. <br>2. In frame for $k=1$ (which called `FastPower(2,0)`): $y$ gets 1. Returns $y*y*x = 1*1*2 = 2$. <br>3. In frame for $k=2$ (which called `FastPower(2,1)`): $y$ gets 2. Returns $y*y = 2*2 = 4$. <br>4. In frame for $k=5$ (which called `FastPower(2,2)`): $y$ gets 4. Returns $y*y*x = 4*4*2 = 32$. <br>Thus, the sequence of values assigned to $y$ in the call frames for $k=1$, then $k=2$, then $k=5$ is 1, then 2, then 4, respectively.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null,
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": []
        }
      ],
      "totalQuestions": 12,
      "answeredQuestions": 0,
      "correctAnswers": 0,
      "isCompleted": false
    },
    {
      "id": "ch_adv_sorting_6",
      "name": "Chapter 6: Divide-and-Conquer Sorting Algorithms",
      "description": "Focuses on Quicksort and Mergesort, their mechanisms, performance characteristics (best, average, worst cases), space usage, stability, and the theoretical lower bound for comparison sorts.",
      "questions": [
        {
          "questionId": "ch_adv_sorting_6_q1",
          "questionText": "What is the generally accepted theoretical lower bound for the time complexity of any **comparison-based** sorting algorithm in the worst case, representing the minimum number of comparisons required?",
          "options": [
            {
              "optionId": "ch_adv_sorting_6_q1_opt1",
              "optionText": "$O(n)$"
            },
            {
              "optionId": "ch_adv_sorting_6_q1_opt2",
              "optionText": "$O(\\log n)$"
            },
            {
              "optionId": "ch_adv_sorting_6_q1_opt3",
              "optionText": "$O(n^2)$"
            },
            {
              "optionId": "ch_adv_sorting_6_q1_opt4",
              "optionText": "$\\Omega(n \\log n)$"
            },
            {
              "optionId": "ch_adv_sorting_6_q1_opt5",
              "optionText": "This lower bound is derived by considering that there are $n!$ possible permutations (orderings) of $n$ distinct elements."
            },
            {
              "optionId": "ch_adv_sorting_6_q1_opt6",
              "optionText": "Each comparison between two elements can at best reduce the number of possible correct orderings by half, forming a binary decision tree."
            },
            {
              "optionId": "ch_adv_sorting_6_q1_opt7",
              "optionText": "The height of this decision tree, representing the minimum number of worst-case comparisons, must be at least $\\log_2(n!)$, which is $\\Omega(n \\log n)$."
            },
            {
              "optionId": "ch_adv_sorting_6_q1_opt8",
              "optionText": "$O(n!)$"
            },
            {
              "optionId": "ch_adv_sorting_6_q1_opt9",
              "optionText": "This bound applies only to in-place sorting algorithms."
            },
            {
              "optionId": "ch_adv_sorting_6_q1_opt10",
              "optionText": "Algorithms like Radix Sort can beat this lower bound because they are not comparison-based (they use digit/value properties)."
            }
          ],
          "correctOptionIds": ["ch_adv_sorting_6_q1_opt4"],
          "explanationText": "The theoretical lower bound for the time complexity of any comparison-based sorting algorithm in the worst case is **$\\Omega(n \\log n)$**. This means that, to sort $n$ elements using only comparisons between elements, at least a number of comparisons proportional to $n \\log n$ will be required in the worst case. This bound is derived by considering a decision tree model: there are $n!$ possible permutations (orderings) of $n$ distinct elements, which must be the leaves of the decision tree. Since each comparison has at most two outcomes, the tree is binary. The height of such a tree must be at least $\\log_2(n!)$, and using Stirling's approximation for $n!$, $\\log_2(n!)$ is shown to be $\\Omega(n \\log n)$. Non-comparison-based sorts like Radix Sort can sometimes achieve better complexities (e.g., $O(nk)$) by using properties of the keys themselves rather than just comparisons.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_adv_sorting_6_q2",
          "questionText": "In the **Quicksort** algorithm, what is the _primary outcome_ of the **partitioning** step with respect to the chosen pivot element?",
          "options": [
            {
              "optionId": "ch_adv_sorting_6_q2_opt1",
              "optionText": "To merge two already sorted subarrays into a single sorted array."
            },
            {
              "optionId": "ch_adv_sorting_6_q2_opt2",
              "optionText": "To select a 'pivot' element randomly from the array."
            },
            {
              "optionId": "ch_adv_sorting_6_q2_opt3",
              "optionText": "To rearrange the elements of the subarray such that all elements less than the pivot come before it, and all elements greater than the pivot come after it."
            },
            {
              "optionId": "ch_adv_sorting_6_q2_opt4",
              "optionText": "To place the chosen pivot element into its final sorted position within the overall sorted array."
            },
            {
              "optionId": "ch_adv_sorting_6_q2_opt5",
              "optionText": "To divide the array into two subarrays (left and right of the pivot) that are then sorted recursively."
            },
            {
              "optionId": "ch_adv_sorting_6_q2_opt6",
              "optionText": "To count the number of elements smaller than the pivot."
            },
            {
              "optionId": "ch_adv_sorting_6_q2_opt7",
              "optionText": "The partitioning step itself typically runs in $O(k)$ time for a subarray of size $k$."
            },
            {
              "optionId": "ch_adv_sorting_6_q2_opt8",
              "optionText": "After partitioning, the two resulting subarrays are then sorted recursively."
            },
            {
              "optionId": "ch_adv_sorting_6_q2_opt9",
              "optionText": "To find the median element of the array, which is then used as the pivot."
            },
            {
              "optionId": "ch_adv_sorting_6_q2_opt10",
              "optionText": "To ensure the stability of the Quicksort algorithm."
            }
          ],
          "correctOptionIds": ["ch_adv_sorting_6_q2_opt4"],
          "explanationText": "The primary outcome of the partitioning step in Quicksort, with respect to the pivot element, is **to place the chosen pivot element into its final sorted position within the overall sorted array**. During partitioning, elements are rearranged such that all elements smaller than the pivot are moved to its left, and all elements larger than the pivot are moved to its right (elements equal to the pivot can be handled in various ways depending on the partitioning scheme). Once this rearrangement is complete, the pivot itself is in the correct position it will occupy in the fully sorted array, and it will not be moved again. The partitioning step typically runs in linear time ($O(k)$ for a subarray of size $k$). The two subarrays formed (to the left and right of the pivot's final position) are then sorted recursively.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_adv_sorting_6_q3",
          "questionText": "The performance of Quicksort heavily depends on pivot choice. What is its _worst-case time complexity_, and what is a common scenario that triggers this worst case if a naive pivot selection strategy (e.g., always picking the first element) is used?",
          "options": [
            {
              "optionId": "ch_adv_sorting_6_q3_opt1",
              "optionText": "Best Case: $O(n \\log n)$, occurs when the pivot consistently divides the array into two nearly equal halves."
            },
            {
              "optionId": "ch_adv_sorting_6_q3_opt2",
              "optionText": "Worst Case: $O(n^2)$, occurs when the pivot consistently results in a highly unbalanced partition (e.g., one part empty, other has $k-1$ elements)."
            },
            {
              "optionId": "ch_adv_sorting_6_q3_opt3",
              "optionText": "The worst case can happen if the array is already sorted or reverse-sorted and the first/last element is always chosen as the pivot."
            },
            {
              "optionId": "ch_adv_sorting_6_q3_opt4",
              "optionText": "Average Case: $O(n \\log n)$, which is why Quicksort is often fast in practice."
            },
            {
              "optionId": "ch_adv_sorting_6_q3_opt5",
              "optionText": "Best Case: $O(n)$, if the array is already sorted and no swaps are needed."
            },
            {
              "optionId": "ch_adv_sorting_6_q3_opt6",
              "optionText": "Worst Case: $O(n \\log n)$, if a randomized pivot is used."
            },
            {
              "optionId": "ch_adv_sorting_6_q3_opt7",
              "optionText": "Choosing the median element as the pivot guarantees the best-case $O(n \\log n)$ partitioning, but finding the median takes $O(n)$ time itself."
            },
            {
              "optionId": "ch_adv_sorting_6_q3_opt8",
              "optionText": "The depth of recursion in the best case is $O(\\log n)$."
            },
            {
              "optionId": "ch_adv_sorting_6_q3_opt9",
              "optionText": "The depth of recursion in the worst case is $O(n)$."
            },
            {
              "optionId": "ch_adv_sorting_6_q3_opt10",
              "optionText": "Space complexity in worst case (naive recursion) can be $O(n)$ due to stack depth."
            }
          ],
          "correctOptionIds": ["ch_adv_sorting_6_q3_opt2"],
          "explanationText": "Quicksort's worst-case time complexity is **$O(n^2)$**. This occurs when the partitioning step consistently produces highly unbalanced partitions – for example, when the pivot chosen is always the smallest or largest element in the current subarray, resulting in one partition being empty and the other containing all remaining $k-1$ elements. A common scenario that triggers this behavior is when Quicksort is applied to an already sorted or reverse-sorted array, and a naive pivot selection strategy is used, such as always picking the first or last element as the pivot. The best-case and average-case complexity of Quicksort is $O(n \\log n)$.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_adv_sorting_6_q4",
          "questionText": "In the **Mergesort** algorithm, what is the primary role of the **merge** step, and what is its typical time complexity for merging two sorted subarrays totaling $k$ elements?",
          "options": [
            {
              "optionId": "ch_adv_sorting_6_q4_opt1",
              "optionText": "To divide the array into two halves recursively."
            },
            {
              "optionId": "ch_adv_sorting_6_q4_opt2",
              "optionText": "To combine two already sorted subarrays into a single, larger sorted subarray."
            },
            {
              "optionId": "ch_adv_sorting_6_q4_opt3",
              "optionText": "The merge step typically takes $O(k)$ time, where $k$ is the total number of elements in the two subarrays being merged."
            },
            {
              "optionId": "ch_adv_sorting_6_q4_opt4",
              "optionText": "The merge step takes $O(k \\log k)$ time."
            },
            {
              "optionId": "ch_adv_sorting_6_q4_opt5",
              "optionText": "It usually requires auxiliary (extra) space proportional to $k$ (i.e., $O(k)$) to perform the merge into a temporary array."
            },
            {
              "optionId": "ch_adv_sorting_6_q4_opt6",
              "optionText": "It works by repeatedly picking the smaller of the current elements from the two input subarrays and placing it into the output array."
            },
            {
              "optionId": "ch_adv_sorting_6_q4_opt7",
              "optionText": "The merge step can be done in-place with $O(1)$ extra space efficiently for arrays."
            },
            {
              "optionId": "ch_adv_sorting_6_q4_opt8",
              "optionText": "The merge step is the 'divide' part of Mergesort."
            },
            {
              "optionId": "ch_adv_sorting_6_q4_opt9",
              "optionText": "The efficiency of Mergesort relies on the efficiency of this merge step."
            },
            {
              "optionId": "ch_adv_sorting_6_q4_opt10",
              "optionText": "The merge step takes $O(k^2)$ time."
            }
          ],
          "correctOptionIds": ["ch_adv_sorting_6_q4_opt2"],
          "explanationText": "The primary role of the merge step in Mergesort is **to combine two already sorted subarrays into a single, larger sorted subarray**. This is the 'combine' phase of its divide-and-conquer strategy. This merge operation is typically performed in $O(k)$ time, where $k$ is the total number of elements in the two subarrays being merged, as each element is examined and copied once. For array-based Mergesort, this step usually requires $O(k)$ auxiliary space for a temporary array to store the merged result.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_adv_sorting_6_q5",
          "questionText": "Which of the following statements _best describes a key performance guarantee_ of the **Mergesort** algorithm, distinguishing it from algorithms like standard Quicksort?",
          "options": [
            {
              "optionId": "ch_adv_sorting_6_q5_opt1",
              "optionText": "Its time complexity is $O(n \\log n)$ in the worst, average, and best cases."
            },
            {
              "optionId": "ch_adv_sorting_6_q5_opt2",
              "optionText": "It is an in-place sorting algorithm, requiring $O(1)$ auxiliary space."
            },
            {
              "optionId": "ch_adv_sorting_6_q5_opt3",
              "optionText": "It typically requires $O(n)$ auxiliary space for the merging process in its array-based version."
            },
            {
              "optionId": "ch_adv_sorting_6_q5_opt4",
              "optionText": "It is a stable sorting algorithm."
            },
            {
              "optionId": "ch_adv_sorting_6_q5_opt5",
              "optionText": "It is not a stable sorting algorithm."
            },
            {
              "optionId": "ch_adv_sorting_6_q5_opt6",
              "optionText": "It is highly adaptive to already sorted or nearly sorted data, achieving $O(n)$ in such cases."
            },
            {
              "optionId": "ch_adv_sorting_6_q5_opt7",
              "optionText": "Its performance does not significantly change based on the initial order of the data (it is not adaptive)."
            },
            {
              "optionId": "ch_adv_sorting_6_q5_opt8",
              "optionText": "The 'divide' step involves complex partitioning around a pivot."
            },
            {
              "optionId": "ch_adv_sorting_6_q5_opt9",
              "optionText": "The 'divide' step simply splits the array into two halves, which takes $O(1)$ time (conceptually, for index calculation)."
            },
            {
              "optionId": "ch_adv_sorting_6_q5_opt10",
              "optionText": "It is generally preferred over Quicksort when stability is a requirement or worst-case $O(n \\log n)$ guarantee is needed."
            }
          ],
          "correctOptionIds": ["ch_adv_sorting_6_q5_opt1"],
          "explanationText": "A key performance guarantee of Mergesort, which distinguishes it from standard Quicksort (with its $O(n^2)$ worst case), is that **its time complexity is $O(n \\log n)$ in the worst, average, and best cases**. This consistent and predictable performance makes Mergesort reliable. Additionally, Mergesort is a stable sorting algorithm. However, its typical array-based implementation requires $O(n)$ auxiliary space, which is a disadvantage compared to Quicksort's in-place partitioning (though Quicksort uses $O(\\log n)$ to $O(n)$ stack space for recursion).",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_adv_sorting_6_q6",
          "questionText": "When comparing Quicksort and Mergesort, which statement _best highlights a common reason Quicksort might be preferred in practice for general-purpose array sorting, despite Mergesort's better worst-case time complexity_?",
          "options": [
            {
              "optionId": "ch_adv_sorting_6_q6_opt1",
              "optionText": "Quicksort is generally faster on average in practice due to lower constant factors and better cache locality (being in-place for partitioning)."
            },
            {
              "optionId": "ch_adv_sorting_6_q6_opt2",
              "optionText": "Mergesort has a better worst-case time complexity guarantee ($O(n \\log n)$) compared to Quicksort's potential $O(n^2)$."
            },
            {
              "optionId": "ch_adv_sorting_6_q6_opt3",
              "optionText": "Quicksort is an in-place sort (typically $O(\\log n)$ stack space for well-behaved recursion, or $O(n)$ in worst-case recursion), while Mergesort (array version) requires $O(n)$ auxiliary space."
            },
            {
              "optionId": "ch_adv_sorting_6_q6_opt4",
              "optionText": "Mergesort is stable by nature, while standard Quicksort implementations are often not stable."
            },
            {
              "optionId": "ch_adv_sorting_6_q6_opt5",
              "optionText": "Quicksort is easier to implement correctly than Mergesort."
            },
            {
              "optionId": "ch_adv_sorting_6_q6_opt6",
              "optionText": "Mergesort is preferred for external sorting (data on disk) because its sequential access pattern for merging is efficient."
            },
            {
              "optionId": "ch_adv_sorting_6_q6_opt7",
              "optionText": "If memory is highly constrained and worst-case time is less critical, Quicksort's lower auxiliary space usage (for partitioning) might be preferred over array-based Mergesort."
            },
            {
              "optionId": "ch_adv_sorting_6_q6_opt8",
              "optionText": "Both are based on the divide-and-conquer paradigm."
            },
            {
              "optionId": "ch_adv_sorting_6_q6_opt9",
              "optionText": "Quicksort's performance is highly sensitive to pivot selection; Mergesort's is not."
            },
            {
              "optionId": "ch_adv_sorting_6_q6_opt10",
              "optionText": "Mergesort always performs fewer comparisons than Quicksort."
            }
          ],
          "correctOptionIds": ["ch_adv_sorting_6_q6_opt1"],
          "explanationText": "Despite Mergesort's guaranteed $O(n \\log n)$ worst-case time complexity, **Quicksort is generally faster on average in practice due to lower constant factors in its operations and better cache locality**. Quicksort's partitioning step is typically performed in-place, leading to more efficient memory access patterns compared to the array-based Mergesort, which usually requires $O(n)$ auxiliary space for merging and involves more data movement. However, Mergesort is preferred when stability or a guaranteed $O(n \\log n)$ worst-case is critical.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_adv_sorting_6_q7",
          "questionText": "If Quicksort, using the first element of the current subarray as the pivot, is applied to an array that is already sorted in ascending order, what is the _most direct consequence on the partitioning process_?",
          "options": [
            {
              "optionId": "ch_adv_sorting_6_q7_opt1",
              "optionText": "The pivot (the smallest element in the current subarray) results in a perfectly balanced partition."
            },
            {
              "optionId": "ch_adv_sorting_6_q7_opt2",
              "optionText": "The pivot (always the smallest element in the current subarray) leads to one partition being empty and the other containing all other $k-1$ elements (for a subarray of size $k$)."
            },
            {
              "optionId": "ch_adv_sorting_6_q7_opt3",
              "optionText": "This scenario leads to Quicksort's worst-case $O(n^2)$ time complexity."
            },
            {
              "optionId": "ch_adv_sorting_6_q7_opt4",
              "optionText": "The algorithm effectively degrades to something like Selection Sort's behavior in terms of recursive depth."
            },
            {
              "optionId": "ch_adv_sorting_6_q7_opt5",
              "optionText": "The depth of recursion becomes $O(n)$."
            },
            {
              "optionId": "ch_adv_sorting_6_q7_opt6",
              "optionText": "Many swaps will occur during partitioning."
            },
            {
              "optionId": "ch_adv_sorting_6_q7_opt7",
              "optionText": "Few or no actual swaps of element positions will occur during partitioning if implemented carefully, but comparisons still happen."
            },
            {
              "optionId": "ch_adv_sorting_6_q7_opt8",
              "optionText": "The algorithm will exhibit $O(n \\log n)$ behavior because the array is sorted."
            },
            {
              "optionId": "ch_adv_sorting_6_q7_opt9",
              "optionText": "The chosen pivot is always the minimum element of the subarray being partitioned."
            },
            {
              "optionId": "ch_adv_sorting_6_q7_opt10",
              "optionText": "The algorithm terminates quickly in $O(n)$ time."
            }
          ],
          "correctOptionIds": ["ch_adv_sorting_6_q7_opt2"],
          "explanationText": "If Quicksort uses the first element as the pivot and is applied to an already sorted array, the most direct consequence on partitioning is that **the pivot (which will always be the smallest element in the current subarray) leads to a highly unbalanced partition: one partition will be empty (elements smaller than the pivot), and the other will contain all the remaining $k-1$ elements (elements larger than the pivot)**. This consistently poor partitioning leads to a recursion depth of $O(n)$ and an overall worst-case time complexity of $O(n^2)$.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_adv_sorting_6_q8",
          "questionText": "Why is Mergesort often a good choice for sorting linked lists, particularly concerning its space requirements when compared to array-based Mergesort?",
          "options": [
            {
              "optionId": "ch_adv_sorting_6_q8_opt1",
              "optionText": "Linked lists allow $O(1)$ random access to elements, which benefits Quicksort's partitioning."
            },
            {
              "optionId": "ch_adv_sorting_6_q8_opt2",
              "optionText": "Mergesort's divide step (splitting the list, e.g., finding the middle) can be done efficiently for linked lists, often in $O(n)$ time using fast/slow pointers."
            },
            {
              "optionId": "ch_adv_sorting_6_q8_opt3",
              "optionText": "Mergesort's merge step on linked lists can be done in-place (by rearranging pointers) with $O(1)$ auxiliary data space, unlike array-based Mergesort which needs $O(n)$ temporary array space."
            },
            {
              "optionId": "ch_adv_sorting_6_q8_opt4",
              "optionText": "Quicksort's partitioning involves many swaps, which are inefficient for linked lists (requiring pointer readjustments for multiple nodes)."
            },
            {
              "optionId": "ch_adv_sorting_6_q8_opt5",
              "optionText": "Linked lists naturally support the sequential access pattern of the merge operation in Mergesort."
            },
            {
              "optionId": "ch_adv_sorting_6_q8_opt6",
              "optionText": "Quicksort requires $O(n)$ auxiliary space for linked lists."
            },
            {
              "optionId": "ch_adv_sorting_6_q8_opt7",
              "optionText": "Mergesort for linked lists retains its $O(n \\log n)$ time complexity."
            },
            {
              "optionId": "ch_adv_sorting_6_q8_opt8",
              "optionText": "Quicksort's typical partitioning schemes rely on efficient random access to elements (e.g., for swaps or pivot access), which is slow ($O(k)$ for $k$-th element) on linked lists."
            },
            {
              "optionId": "ch_adv_sorting_6_q8_opt9",
              "optionText": "Mergesort is inherently stable, which is often desired and easily maintained with linked lists."
            },
            {
              "optionId": "ch_adv_sorting_6_q8_opt10",
              "optionText": "Quicksort for linked lists becomes $O(n^2)$ even in the average case."
            }
          ],
          "correctOptionIds": ["ch_adv_sorting_6_q8_opt3"],
          "explanationText": "A key reason Mergesort is well-suited for linked lists is that **its merge step on linked lists can be performed in-place by rearranging pointers, requiring only $O(1)$ auxiliary data space** (excluding the stack space for recursion, which is $O(\\log n)$). This contrasts sharply with array-based Mergesort, which typically needs an $O(n)$ auxiliary array for merging. Additionally, linked lists naturally support the sequential access pattern of merging, and Quicksort's reliance on random access for efficient partitioning makes it less ideal for linked lists.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_adv_sorting_6_q9",
          "questionText": "For sorting very small arrays (e.g., $n < 20$), why might an algorithm like Insertion Sort be practically preferred over more complex algorithms like Quicksort or Mergesort, despite Insertion Sort's worse asymptotic complexity?",
          "options": [
            {
              "optionId": "ch_adv_sorting_6_q9_opt1",
              "optionText": "Insertion Sort's number of swaps is always $O(n)$, making it ideal for small arrays."
            },
            {
              "optionId": "ch_adv_sorting_6_q9_opt2",
              "optionText": "Insertion Sort performs optimally on small arrays because its $O(n)$ best-case complexity is frequently met."
            },
            {
              "optionId": "ch_adv_sorting_6_q9_opt3",
              "optionText": "Insertion Sort's logic is simpler and involves fewer comparisons on average than Quicksort for tiny $n$."
            },
            {
              "optionId": "ch_adv_sorting_6_q9_opt4",
              "optionText": "Heapsort, due to its $O(n \\log n)$ nature, is actually faster than Insertion Sort even for $n < 20$."
            },
            {
              "optionId": "ch_adv_sorting_6_q9_opt5",
              "optionText": "Because the constant factors and overhead of recursive calls in Quicksort/Mergesort can make them slower for very small $n$."
            },
            {
              "optionId": "ch_adv_sorting_6_q9_opt6",
              "optionText": "Many hybrid sorting algorithms (like Timsort or Introsort) switch to Insertion Sort for small partitions for this reason."
            },
            {
              "optionId": "ch_adv_sorting_6_q9_opt7",
              "optionText": "Radix Sort is generally the fastest for small integer arrays."
            },
            {
              "optionId": "ch_adv_sorting_6_q9_opt8",
              "optionText": "The simplicity of implementing Insertion Sort correctly reduces development time for small, non-critical tasks."
            },
            {
              "optionId": "ch_adv_sorting_6_q9_opt9",
              "optionText": "Quicksort and Mergesort are always faster regardless of $n$ due to their superior Big O."
            },
            {
              "optionId": "ch_adv_sorting_6_q9_opt10",
              "optionText": "Insertion Sort is stable, which is a primary requirement for small array sorting."
            }
          ],
          "correctOptionIds": ["ch_adv_sorting_6_q9_opt5"],
          "explanationText": "For very small arrays, algorithms like Insertion Sort can be practically faster than Quicksort or Mergesort primarily **because the constant factors and overhead associated with the recursive calls and more complex logic of Quicksort/Mergesort can outweigh their superior asymptotic ($O(n \\log n)$) behavior**. Insertion Sort has a simple loop structure with low overhead. Its $O(n^2)$ complexity is not detrimental for tiny $n$ (e.g., $n < 20$). This is why many sophisticated hybrid sorting algorithms (as mentioned in `ch_adv_sorting_6_q9_opt6`) switch to Insertion Sort when dealing with small partitions. While simplicity of implementation (`ch_adv_sorting_6_q9_opt8`) can be a factor, performance is the key reason here.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_adv_sorting_6_q10",
          "questionText": "The 'three-way partition' variant of Quicksort is particularly useful for arrays with many duplicate keys. What is its _primary mechanism_ for handling these duplicates?",
          "options": [
            {
              "optionId": "ch_adv_sorting_6_q10_opt1",
              "optionText": "It partitions the array into three parts: elements less than the pivot, elements equal to the pivot, and elements greater than the pivot."
            },
            {
              "optionId": "ch_adv_sorting_6_q10_opt2",
              "optionText": "After partitioning, the elements equal to the pivot are already in their final sorted positions and do not need further processing."
            },
            {
              "optionId": "ch_adv_sorting_6_q10_opt3",
              "optionText": "Recursive calls are then made only on the 'less than' and 'greater than' partitions, excluding the 'equal to pivot' middle part."
            },
            {
              "optionId": "ch_adv_sorting_6_q10_opt4",
              "optionText": "This can improve performance significantly, potentially towards $O(n)$ in the case of arrays with very few unique values (many duplicates)."
            },
            {
              "optionId": "ch_adv_sorting_6_q10_opt5",
              "optionText": "It makes Quicksort stable."
            },
            {
              "optionId": "ch_adv_sorting_6_q10_opt6",
              "optionText": "It always uses three pivots simultaneously."
            },
            {
              "optionId": "ch_adv_sorting_6_q10_opt7",
              "optionText": "Standard (two-way) partitioning can handle duplicates inefficiently, potentially leading to $O(n^2)$ behavior if many elements are equal to the pivot and all go to one side of the partition."
            },
            {
              "optionId": "ch_adv_sorting_6_q10_opt8",
              "optionText": "It is more complex to implement than standard two-way partitioning."
            },
            {
              "optionId": "ch_adv_sorting_6_q10_opt9",
              "optionText": "Dijkstra's Dutch National Flag problem provides a basis for one such partitioning scheme (e.g., Bentley-McIlroy)."
            },
            {
              "optionId": "ch_adv_sorting_6_q10_opt10",
              "optionText": "It guarantees $O(n \\log n)$ worst-case performance."
            }
          ],
          "correctOptionIds": ["ch_adv_sorting_6_q10_opt1"],
          "explanationText": "The primary mechanism of three-way partitioning in Quicksort is that **it partitions the array into three distinct parts based on the pivot: elements less than the pivot, elements equal to the pivot, and elements greater than the pivot**. The significant benefit is that elements equal to the pivot are then correctly placed and excluded from subsequent recursive calls, which are made only on the 'less than' and 'greater than' partitions. This can dramatically improve performance on inputs with many duplicate keys, potentially leading to linear time if most elements are identical, by avoiding the $O(n^2)$ behavior that standard two-way partitioning might exhibit with such inputs.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        }
      ],
      "totalQuestions": 10,
      "answeredQuestions": 0,
      "correctAnswers": 0,
      "isCompleted": false
    },
    {
      "id": "ch_limits_pnp_7",
      "name": "Chapter 7: Limits of Algorithms - P, NP, and NP-Completeness",
      "description": "Explores the concepts of tractability (P), non-deterministic polynomial time (NP), NP-complete problems, reductions, and the significance of the P vs NP problem.",
      "questions": [
        {
          "questionId": "ch_limits_pnp_7_q1",
          "questionText": "What is the _formal definition_ of the complexity class **P** in computational complexity theory?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q1_opt1",
              "optionText": "The set of all decision problems that can be solved by a deterministic Turing machine in **polynomial time** with respect to the input size."
            },
            {
              "optionId": "ch_limits_pnp_7_q1_opt2",
              "optionText": "Problems in P are generally considered **tractable** or efficiently solvable."
            },
            {
              "optionId": "ch_limits_pnp_7_q1_opt3",
              "optionText": "Examples include sorting (e.g., Mergesort), shortest path in a graph (e.g., Dijkstra's), and matrix multiplication."
            },
            {
              "optionId": "ch_limits_pnp_7_q1_opt4",
              "optionText": "The set of problems solvable in exponential time."
            },
            {
              "optionId": "ch_limits_pnp_7_q1_opt5",
              "optionText": "The set of problems for which a solution can be verified in polynomial time."
            },
            {
              "optionId": "ch_limits_pnp_7_q1_opt6",
              "optionText": "P stands for 'Probabilistic' polynomial time."
            },
            {
              "optionId": "ch_limits_pnp_7_q1_opt7",
              "optionText": "Any decision problem solvable by an algorithm with time complexity $O(n^k)$ for some constant $k$ is in P."
            },
            {
              "optionId": "ch_limits_pnp_7_q1_opt8",
              "optionText": "All problems in P are also in NP."
            },
            {
              "optionId": "ch_limits_pnp_7_q1_opt9",
              "optionText": "The Halting Problem is in P."
            },
            {
              "optionId": "ch_limits_pnp_7_q1_opt10",
              "optionText": "P includes problems solvable in $O(\\log n)$ time."
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q1_opt1"],
          "explanationText": "The formal definition of the complexity class P is: **the set of all decision problems that can be solved by a deterministic Turing machine in polynomial time with respect to the input size**. This means if a problem can be solved by an algorithm whose running time is bounded by $O(n^k)$ for some constant $k$ (where $n$ is the input size), then the problem is in P. Problems in P are generally considered 'tractable' or efficiently solvable. The statement that problems solvable with time complexity $O(n^k)$ are in P is a direct consequence of this definition.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_limits_pnp_7_q2",
          "questionText": "What is the _most common definition_ of the complexity class **NP** (Non-deterministic Polynomial time) in terms of solution verification?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q2_opt1",
              "optionText": "The set of decision problems for which a 'yes' instance has a certificate (or proof) that can be **verified** in polynomial time by a deterministic algorithm."
            },
            {
              "optionId": "ch_limits_pnp_7_q2_opt2",
              "optionText": "Equivalently, the set of decision problems that can be solved in polynomial time by a **non-deterministic Turing machine**."
            },
            {
              "optionId": "ch_limits_pnp_7_q2_opt3",
              "optionText": "It stands for 'Not Polynomial', meaning problems that cannot be solved in polynomial time."
            },
            {
              "optionId": "ch_limits_pnp_7_q2_opt4",
              "optionText": "All problems in NP are known to be intractable."
            },
            {
              "optionId": "ch_limits_pnp_7_q2_opt5",
              "optionText": "The class P is a subset of NP ($P \\subseteq NP$)."
            },
            {
              "optionId": "ch_limits_pnp_7_q2_opt6",
              "optionText": "The Boolean Satisfiability Problem (SAT) is a well-known example of a problem in NP."
            },
            {
              "optionId": "ch_limits_pnp_7_q2_opt7",
              "optionText": "If a problem is in NP, it means we can always find a solution quickly, but checking it is hard."
            },
            {
              "optionId": "ch_limits_pnp_7_q2_opt8",
              "optionText": "NP problems typically involve searching through an exponentially large space of potential solutions."
            },
            {
              "optionId": "ch_limits_pnp_7_q2_opt9",
              "optionText": "The 'non-deterministic' aspect implies a hypothetical machine that can 'guess' the correct path to a solution and then verify it."
            },
            {
              "optionId": "ch_limits_pnp_7_q2_opt10",
              "optionText": "The Traveling Salesperson Problem (decision version) is in NP."
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q2_opt1"],
          "explanationText": "The most common way to define the class NP (Non-deterministic Polynomial time) is as **the set of decision problems for which a 'yes' instance has a certificate (or proof) that can be verified in polynomial time by a deterministic algorithm**. This means if someone gives you a potential solution to a problem in NP, you can check if it's correct quickly (in polynomial time). An equivalent formal definition is the set of decision problems solvable in polynomial time by a non-deterministic Turing machine. It is known that P is a subset of NP ($P \\subseteq NP$).",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_limits_pnp_7_q3",
          "questionText": "For a problem to be classified as NP-Complete, it must satisfy two essential conditions. Which of the following describes the condition related to the verifiability of its solutions in polynomial time?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q3_opt1",
              "optionText": "The problem must be in the class **NP**."
            },
            {
              "optionId": "ch_limits_pnp_7_q3_opt2",
              "optionText": "The problem must be **NP-hard**."
            },
            {
              "optionId": "ch_limits_pnp_7_q3_opt3",
              "optionText": "The problem must be solvable in polynomial time (in P)."
            },
            {
              "optionId": "ch_limits_pnp_7_q3_opt4",
              "optionText": "The problem must be undecidable."
            },
            {
              "optionId": "ch_limits_pnp_7_q3_opt5",
              "optionText": "The problem must have been first proven NP-Complete by Cook or Levin."
            },
            {
              "optionId": "ch_limits_pnp_7_q3_opt6",
              "optionText": "The problem must be reducible to SAT in polynomial time."
            },
            {
              "optionId": "ch_limits_pnp_7_q3_opt7",
              "optionText": "The problem must involve graph theory."
            },
            {
              "optionId": "ch_limits_pnp_7_q3_opt8",
              "optionText": "The problem must have an exponential number of possible solutions."
            },
            {
              "optionId": "ch_limits_pnp_7_q3_opt9",
              "optionText": "The problem must be a decision problem."
            },
            {
              "optionId": "ch_limits_pnp_7_q3_opt10",
              "optionText": "The problem must not be solvable by a greedy algorithm."
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q3_opt1"],
          "explanationText": "A problem is NP-Complete if it meets two conditions: 1. **The problem must be in the class NP**. This means that if a solution is provided (a 'certificate'), it can be verified in polynomial time. 2. The problem must be NP-hard, meaning every other problem in NP can be reduced to it in polynomial time. The question asks about the condition related to verifiability, which directly corresponds to the problem being in NP.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_limits_pnp_7_q4",
          "questionText": "When we say problem A can be **reduced** to problem B in polynomial time ($A \\le_P B$), what is the _most significant implication_ regarding their relative difficulty?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q4_opt1",
              "optionText": "It means problem A is simpler than problem B."
            },
            {
              "optionId": "ch_limits_pnp_7_q4_opt2",
              "optionText": "There exists an algorithm (the reduction) that can transform any instance of problem A into an instance of problem B, and this transformation takes polynomial time."
            },
            {
              "optionId": "ch_limits_pnp_7_q4_opt3",
              "optionText": "A 'yes' answer for the transformed instance of B must correspond to a 'yes' answer for the original instance of A, and a 'no' answer for B to a 'no' answer for A (for decision problems)."
            },
            {
              "optionId": "ch_limits_pnp_7_q4_opt4",
              "optionText": "This implies that if problem B can be solved in polynomial time, then problem A can also be solved in polynomial time (using the reduction and B's solver)."
            },
            {
              "optionId": "ch_limits_pnp_7_q4_opt5",
              "optionText": "Reductions are a primary tool for proving problems are NP-hard: if a known NP-hard problem $X$ is reduced to $Y$ ($X \\le_P Y$), then $Y$ is also NP-hard."
            },
            {
              "optionId": "ch_limits_pnp_7_q4_opt6",
              "optionText": "It means problem A and problem B are essentially the same problem."
            },
            {
              "optionId": "ch_limits_pnp_7_q4_opt7",
              "optionText": "The transformation must preserve 'yes' instances to 'yes' instances and 'no' instances to 'no' instances for decision problems."
            },
            {
              "optionId": "ch_limits_pnp_7_q4_opt8",
              "optionText": "It implies that problem A is at most as hard as problem B (in terms of polynomial solvability)."
            },
            {
              "optionId": "ch_limits_pnp_7_q4_opt9",
              "optionText": "The reduction itself must be an exponential-time algorithm."
            },
            {
              "optionId": "ch_limits_pnp_7_q4_opt10",
              "optionText": "If problem A is NP-hard and $A \\le_P B$, then B must also be NP-hard."
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q4_opt4"],
          "explanationText": "A polynomial-time reduction from problem A to problem B ($A \\le_P B$) means there's a polynomial-time algorithm to transform any instance of A into an instance of B such that solving the B instance gives a solution to the A instance. The most significant implication is that **if problem B can be solved in polynomial time, then problem A can also be solved in polynomial time**. This is because the total time to solve A would be the polynomial time for reduction plus the polynomial time for solving B. This effectively means A is 'no harder than' B. Reductions are crucial for proving NP-hardness: if a known NP-hard problem A is reduced to B, then B must also be NP-hard.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_limits_pnp_7_q5",
          "questionText": "The **P versus NP problem** is a major unsolved question in computer science. What is the _fundamental question_ it asks?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q5_opt1",
              "optionText": "Fundamentally, it asks whether every problem whose solution can be quickly verified (NP) can also be quickly solved (P)."
            },
            {
              "optionId": "ch_limits_pnp_7_q5_opt2",
              "optionText": "More formally, it asks: Is the class P equal to the class NP ($P=NP$) or is P a proper subset of NP ($P \\subsetneq NP$)?"
            },
            {
              "optionId": "ch_limits_pnp_7_q5_opt3",
              "optionText": "A direct consequence is: can NP-Complete problems be solved by polynomial-time deterministic algorithms? (Yes, if P=NP; likely No, if P!=NP)."
            },
            {
              "optionId": "ch_limits_pnp_7_q5_opt4",
              "optionText": "If $P=NP$, it would imply that many currently intractable problems (like SAT, TSP decision version) have efficient (polynomial-time) solutions."
            },
            {
              "optionId": "ch_limits_pnp_7_q5_opt5",
              "optionText": "Most computer scientists and mathematicians currently believe that $P \\ne NP$."
            },
            {
              "optionId": "ch_limits_pnp_7_q5_opt6",
              "optionText": "A proof for $P=NP$ or $P \\ne NP$ would have profound implications for fields like cryptography, AI, optimization, and mathematics."
            },
            {
              "optionId": "ch_limits_pnp_7_q5_opt7",
              "optionText": "It asks if non-deterministic computation is fundamentally more powerful than deterministic computation in terms of polynomial time solvability."
            },
            {
              "optionId": "ch_limits_pnp_7_q5_opt8",
              "optionText": "The problem has already been solved, and it's known that $P \\ne NP$."
            },
            {
              "optionId": "ch_limits_pnp_7_q5_opt9",
              "optionText": "It is primarily concerned with the space complexity of problems."
            },
            {
              "optionId": "ch_limits_pnp_7_q5_opt10",
              "optionText": "If $P=NP$, then problems like factoring large numbers (basis of RSA) could be done efficiently, breaking current cryptographic schemes. (Note: Factoring is in NP, but not known to be NP-Complete)."
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q5_opt1"],
          "explanationText": "The fundamental question of the P versus NP problem is: **whether every problem for which a proposed solution can be quickly verified (this defines the class NP) can also be quickly solved (this defines the class P)**. 'Quickly' here means in polynomial time. More formally, it asks if the complexity class P is equal to the complexity class NP. If P=NP, it would mean that many problems currently considered very hard to solve (like NP-Complete problems such as SAT or the decision version of TSP) could actually be solved efficiently. Most researchers believe $P \\ne NP$, but this remains unproven.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_limits_pnp_7_q6",
          "questionText": "Which of the following statements _best defines_ what it means for a problem to be undecidable?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q6_opt1",
              "optionText": "It is a problem for which no algorithm can ever be constructed that will always produce a correct yes/no answer for all possible inputs in a finite amount of time."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_opt2",
              "optionText": "The Halting Problem (determining if an arbitrary program will halt or run forever on a given input) is a classic example of an undecidable problem."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_opt3",
              "optionText": "It means the problem is NP-Complete and likely requires exponential time."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_opt4",
              "optionText": "It means no one has yet found an algorithm for it, but one might exist."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_opt5",
              "optionText": "Undecidability is a stronger form of difficulty than NP-hardness; NP-hard problems are decidable (an algorithm exists, possibly exponential), but undecidable problems have no general algorithm at all."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_opt6",
              "optionText": "Alan Turing's work on Turing machines was fundamental in establishing the concept of undecidability."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_opt7",
              "optionText": "Post's Correspondence Problem is another example of an undecidable problem."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_opt8",
              "optionText": "Undecidable problems can often be solved for specific, restricted instances, but not for the general case."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_opt9",
              "optionText": "The Program Equivalence problem (determining if two programs compute the same function) is undecidable."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_opt10",
              "optionText": "All undecidable problems are decision problems."
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q6_opt1"],
          "explanationText": "The best definition of an undecidable problem is that **it is a problem for which no algorithm can ever be constructed that will always produce a correct yes/no answer for all possible inputs in a finite amount of time**. This means there is no general, universally applicable procedure to solve it. The Halting Problem is a classic example illustrating this concept. Undecidability represents a fundamental limit on what can be computed, distinct from NP-hardness (which concerns problems that are decidable but potentially very time-consuming).",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_limits_pnp_7_q7",
          "questionText": "If a problem X is NP-Complete, and we find a polynomial-time reduction from X to a new problem Y (i.e., $X \\le_P Y$), what is the _most immediate conclusion_ we can draw about problem Y's hardness classification?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q7_opt1",
              "optionText": "Problem Y must be in P."
            },
            {
              "optionId": "ch_limits_pnp_7_q7_opt2",
              "optionText": "Problem Y must be NP-hard."
            },
            {
              "optionId": "ch_limits_pnp_7_q7_opt3",
              "optionText": "If problem Y is also known to be in NP, then problem Y is NP-Complete."
            },
            {
              "optionId": "ch_limits_pnp_7_q7_opt4",
              "optionText": "Problem Y is easier than problem X."
            },
            {
              "optionId": "ch_limits_pnp_7_q7_opt5",
              "optionText": "Problem Y cannot be solved in polynomial time unless P=NP."
            },
            {
              "optionId": "ch_limits_pnp_7_q7_opt6",
              "optionText": "This implies that Y is at least as hard as X (in terms of polynomial solvability)."
            },
            {
              "optionId": "ch_limits_pnp_7_q7_opt7",
              "optionText": "Problem Y is undecidable."
            },
            {
              "optionId": "ch_limits_pnp_7_q7_opt8",
              "optionText": "Problem Y must be solvable in exponential time."
            },
            {
              "optionId": "ch_limits_pnp_7_q7_opt9",
              "optionText": "The reduction shows how to solve Y using an algorithm for X."
            },
            {
              "optionId": "ch_limits_pnp_7_q7_opt10",
              "optionText": "Problem Y is a special case of problem X."
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q7_opt2"],
          "explanationText": "If an NP-Complete problem $X$ is polynomially reducible to problem $Y$ (denoted $X \\le_P Y$), the most immediate and direct conclusion regarding $Y$'s hardness classification is that **problem $Y$ must be NP-hard**. This is because NP-hardness means that every problem in NP can be reduced to $Y$ in polynomial time. Since $X$ is NP-Complete, all NP problems reduce to $X$, and $X$ reduces to $Y$, then by transitivity, all NP problems reduce to $Y$. If $Y$ were also shown to be in NP (its solutions verifiable in polynomial time), then $Y$ would be NP-Complete. The statement that '$Y$ cannot be solved in polynomial time unless P=NP' (option `ch_limits_pnp_7_q7_opt5`) is a direct consequence of $Y$ being NP-hard, but NP-hardness itself is the primary classification derived from the reduction.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_limits_pnp_7_q8",
          "questionText": "Among the following, which graph-theoretic problem is a well-known example that has been proven to be NP-Complete?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q8_opt1",
              "optionText": "Finding if a graph contains an Eulerian circuit."
            },
            {
              "optionId": "ch_limits_pnp_7_q8_opt2",
              "optionText": "The Graph Coloring problem (decision version: can the graph be colored with $k$ colors?)."
            },
            {
              "optionId": "ch_limits_pnp_7_q8_opt3",
              "optionText": "Checking if a graph is bipartite."
            },
            {
              "optionId": "ch_limits_pnp_7_q8_opt4",
              "optionText": "Finding a Minimum Spanning Tree in a weighted graph."
            },
            {
              "optionId": "ch_limits_pnp_7_q8_opt5",
              "optionText": "Finding the shortest path between two nodes in a weighted graph."
            },
            {
              "optionId": "ch_limits_pnp_7_q8_opt6",
              "optionText": "The Halting Problem for graph algorithms."
            },
            {
              "optionId": "ch_limits_pnp_7_q8_opt7",
              "optionText": "Topological sorting of a directed acyclic graph."
            },
            {
              "optionId": "ch_limits_pnp_7_q8_opt8",
              "optionText": "Graph Isomorphism (determining if two graphs are structurally identical)."
            },
            {
              "optionId": "ch_limits_pnp_7_q8_opt9",
              "optionText": "Finding the diameter of a graph."
            },
            {
              "optionId": "ch_limits_pnp_7_q8_opt10",
              "optionText": "Maximum flow in a flow network."
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q8_opt2"],
          "explanationText": "The **Graph Coloring problem** (decision version: determining if a graph can be colored with $k$ colors such that no two adjacent vertices share the same color) is a classic NP-Complete problem. Many other problems listed, such as finding Eulerian circuits, checking bipartiteness, Minimum Spanning Tree, shortest path, topological sort, and maximum flow, are solvable in polynomial time (are in P). The Halting Problem is undecidable. Graph Isomorphism is in NP but not known to be NP-Complete or in P.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_limits_pnp_7_q9",
          "questionText": "What was the _most groundbreaking achievement_ of the Cook-Levin theorem in complexity theory?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q9_opt1",
              "optionText": "It proved that P = NP."
            },
            {
              "optionId": "ch_limits_pnp_7_q9_opt2",
              "optionText": "It proved that P is not equal to NP."
            },
            {
              "optionId": "ch_limits_pnp_7_q9_opt3",
              "optionText": "It established that the Boolean Satisfiability Problem (SAT) is NP-Complete."
            },
            {
              "optionId": "ch_limits_pnp_7_q9_opt4",
              "optionText": "SAT was the first problem to be proven NP-Complete, serving as a foundational result."
            },
            {
              "optionId": "ch_limits_pnp_7_q9_opt5",
              "optionText": "It provided the crucial first 'anchor' NP-Complete problem, enabling subsequent NP-Completeness proofs for many other problems via polynomial-time reductions from SAT (or other known NPC problems)."
            },
            {
              "optionId": "ch_limits_pnp_7_q9_opt6",
              "optionText": "It showed that all NP problems can be solved in exponential time."
            },
            {
              "optionId": "ch_limits_pnp_7_q9_opt7",
              "optionText": "It defined the class NP."
            },
            {
              "optionId": "ch_limits_pnp_7_q9_opt8",
              "optionText": "It proved that the Halting Problem is undecidable."
            },
            {
              "optionId": "ch_limits_pnp_7_q9_opt9",
              "optionText": "The theorem shows that any problem solvable by a non-deterministic Turing machine in polynomial time can be effectively encoded as a SAT instance of polynomial size."
            },
            {
              "optionId": "ch_limits_pnp_7_q9_opt10",
              "optionText": "It was independently proven by Stephen Cook and Leonid Levin around the same time."
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q9_opt3"],
          "explanationText": "The most groundbreaking achievement of the Cook-Levin theorem was that **it established that the Boolean Satisfiability Problem (SAT) is NP-Complete**. This was a monumental result because SAT became the very first problem for which NP-completeness was proven. This provided the essential 'anchor' or starting point for the entire theory of NP-completeness, allowing researchers to subsequently prove thousands of other problems NP-Complete by reducing SAT (or other already known NP-Complete problems) to them. The theorem itself did not solve the P versus NP question.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null,
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": []
        },
        {
          "questionId": "ch_limits_pnp_7_q10",
          "questionText": "If it were proven that $P \\ne NP$ (which is widely believed), what would be the _most significant practical consequence_ for attempting to find exact, optimal solutions for NP-Complete problems like the Traveling Salesperson Problem (TSP) for large instances?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q10_opt1",
              "optionText": "It would mean no general polynomial-time algorithm exists for solving these problems exactly for all instances."
            },
            {
              "optionId": "ch_limits_pnp_7_q10_opt2",
              "optionText": "Practitioners would continue to rely heavily on approximation algorithms, heuristics, or algorithms efficient for special cases or average cases for these problems."
            },
            {
              "optionId": "ch_limits_pnp_7_q10_opt3",
              "optionText": "Finding an exact optimal solution for large instances would remain computationally infeasible for many such problems, likely requiring super-polynomial (e.g., exponential) time."
            },
            {
              "optionId": "ch_limits_pnp_7_q10_opt4",
              "optionText": "It would confirm that these problems are fundamentally harder to solve than problems in P."
            },
            {
              "optionId": "ch_limits_pnp_7_q10_opt5",
              "optionText": "It means these problems become undecidable."
            },
            {
              "optionId": "ch_limits_pnp_7_q10_opt6",
              "optionText": "It would have no practical implications, as current algorithms are good enough."
            },
            {
              "optionId": "ch_limits_pnp_7_q10_opt7",
              "optionText": "It would validate the security assumptions of many cryptographic systems that rely on the presumed intractability of certain NP problems (though not all are NP-Complete)."
            },
            {
              "optionId": "ch_limits_pnp_7_q10_opt8",
              "optionText": "It would imply that non-deterministic computation (the ability to 'guess' correctly) is inherently more powerful than deterministic computation for these problems."
            },
            {
              "optionId": "ch_limits_pnp_7_q10_opt9",
              "optionText": "Research would stop on finding exact algorithms for these problems."
            },
            {
              "optionId": "ch_limits_pnp_7_q10_opt10",
              "optionText": "It means these problems can be solved in polynomial time, but only on a non-deterministic Turing machine."
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q10_opt1"],
          "explanationText": "If $P \\ne NP$ were proven, the most significant practical consequence for NP-Complete problems would be that **no general polynomial-time algorithm exists for solving these problems exactly for all instances**. This would confirm their inherent computational difficulty, meaning that finding exact, optimal solutions for large instances would likely require super-polynomial (e.g., exponential) time and thus remain computationally infeasible for many practical purposes. As a result, practitioners would continue to focus on approximation algorithms, heuristics, and methods for special cases to find 'good enough' solutions in a reasonable timeframe.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_limits_pnp_7_q11",
          "questionText": "Which of the following statements _most accurately describes one key conceptual relationship_ between P, NP, and NP-Complete (NPC) classes, assuming the common belief that $P \\ne NP$?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q11_opt1",
              "optionText": "$P$ is a proper subset of $NP$ ($P \\subsetneq NP$)."
            },
            {
              "optionId": "ch_limits_pnp_7_q11_opt2",
              "optionText": "$NPC$ is a subset of $NP$ ($NPC \\subset NP$)."
            },
            {
              "optionId": "ch_limits_pnp_7_q11_opt3",
              "optionText": "The intersection of $P$ and $NPC$ is empty ($P \\cap NPC = \\emptyset$), because if an NPC problem were in P, then P would equal NP."
            },
            {
              "optionId": "ch_limits_pnp_7_q11_opt4",
              "optionText": "If a problem is in $P$, it cannot be $NPC$ (this is a direct consequence if $P \\ne NP$)."
            },
            {
              "optionId": "ch_limits_pnp_7_q11_opt5",
              "optionText": "$NP$ may contain problems that are not in $P$ and not $NPC$ (these are called NP-intermediate problems, e.g., Integer Factorization is a candidate if $P \\ne NP$)."
            },
            {
              "optionId": "ch_limits_pnp_7_q11_opt6",
              "optionText": "$P = NP = NPC$."
            },
            {
              "optionId": "ch_limits_pnp_7_q11_opt7",
              "optionText": "All problems in $NP$ are also $NPC$."
            },
            {
              "optionId": "ch_limits_pnp_7_q11_opt8",
              "optionText": "$NPC$ problems are the 'easiest' problems in $NP$ because they are all reducible to each other."
            },
            {
              "optionId": "ch_limits_pnp_7_q11_opt9",
              "optionText": "Any problem in $NPC$ can be used to solve any other problem in $NP$ with only polynomial overhead via reductions."
            },
            {
              "optionId": "ch_limits_pnp_7_q11_opt10",
              "optionText": "The Halting problem is in $NPC$."
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q11_opt1"],
          "explanationText": "Assuming the widely believed conjecture that $P \\ne NP$, a key conceptual relationship is that **$P$ is a proper subset of $NP$ ($P \\subsetneq NP$)**. This means all problems solvable in polynomial time (P) are also verifiable in polynomial time (NP), but there exist problems in NP that are not solvable in polynomial time. Other true statements under this assumption include: NP-Complete (NPC) problems form a subset of NP; the intersection of P and NPC is empty; and NP might contain NP-intermediate problems (neither in P nor NPC).",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_limits_pnp_7_q12",
          "questionText": "What is a _primary reason_ (related to its proof methodology) why the Halting Problem (asking whether an arbitrary program will halt on a given input) is undecidable?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q12_opt1",
              "optionText": "Because no general algorithm can be constructed that correctly answers this question for all possible program-input pairs in finite time."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_opt2",
              "optionText": "The proof of undecidability often involves a diagonalization argument or a proof by contradiction."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_opt3",
              "optionText": "A common proof technique shows that if such a halting-checker algorithm (H) existed, one could construct a paradoxical program (P) that feeds its own description to H and then does the opposite of what H predicts P will do, leading to a contradiction."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_opt4",
              "optionText": "Because it is NP-Complete, and P is likely not equal to NP."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_opt5",
              "optionText": "Because programs can be infinitely long."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_opt6",
              "optionText": "It means we can never determine if _any_ specific program will halt."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_opt7",
              "optionText": "The problem is decidable for very simple programs or finite state machines."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_opt8",
              "optionText": "Its undecidability was first proven by Alan Turing in the context of Turing machines."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_opt9",
              "optionText": "Its undecidability implies that automatic full verification of all software properties (like proving freedom from all infinite loops) is impossible."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_opt10",
              "optionText": "Because some programs require exponential time to halt."
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q12_opt3"],
          "explanationText": "A primary reason for the Halting Problem's undecidability, related to its proof methodology, is that **a common proof technique shows that if such a halting-checker algorithm (H) existed, one could construct a paradoxical program (P) that feeds its own description to H and then does the opposite of what H predicts P will do, leading to a contradiction**. This method, often involving a self-referential argument similar to diagonalization, demonstrates the impossibility of a general halting decider. While the statement that 'no general algorithm can be constructed' is the definition of undecidability, and Alan Turing's proof is historical, the paradoxical construction is central to _how_ this undecidability is proven.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_limits_pnp_7_q6_partA_definition",
          "questionText": "What does it most fundamentally mean for a problem to be **undecidable**?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q6_partA_opt1",
              "optionText": "No algorithm can ever be constructed that will always produce a correct yes/no answer for all possible inputs in a finite amount of time."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partA_opt2",
              "optionText": "It means the problem is NP-Complete and likely requires exponential time."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partA_opt3",
              "optionText": "It means no one has yet found an algorithm for it, but one might exist."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partA_opt4",
              "optionText": "Undecidability is a stronger form of difficulty than NP-hardness; NP-hard problems are decidable, but undecidable problems have no general algorithm."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partA_opt5",
              "optionText": "All undecidable problems are decision problems."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partA_opt6",
              "optionText": "It can be solved for specific, restricted instances, but not for the general case."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partA_opt7",
              "optionText": "Its solution is known but too complex to implement."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partA_opt8",
              "optionText": "It requires a non-deterministic Turing machine to solve."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partA_opt9",
              "optionText": "It primarily relates to problems with infinite output spaces."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partA_opt10",
              "optionText": "It is a problem that can only be solved by quantum computers."
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q6_partA_opt1"],
          "explanationText": "The most fundamental meaning of undecidability is that **no algorithm can ever be constructed that will always produce a correct yes/no answer for all possible inputs in a finite amount of time**. This is a core definition. Undecidability implies a stronger form of difficulty than NP-hardness; NP-hard problems are decidable (an algorithm exists, possibly exponential), but undecidable problems have no general algorithm at all.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_limits_pnp_7_q6_partB_example",
          "questionText": "Which of the following is a classic example of an undecidable problem in computer science?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q6_partB_opt1",
              "optionText": "The Boolean Satisfiability Problem (SAT)."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partB_opt2",
              "optionText": "The Halting Problem."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partB_opt3",
              "optionText": "Sorting an array of numbers."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partB_opt4",
              "optionText": "The Traveling Salesperson Problem (TSP)."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partB_opt5",
              "optionText": "Finding the shortest path in a graph."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partB_opt6",
              "optionText": "Post's Correspondence Problem."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partB_opt7",
              "optionText": "The Program Equivalence problem."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partB_opt8",
              "optionText": "Integer Factorization."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partB_opt9",
              "optionText": "Vertex Cover Problem."
            },
            {
              "optionId": "ch_limits_pnp_7_q6_partB_opt10",
              "optionText": "Matrix Multiplication."
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q6_partB_opt2"],
          "explanationText": "**The Halting Problem** (determining if an arbitrary program will halt or run forever on a given input) is a classic example of an undecidable problem. Other examples include Post's Correspondence Problem and the Program Equivalence problem. Problems like SAT, TSP, and Vertex Cover are NP-Complete (and thus decidable, though hard), while Sorting and Shortest Path are in P (efficiently solvable).",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_limits_pnp_7_q12_partA_reason",
          "questionText": "What is a primary reason why the Halting Problem (asking whether an arbitrary program will halt on a given input) is undecidable?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q12_partA_opt1",
              "optionText": "No general algorithm can be constructed that correctly answers this question for all possible program-input pairs in finite time."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partA_opt2",
              "optionText": "The proof involves a diagonalization argument or a proof by contradiction, showing that a hypothetical halting-checker leads to a paradox."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partA_opt3",
              "optionText": "Because it is NP-Complete, and P is likely not equal to NP."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partA_opt4",
              "optionText": "Because computer programs can be infinitely long."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partA_opt5",
              "optionText": "It implies that automatic full verification of all software properties is impossible."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partA_opt6",
              "optionText": "It is decidable for finite state machines."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partA_opt7",
              "optionText": "Because some programs require exponential time to halt."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partA_opt8",
              "optionText": "Its solution space is too large to search."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partA_opt9",
              "optionText": "The problem definition is ambiguous."
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partA_opt10",
              "optionText": "It was proven undecidable using a model of computation weaker than Turing machines."
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q12_partA_opt1"],
          "explanationText": "A primary reason the Halting Problem is undecidable is that **no general algorithm can be constructed that correctly answers whether any arbitrary program will halt on a given input for all possible program-input pairs in a finite amount of time**. Proofs of this, like Turing's original proof, often use a method of contradiction (related to diagonalization): if such a halting-checker algorithm existed, one could construct a paradoxical program that behaves contrary to the checker's prediction about itself, leading to a logical impossibility. The implication for software verification, while significant, is a consequence of this fundamental undecidability.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_limits_pnp_7_q12_partB_history",
          "questionText": "Who first proved the undecidability of the Halting Problem?",
          "options": [
            {
              "optionId": "ch_limits_pnp_7_q12_partB_opt1",
              "optionText": "Stephen Cook"
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partB_opt2",
              "optionText": "Leonid Levin"
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partB_opt3",
              "optionText": "Alan Turing"
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partB_opt4",
              "optionText": "Kurt Gödel"
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partB_opt5",
              "optionText": "Alonzo Church"
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partB_opt6",
              "optionText": "John von Neumann"
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partB_opt7",
              "optionText": "Edsger Dijkstra"
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partB_opt8",
              "optionText": "Richard Karp"
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partB_opt9",
              "optionText": "Donald Knuth"
            },
            {
              "optionId": "ch_limits_pnp_7_q12_partB_opt10",
              "optionText": "Noam Chomsky"
            }
          ],
          "correctOptionIds": ["ch_limits_pnp_7_q12_partB_opt3"],
          "explanationText": "The undecidability of the Halting Problem was first proven by **Alan Turing** in 1936 in his seminal paper on Turing machines. This was a foundational result in the theory of computation.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        }
      ],
      "totalQuestions": 16,
      "answeredQuestions": 0,
      "correctAnswers": 0,
      "isCompleted": false
    },
    {
      "id": "ch_regex_fsm_8",
      "name": "Chapter 8: Regular Expressions and Finite State Machines",
      "description": "Covers formal language basics, operations on languages, regular expression syntax and semantics, Finite State Machine (FSM) components and operation, and the equivalence between regex and FSMs.",
      "questions": [
        {
          "chapterIdToAddTo": "ch_regex_fsm_8",
          "questionId": "ch_regex_fsm_8_q1",
          "questionText": "In formal language theory, what is an 'alphabet' (often denoted $\\Sigma$)?",
          "options": [
            {
              "optionId": "ch_regex_fsm_8_q1_partA_opt1",
              "optionText": "A finite, non-empty set of symbols (or letters)."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partA_opt2",
              "optionText": "A <b>string</b> (or word): a finite sequence of symbols chosen from an alphabet."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partA_opt3",
              "optionText": "A <b>language</b>: a set of strings over a particular alphabet (can be finite or infinite)."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partA_opt4",
              "optionText": "$\\Sigma^*$ denotes the set of all possible strings over the alphabet $\\Sigma$, including the empty string."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partA_opt5",
              "optionText": "Grammar rules specific to natural languages like English."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partA_opt6",
              "optionText": "An infinite set of characters."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partA_opt7",
              "optionText": "The empty string, often denoted by $\\epsilon$ or $\\lambda$."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partA_opt8",
              "optionText": "A specific programming language's keywords."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partA_opt9",
              "optionText": "A regular expression used to define a language."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partA_opt10",
              "optionText": "A state in a finite automaton."
            }
          ],
          "correctOptionIds": ["ch_regex_fsm_8_q1_partA_opt1"],
          "explanationText": "An <b>alphabet</b> ($\\Sigma$) in formal language theory is defined as a <b>finite, non-empty set of symbols</b> (also called letters or characters). For example, $\\Sigma = \\{0, 1\\}$ is the binary alphabet, and $\\Sigma = \\{a, b, c\\}$ is another common example. Strings are formed from symbols in an alphabet, and languages are sets of these strings.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "chapterIdToAddTo": "ch_regex_fsm_8",
          "questionId": "ch_regex_fsm_8_q1_part3",
          "questionText": "How is a 'language' defined in the context of formal language theory?",
          "options": [
            {
              "optionId": "ch_regex_fsm_8_q1_partC_opt1",
              "optionText": "A finite, non-empty set of symbols."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partC_opt2",
              "optionText": "A finite sequence of symbols chosen from an alphabet."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partC_opt3",
              "optionText": "A set of finite sequences of symbols (strings), where each symbol is from a particular alphabet."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partC_opt4",
              "optionText": "Only infinite sets of strings can be languages."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partC_opt5",
              "optionText": "The set of all possible strings over an alphabet, $\\Sigma^*$ (this is one specific example, not the general definition)."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partC_opt6",
              "optionText": "A specific type of grammar, like a Context-Free Grammar."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partC_opt7",
              "optionText": "The empty set $\\emptyset$ cannot be considered a language."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partC_opt8",
              "optionText": "A natural communication system like English or Spanish."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partC_opt9",
              "optionText": "A regular expression itself (a regular expression *describes* a language)."
            },
            {
              "optionId": "ch_regex_fsm_8_q1_partC_opt10",
              "optionText": "A single, very long string of symbols."
            }
          ],
          "correctOptionIds": ["ch_regex_fsm_8_q1_partC_opt3"],
          "explanationText": "A <b>language</b> in formal language theory is defined as a <b>set of finite sequences of symbols (strings), where each symbol in those strings is drawn from a specific alphabet</b>. A language can be finite (containing a limited number of strings, e.g., $\\{'cat', 'dog'\\}$) or infinite (e.g., all binary strings with an even number of 0s). The set of all possible strings $\\Sigma^*$ is one example of a language, as is the empty set $\\emptyset$ (the language containing no strings), and the set containing only the empty string, $\\{\\epsilon\\}$.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_regex_fsm_8_q2",
          "questionText": "Given languages $L_1 = \\{a, ab\\}$ and $L_2 = \\{b, bc\\}$ over $\\Sigma = \\{a, b, c\\}$. What is the result of the concatenation operation $L_1 L_2$?",
          "options": [
            {
              "optionId": "ch_regex_fsm_8_q2_opt1",
              "optionText": "$\\{a, ab, b, bc\\}$"
            },
            {
              "optionId": "ch_regex_fsm_8_q2_opt2",
              "optionText": "$\\{ab, abc, abb, abbc\\}$"
            },
            {
              "optionId": "ch_regex_fsm_8_q2_opt3",
              "optionText": "$\\{\\epsilon\\}$"
            },
            {
              "optionId": "ch_regex_fsm_8_q2_opt4",
              "optionText": "$\\{\\epsilon, a, ab, aa, aab, aba, abab, \\dots \\}$"
            },
            {
              "optionId": "ch_regex_fsm_8_q2_opt5",
              "optionText": "$\\{a, b, c, aa, bb, cc, \\dots \\}$"
            },
            {
              "optionId": "ch_regex_fsm_8_q2_opt6",
              "optionText": "$\\{ba, bca, bab, bcab\\}$"
            },
            {
              "optionId": "ch_regex_fsm_8_q2_opt7",
              "optionText": "$\\{ab, bc\\}$"
            },
            {
              "optionId": "ch_regex_fsm_8_q2_opt8",
              "optionText": "The set of all strings from $L_1$ followed by all strings from $L_2$ individually."
            },
            {
              "optionId": "ch_regex_fsm_8_q2_opt9",
              "optionText": "$\\{ac, abc, abac, abbc\\}$"
            },
            {
              "optionId": "ch_regex_fsm_8_q2_opt10",
              "optionText": "$\\{a, ab, b, bc, ab, abc, abb, abbc\\}$"
            }
          ],
          "correctOptionIds": ["ch_regex_fsm_8_q2_opt2"],
          "explanationText": "The concatenation $L_1 L_2$ is formed by taking every string $s_1$ from $L_1$ and appending every string $s_2$ from $L_2$ to it. <br>Given $L_1 = \\{a, ab\\}$ and $L_2 = \\{b, bc\\}$: <br>- Take 'a' from $L_1$: 'a' + 'b' = 'ab'; 'a' + 'bc' = 'abc'. <br>- Take 'ab' from $L_1$: 'ab' + 'b' = 'abb'; 'ab' + 'bc' = 'abbc'. <br>Thus, $L_1 L_2 = \\{ab, abc, abb, abbc\\}$.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_regex_fsm_8_q3",
          "questionText": "The regular expression `(a|b)*abb` describes a set of strings. Which of the following statements _most accurately defines this set_?",
          "options": [
            {
              "optionId": "ch_regex_fsm_8_q3_opt1",
              "optionText": "Any string of `a`'s and `b`'s that ends with the sequence `abb`."
            },
            {
              "optionId": "ch_regex_fsm_8_q3_opt2",
              "optionText": "` `(a|b)*` means zero or more occurrences of either `a` or `b`."
            },
            {
              "optionId": "ch_regex_fsm_8_q3_opt3",
              "optionText": "Strings like `abb`, `aabb`, `babb`, `aaabb` are in the language."
            },
            {
              "optionId": "ch_regex_fsm_8_q3_opt4",
              "optionText": "Strings that start with `abb`."
            },
            {
              "optionId": "ch_regex_fsm_8_q3_opt5",
              "optionText": "Strings that contain `abb` anywhere."
            },
            {
              "optionId": "ch_regex_fsm_8_q3_opt6",
              "optionText": "The string `ab` is not in this language."
            },
            {
              "optionId": "ch_regex_fsm_8_q3_opt7",
              "optionText": "The string `ababa` is not in this language."
            },
            {
              "optionId": "ch_regex_fsm_8_q3_opt8",
              "optionText": "The shortest string in the language is `abb`."
            },
            {
              "optionId": "ch_regex_fsm_8_q3_opt9",
              "optionText": "It describes an infinite language."
            },
            {
              "optionId": "ch_regex_fsm_8_q3_opt10",
              "optionText": "It is equivalent to `(a*|b*)abb`."
            }
          ],
          "correctOptionIds": ["ch_regex_fsm_8_q3_opt1"],
          "explanationText": "The regular expression `(a|b)*abb` describes **any string of `a`'s and `b`'s that ends with the fixed sequence `abb`**. The `(a|b)*` part matches zero or more occurrences of either `a` or `b` (any sequence of `a`'s and `b`'s, including the empty string). This is then followed by the literal string `abb`. Examples include `abb`, `aabb`, `babb`, `abababb`. The shortest string is `abb`. It does not describe strings that merely contain `abb` (that would be `(a|b)*abb(a|b)*`).",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_regex_fsm_8_q4",
          "questionText": "Which of the following is an essential component in the formal 5-tuple definition of a Finite Automaton (FA) as a language recognizer? (Select any one essential component.)",
          "options": [
            {
              "optionId": "ch_regex_fsm_8_q4_opt1",
              "optionText": "A finite set of **states** ($Q$)."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_opt2",
              "optionText": "A finite input **alphabet** ($\\Sigma$)."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_opt3",
              "optionText": "A **transition function** ($\\delta : Q \\times \\Sigma \\rightarrow Q$ for a Deterministic FSM)."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_opt4",
              "optionText": "A designated **start state** ($q_0 \\in Q$)."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_opt5",
              "optionText": "A set of **accept (or final) states** ($F \\subseteq Q$)."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_opt6",
              "optionText": "An infinite tape for memory storage."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_opt7",
              "optionText": "A stack for managing nested calls."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_opt8",
              "optionText": "A set of production rules (like in grammars)."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_opt9",
              "optionText": "For a Non-deterministic FSM (NFA), the transition function can map to a set of states ($\\delta : Q \\times (\\Sigma \\cup \\{\\epsilon\\}) \\rightarrow \\mathcal{P}(Q)$)."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_opt10",
              "optionText": "An output alphabet and an output function (for FSMs that produce output, like Mealy/Moore machines, distinct from recognizers)."
            }
          ],
          "correctOptionIds": [
            "ch_regex_fsm_8_q4_opt1",
            "ch_regex_fsm_8_q4_opt2",
            "ch_regex_fsm_8_q4_opt3",
            "ch_regex_fsm_8_q4_opt4",
            "ch_regex_fsm_8_q4_opt5"
          ],
          "explanationText": "A Finite Automaton (FA) as a language recognizer is formally a 5-tuple: $Q$ (a finite set of states), $\\Sigma$ (a finite input alphabet), $\\delta$ (a transition function), $q_0$ (a start state), and $F$ (a set of accept states). Selecting any of these components (e.g., 'a finite set of states', 'a transition function', or 'a set of accept states') identifies an essential part of this definition. The transition function for an NFA, as described in another option, is a variation for non-deterministic machines. Components like an infinite tape or a stack belong to more powerful computational models, not FAs.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_regex_fsm_8_q5",
          "questionText": "How does a Deterministic Finite Automaton (DFA) _primarily determine if an input string is accepted_?",
          "options": [
            {
              "optionId": "ch_regex_fsm_8_q5_opt1",
              "optionText": "It starts in the designated start state."
            },
            {
              "optionId": "ch_regex_fsm_8_q5_opt2",
              "optionText": "For each symbol in the input string (read from left to right), it follows the unique transition defined by the current state and the input symbol to a new state."
            },
            {
              "optionId": "ch_regex_fsm_8_q5_opt3",
              "optionText": "If, after processing all symbols, the DFA is in one of the accept states, the string is accepted; otherwise, it is rejected."
            },
            {
              "optionId": "ch_regex_fsm_8_q5_opt4",
              "optionText": "If at any point there is no valid transition for the current state and input symbol, the string is rejected (though for a complete DFA, a transition always exists, possibly to a 'dead' state)."
            },
            {
              "optionId": "ch_regex_fsm_8_q5_opt5",
              "optionText": "It can make multiple transitions simultaneously on one input symbol."
            },
            {
              "optionId": "ch_regex_fsm_8_q5_opt6",
              "optionText": "It can use $\\epsilon$-transitions (transitions without consuming an input symbol)."
            },
            {
              "optionId": "ch_regex_fsm_8_q5_opt7",
              "optionText": "The DFA must have at least one accept state to accept any string (other than the empty language)."
            },
            {
              "optionId": "ch_regex_fsm_8_q5_opt8",
              "optionText": "The input string is processed from right to left."
            },
            {
              "optionId": "ch_regex_fsm_8_q5_opt9",
              "optionText": "It uses a stack to remember previous states."
            },
            {
              "optionId": "ch_regex_fsm_8_q5_opt10",
              "optionText": "Acceptance depends on the path taken, not just the final state."
            }
          ],
          "correctOptionIds": ["ch_regex_fsm_8_q5_opt3"],
          "explanationText": "A Deterministic Finite Automaton (DFA) processes an input string by starting in its designated start state and making a unique transition for each input symbol based on its current state and that symbol. The primary way a DFA determines acceptance is: **if, after processing all symbols in the input string, the DFA is in one of its designated accept (or final) states, the string is accepted; otherwise, it is rejected**. The path taken to reach the final state is determined by the input string and the DFA's transitions, but the acceptance itself is solely based on whether the state reached _after the entire string is read_ is an accept state.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_regex_fsm_8_q6",
          "questionText": "What is the _most fundamental relationship_ between regular expressions and finite automata (DFAs and NFAs) in terms of the languages they can describe?",
          "options": [
            {
              "optionId": "ch_regex_fsm_8_q6_opt1",
              "optionText": "They are **equivalent in expressive power**: any language that can be described by a regular expression can be recognized by a finite automaton, and vice-versa."
            },
            {
              "optionId": "ch_regex_fsm_8_q6_opt2",
              "optionText": "This means regular expressions and finite automata both define the class of **regular languages**."
            },
            {
              "optionId": "ch_regex_fsm_8_q6_opt3",
              "optionText": "Algorithms exist to convert any regular expression into an equivalent NFA (e.g., Thompson's construction)."
            },
            {
              "optionId": "ch_regex_fsm_8_q6_opt4",
              "optionText": "Algorithms exist to convert any NFA into an equivalent DFA (e.g., subset construction)."
            },
            {
              "optionId": "ch_regex_fsm_8_q6_opt5",
              "optionText": "Algorithms exist to convert any DFA into an equivalent regular expression (e.g., state elimination or using Arden's theorem)."
            },
            {
              "optionId": "ch_regex_fsm_8_q6_opt6",
              "optionText": "Regular expressions are generally more powerful than finite automata."
            },
            {
              "optionId": "ch_regex_fsm_8_q6_opt7",
              "optionText": "Finite automata are generally more powerful than regular expressions."
            },
            {
              "optionId": "ch_regex_fsm_8_q6_opt8",
              "optionText": "DFAs are more powerful than NFAs."
            },
            {
              "optionId": "ch_regex_fsm_8_q6_opt9",
              "optionText": "NFAs are more powerful than DFAs."
            },
            {
              "optionId": "ch_regex_fsm_8_q6_opt10",
              "optionText": "Converting a DFA to a regex can result in an exponentially larger regex."
            }
          ],
          "correctOptionIds": ["ch_regex_fsm_8_q6_opt1"],
          "explanationText": "The most fundamental relationship (established by Kleene's Theorem) is that regular expressions and finite automata (both DFAs and NFAs, as DFAs and NFAs are also equivalent in power) are **equivalent in expressive power**. This means that any language that can be described by a regular expression can also be recognized by some finite automaton, and conversely, any language recognized by a finite automaton can be described by some regular expression. Both formalisms precisely define the class of **regular languages**. Algorithms exist for conversions between these models (regex to NFA, NFA to DFA, DFA to regex).",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_regex_fsm_8_q7",
          "questionText": "When designing a Finite State Machine for the language of strings over $\\Sigma = \\{a, b\\}$ that contain an **odd number of `a`'s**, what is the _minimum number of states required_, and what would be the accept state?",
          "options": [
            {
              "optionId": "ch_regex_fsm_8_q7_opt1",
              "optionText": "Two states: $q_{even}$ (start, non-accept) for even `a`'s seen, and $q_{odd}$ (accept) for odd `a`'s seen."
            },
            {
              "optionId": "ch_regex_fsm_8_q7_opt2",
              "optionText": "One state that counts the number of `a`'s and becomes an accept state if the count is odd."
            },
            {
              "optionId": "ch_regex_fsm_8_q7_opt3",
              "optionText": "Three states: start, one `a` seen (accept), more than one `a` seen (non-accept if even, accept if odd)."
            },
            {
              "optionId": "ch_regex_fsm_8_q7_opt4",
              "optionText": "Two states: $q_{start}$ (non-accept), and $q_{accept}$ (accept), where reading an 'a' always transitions to $q_{accept}$."
            },
            {
              "optionId": "ch_regex_fsm_8_q7_opt5",
              "optionText": "An FSM cannot recognize this language as it requires counting."
            },
            {
              "optionId": "ch_regex_fsm_8_q7_opt6",
              "optionText": "Four states: (even a's, last was a), (even a's, last was b), (odd a's, last was a), (odd a's, last was b)."
            },
            {
              "optionId": "ch_regex_fsm_8_q7_opt7",
              "optionText": "The start state should be $q_{odd}$ because an empty string has zero 'a's (even) and we want odd."
            },
            {
              "optionId": "ch_regex_fsm_8_q7_opt8",
              "optionText": "Only one state is needed if it's an NFA."
            },
            {
              "optionId": "ch_regex_fsm_8_q7_opt9",
              "optionText": "The transitions would be: on 'a', $q_{even} \\leftrightarrow q_{odd}$; on 'b', states remain unchanged."
            },
            {
              "optionId": "ch_regex_fsm_8_q7_opt10",
              "optionText": "Minimum three states are required to track parity and the last symbol."
            }
          ],
          "correctOptionIds": ["ch_regex_fsm_8_q7_opt1"],
          "explanationText": "To recognize strings with an odd number of `a`'s, a minimum of **two states** is required. One state, say $q_{even}$, represents having seen an even number of `a`'s so far. This would be the start state (as the empty string has zero, i.e., an even number of `a`'s) and would not be an accept state. The second state, $q_{odd}$, represents having seen an odd number of `a`'s, and this would be the accept state. Reading an `a` causes a transition between $q_{even}$ and $q_{odd}$ (as described in the option stating 'on 'a', $q_{even} \\leftrightarrow q_{odd}$'). Reading a `b` does not change the parity of `a`'s, so it would cause a transition from $q_{even}$ to $q_{even}$ and from $q_{odd}$ to $q_{odd}$.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_regex_fsm_8_q8",
          "questionText": "What does the regular expression shorthand `[0-9]+` primarily represent?",
          "options": [
            {
              "optionId": "ch_regex_fsm_8_q8_opt1",
              "optionText": "One or more occurrences of any digit from 0 to 9."
            },
            {
              "optionId": "ch_regex_fsm_8_q8_opt2",
              "optionText": "`[0-9]` means 'any character that is a digit from 0 to 9'."
            },
            {
              "optionId": "ch_regex_fsm_8_q8_opt3",
              "optionText": "The `+` (Kleene plus) operator means 'one or more' repetitions of the preceding item."
            },
            {
              "optionId": "ch_regex_fsm_8_q8_opt4",
              "optionText": "Exactly one digit."
            },
            {
              "optionId": "ch_regex_fsm_8_q8_opt5",
              "optionText": "Zero or more digits (that would be `[0-9]*`)."
            },
            {
              "optionId": "ch_regex_fsm_8_q8_opt6",
              "optionText": "A string containing only the digit 9, repeated one or more times."
            },
            {
              "optionId": "ch_regex_fsm_8_q8_opt7",
              "optionText": "Any number, including those with decimal points."
            },
            {
              "optionId": "ch_regex_fsm_8_q8_opt8",
              "optionText": "Strings like `1`, `123`, `0`, `9999` are in this language."
            },
            {
              "optionId": "ch_regex_fsm_8_q8_opt9",
              "optionText": "The empty string $\\epsilon$ is in this language."
            },
            {
              "optionId": "ch_regex_fsm_8_q8_opt10",
              "optionText": "`zero or more occurences of (0|1|2|3|4|5|6|7|8|9)` followed by zero or more of `(0|1|2|3|4|5|6|7|8|9)`."
            }
          ],
          "correctOptionIds": ["ch_regex_fsm_8_q8_opt1"],
          "explanationText": "The regular expression shorthand `[0-9]+` primarily represents **one or more occurrences of any digit from 0 to 9**. The character class `[0-9]` matches any single digit. The `+` (Kleene plus) quantifier means the preceding element (a digit) must appear one or more times. This 'one or more' structure can also be expressed as one instance of the element followed by zero or more instances of the element (e.g., $X^+$ is equivalent to $XX^*$). So, `[0-9]+` is equivalent to `[0-9][0-9]*`. Using a more verbose notation with ORs for each digit, this means one digit (e.g., `(0|1|2|3|4|5|6|7|8|9)`) followed by zero or more occurrences of any digit (e.g., `(0|1|2|3|4|5|6|7|8|9)*`).",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_regex_fsm_8_q9",
          "questionText": "Which of the following languages, often requiring unbounded memory or counting to match symbol occurrences, is a classic example of a language that is **NOT** regular?",
          "options": [
            {
              "optionId": "ch_regex_fsm_8_q9_opt1",
              "optionText": "The language $L = \\{a^n b^n \\mid n \\ge 0\\}$ (strings of $n$ `a`'s followed by $n$ `b`'s)."
            },
            {
              "optionId": "ch_regex_fsm_8_q9_opt2",
              "optionText": "The language of all strings over $\\Sigma = \\{a,b\\}$ (i.e., $(a|b)^*$)."
            },
            {
              "optionId": "ch_regex_fsm_8_q9_opt3",
              "optionText": "The language of binary strings representing numbers divisible by 3."
            },
            {
              "optionId": "ch_regex_fsm_8_q9_opt4",
              "optionText": "The language of all strings over $\\Sigma = \\{a, b\\}$ that end with `ab`."
            },
            {
              "optionId": "ch_regex_fsm_8_q9_opt5",
              "optionText": "The language of all strings over $\\Sigma = \\{a, b\\}$ with an even number of `a`'s."
            },
            {
              "optionId": "ch_regex_fsm_8_q9_opt6",
              "optionText": "The language consisting of only the string '`apple`'."
            },
            {
              "optionId": "ch_regex_fsm_8_q9_opt7",
              "optionText": "The language of strings with an odd number of `b`'s."
            },
            {
              "optionId": "ch_regex_fsm_8_q9_opt8",
              "optionText": "Any finite language is regular."
            },
            {
              "optionId": "ch_regex_fsm_8_q9_opt9",
              "optionText": "The language described by `a_b_`."
            },
            {
              "optionId": "ch_regex_fsm_8_q9_opt10",
              "optionText": "The language of correctly matched parentheses (e.g., $(()())$)."
            }
          ],
          "correctOptionIds": ["ch_regex_fsm_8_q9_opt1"],
          "explanationText": "The language $L = \\{a^n b^n \\mid n \\ge 0\\}$ is a classic example of a language that is **NOT regular**. Recognizing this language requires counting the number of 'a's and ensuring an equal number of 'b's follow, which needs unbounded memory that Finite Automata (recognizers for regular languages) do not possess. Languages like balanced parentheses (option `ch_regex_fsm_8_q9_opt10`) are also not regular (they are context-free). The other options list examples of regular languages.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_regex_fsm_8_q10",
          "questionText": "What is the _fundamental limitation_ of Finite State Machines (and thus Regular Expressions) that prevents them from recognizing languages like $L = \\{a^n b^n \\mid n \\ge 0\\}$?",
          "options": [
            {
              "optionId": "ch_regex_fsm_8_q10_opt1",
              "optionText": "They have a **finite number of states**, and thus finite memory."
            },
            {
              "optionId": "ch_regex_fsm_8_q10_opt2",
              "optionText": "To recognize $a^n b^n$, the machine would need to 'remember' the exact count of `a`'s seen, which can be arbitrarily large."
            },
            {
              "optionId": "ch_regex_fsm_8_q10_opt3",
              "optionText": "This requires unbounded memory or counting capability, which FSMs do not possess."
            },
            {
              "optionId": "ch_regex_fsm_8_q10_opt4",
              "optionText": "They cannot handle nested structures."
            },
            {
              "optionId": "ch_regex_fsm_8_q10_opt5",
              "optionText": "Their transition function is too simple."
            },
            {
              "optionId": "ch_regex_fsm_8_q10_opt6",
              "optionText": "They can only recognize patterns with bounded repetition."
            },
            {
              "optionId": "ch_regex_fsm_8_q10_opt7",
              "optionText": "The Pumping Lemma for regular languages formally captures this limitation."
            },
            {
              "optionId": "ch_regex_fsm_8_q10_opt8",
              "optionText": "They lack a stack or other auxiliary memory."
            },
            {
              "optionId": "ch_regex_fsm_8_q10_opt9",
              "optionText": "They can only perform local checks, not global correspondence over arbitrary distances."
            },
            {
              "optionId": "ch_regex_fsm_8_q10_opt10",
              "optionText": "They can be converted to Context-Free Grammars, which can recognize such languages."
            }
          ],
          "correctOptionIds": ["ch_regex_fsm_8_q10_opt1"],
          "explanationText": "The fundamental limitation of Finite State Machines (FSMs) is that **they have a finite number of states, and thus only finite memory**. To recognize languages like $L = \\{a^n b^n \\mid n \\ge 0\\}$, where $n$ can be arbitrarily large, the machine would need to remember the exact count of `a`'s to ensure an equal number of `b`'s follow. This requires an unbounded counting capability, which cannot be achieved with a fixed, finite number of states. FSMs lack auxiliary memory like a stack, which is needed for such languages (these are recognized by Pushdown Automata).",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "questionId": "ch_regex_fsm_8_q4_partA",
          "questionText": "In the formal 5-tuple definition of a Finite Automaton (FA) ($Q, \\Sigma, \\delta, q_0, F$), what does the component $Q$ represent?",
          "options": [
            {
              "optionId": "ch_regex_fsm_8_q4_partA_opt1",
              "optionText": "A finite set of **states**."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partA_opt2",
              "optionText": "A finite input **alphabet**."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partA_opt3",
              "optionText": "A **transition function**."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partA_opt4",
              "optionText": "A designated **start state**."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partA_opt5",
              "optionText": "A set of **accept (or final) states**."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partA_opt6",
              "optionText": "The language recognized by the FA."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partA_opt7",
              "optionText": "The set of all possible input strings."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partA_opt8",
              "optionText": "An output function for the FA."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partA_opt9",
              "optionText": "A stack used by the FA."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partA_opt10",
              "optionText": "A counter for input symbols."
            }
          ],
          "correctOptionIds": ["ch_regex_fsm_8_q4_partA_opt1"],
          "explanationText": "In the 5-tuple definition of a Finite Automaton ($M = (Q, \\Sigma, \\delta, q_0, F)$), the component $Q$ represents **a finite set of states**. These states define the different configurations the automaton can be in while processing an input string.",
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "questionId": "ch_regex_fsm_8_q4_partB",
          "questionText": "What is the role of the transition function $\\delta$ in the formal definition of a Deterministic Finite Automaton (DFA)?",
          "options": [
            {
              "optionId": "ch_regex_fsm_8_q4_partB_opt1",
              "optionText": "It defines the finite set of states."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partB_opt2",
              "optionText": "It specifies the input alphabet."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partB_opt3",
              "optionText": "It maps a pair (current state, input symbol) to a next state."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partB_opt4",
              "optionText": "It designates the initial state of the automaton."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partB_opt5",
              "optionText": "It identifies the set of accept states."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partB_opt6",
              "optionText": "It determines if an input string is accepted or rejected directly."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partB_opt7",
              "optionText": "For an NFA, it maps to a set of possible next states."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partB_opt8",
              "optionText": "It allows transitions on the empty string $\\epsilon$."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partB_opt9",
              "optionText": "It always ensures the DFA halts."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partB_opt10",
              "optionText": "It is typically represented as a table or a state diagram."
            }
          ],
          "correctOptionIds": ["ch_regex_fsm_8_q4_partB_opt3"],
          "explanationText": "The transition function $\\delta$ in a Deterministic Finite Automaton (DFA) **maps a pair consisting of the current state and the current input symbol to a uniquely determined next state**. Formally, $\\delta: Q \\times \\Sigma \\rightarrow Q$. This function dictates how the DFA moves from state to state as it processes an input string. Option `ch_regex_fsm_8_q4_partB_opt10` describes its representation, not its role.",
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "questionId": "ch_regex_fsm_8_q4_partC",
          "questionText": "In the 5-tuple definition of a Finite Automaton (`FA`) ($Q, \\Sigma, \\delta, q_0, F$), what is the significance of the component $F$?",
          "options": [
            {
              "optionId": "ch_regex_fsm_8_q4_partC_opt1",
              "optionText": "It is the finite set of all states (this describes $Q$)."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partC_opt2",
              "optionText": "It is the input alphabet (this describes $\\Sigma$)."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partC_opt3",
              "optionText": "It is the transition function (this describes $\\delta$)."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partC_opt4",
              "optionText": "It is the start state (this describes $q_0$)."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partC_opt5",
              "optionText": "It is the set of **accept (or final) states**."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partC_opt6",
              "optionText": "It must contain exactly one state."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partC_opt7",
              "optionText": "It is the set of states from which no transitions are possible."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partC_opt8",
              "optionText": "If the `FA` is in a state belonging to $F$ after processing an input string, the string is accepted."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partC_opt9",
              "optionText": "It cannot be an empty set if the language accepted by the `FA` is non-empty."
            },
            {
              "optionId": "ch_regex_fsm_8_q4_partC_opt10",
              "optionText": "It is always disjoint from the start state $q_0$."
            }
          ],
          "correctOptionIds": ["ch_regex_fsm_8_q4_partC_opt5"],
          "explanationText": "The component $F$ in the 5-tuple definition of a Finite Automaton (`FA`) ($M = (Q, \\Sigma, \\delta, q_0, F)$) represents **the set of accept (or final) states**. These are a subset of $Q$ (i.e., $F \\subseteq Q$). If, after processing an entire input string, the automaton is in one of these accept states (a state $s \\in F$), the string is considered to be part of the language recognized by the `FA`.",
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        }
      ],
      "totalQuestions": 14,
      "answeredQuestions": 0,
      "correctAnswers": 0,
      "isCompleted": false
    },
    {
      "id": "ch_cfg_9",
      "name": "Chapter 9: Context-Free Grammars and Languages",
      "description": "Introduces Context-Free Grammars (CFGs), their components, derivations, parse trees, ambiguity, and their role in defining languages more complex than regular ones.",
      "questions": [
        {
          "questionId": "ch_cfg_9_q1",
          "questionText": "What is a key component in the formal 4-tuple definition of a **Context-Free Grammar (CFG)**? (Select any one key component.)",
          "options": [
            {
              "optionId": "ch_cfg_9_q1_opt1",
              "optionText": "A set of **terminal symbols** ($\\Sigma$): the alphabet of the language being defined."
            },
            {
              "optionId": "ch_cfg_9_q1_opt2",
              "optionText": "A set of **non-terminal symbols** (or variables, $N$): syntactic categories used in derivations."
            },
            {
              "optionId": "ch_cfg_9_q1_opt3",
              "optionText": "A set of **production rules** ($P$): rules of the form $A \\rightarrow \\beta$, where $A$ is a non-terminal and $\\beta$ is a string of terminals and/or non-terminals."
            },
            {
              "optionId": "ch_cfg_9_q1_opt4",
              "optionText": "A designated **start symbol** ($S \\in N$): the non-terminal from which all derivations begin."
            },
            {
              "optionId": "ch_cfg_9_q1_opt5",
              "optionText": "A finite set of states, as in an FSM."
            },
            {
              "optionId": "ch_cfg_9_q1_opt6",
              "optionText": "A transition function mapping states and inputs."
            },
            {
              "optionId": "ch_cfg_9_q1_opt7",
              "optionText": "The 'context-free' part means that a non-terminal $A$ can be replaced by $\\beta$ regardless of the context (surrounding symbols) in which $A$ appears."
            },
            {
              "optionId": "ch_cfg_9_q1_opt8",
              "optionText": "Terminals are symbols that cannot be further broken down by production rules."
            },
            {
              "optionId": "ch_cfg_9_q1_opt9",
              "optionText": "Non-terminals must eventually be replaced by sequences of terminals to derive a string in the language."
            },
            {
              "optionId": "ch_cfg_9_q1_opt10",
              "optionText": "An explicit stack for parsing."
            }
          ],
          "correctOptionIds": [
            "ch_cfg_9_q1_opt1",
            "ch_cfg_9_q1_opt2",
            "ch_cfg_9_q1_opt3",
            "ch_cfg_9_q1_opt4"
          ],
          "explanationText": "A Context-Free Grammar (CFG) is formally a 4-tuple consisting of: a set of **terminal symbols** ($\\Sigma$), a set of **non-terminal symbols** ($N$), a set of **production rules** ($P$), and a designated **start symbol** ($S \\in N$). Selecting any one of these, for example, 'a set of non-terminal symbols', 'a set of production rules', or 'a designated start symbol', identifies a key component from this definition. The 'context-free' nature, as described in another option, is a property of how these rules are applied. Components like states or transition functions are part of Finite State Machines, not CFGs.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_cfg_9_q2",
          "questionText": "Consider the CFG: $S \\rightarrow aSb \\mid \\epsilon$. Which language does this grammar generate?",
          "options": [
            {
              "optionId": "ch_cfg_9_q2_opt1",
              "optionText": "The language $L = \\{a^n b^n \\mid n \\ge 0\\}$ (zero or more `a`'s followed by an equal number of `b`'s)."
            },
            {
              "optionId": "ch_cfg_9_q2_opt2",
              "optionText": "Strings generated include $\\epsilon, ab, aabb, aaabbb, \\dots$."
            },
            {
              "optionId": "ch_cfg_9_q2_opt3",
              "optionText": "This language is context-free but not regular."
            },
            {
              "optionId": "ch_cfg_9_q2_opt4",
              "optionText": "The language of all strings with an equal number of `a`'s and `b`'s (e.g., `aabb`, `abab`)."
            },
            {
              "optionId": "ch_cfg_9_q2_opt5",
              "optionText": "The language $(ab)^*$"
            },
            {
              "optionId": "ch_cfg_9_q2_opt6",
              "optionText": "The derivation for $aabb$ is $S \\Rightarrow aSb \\Rightarrow aaSbb \\Rightarrow aabb\\epsilon = aabb$."
            },
            {
              "optionId": "ch_cfg_9_q2_opt7",
              "optionText": "The rule $S \\rightarrow aSb$ adds an `a` at the beginning and a `b` at the end simultaneously."
            },
            {
              "optionId": "ch_cfg_9_q2_opt8",
              "optionText": "The rule $S \\rightarrow \\epsilon$ provides the base case to terminate the recursion."
            },
            {
              "optionId": "ch_cfg_9_q2_opt9",
              "optionText": "The language $a^_b^_$."
            },
            {
              "optionId": "ch_cfg_9_q2_opt10",
              "optionText": "Strings like `aab` or `ba` are not in this language."
            }
          ],
          "correctOptionIds": ["ch_cfg_9_q2_opt1"],
          "explanationText": "The grammar $S \\rightarrow aSb \\mid \\epsilon$ generates **the language $L = \\{a^n b^n \\mid n \\ge 0\\}$**. The rule $S \\rightarrow aSb$ recursively prepends an 'a' and appends a 'b' around a central $S$, ensuring that for every 'a' added at the front, a 'b' is added at the end. The rule $S \\rightarrow \\epsilon$ serves as the base case, allowing the derivation to terminate and producing an equal number of 'a's and 'b's (including $n=0$ for the empty string $\\epsilon$). Examples include $\\epsilon, ab, aabb$. This language is context-free but famously not regular.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_cfg_9_q3",
          "questionText": "What is a **parse tree** (or derivation tree) in the context of a Context-Free Grammar (CFG)?",
          "options": [
            {
              "optionId": "ch_cfg_9_q3_opt1",
              "optionText": "A graphical representation of how a string in the language can be derived from the start symbol using the production rules."
            },
            {
              "optionId": "ch_cfg_9_q3_opt2",
              "optionText": "The root of the tree is labeled with the start symbol."
            },
            {
              "optionId": "ch_cfg_9_q3_opt3",
              "optionText": "Internal nodes are labeled with non-terminal symbols."
            },
            {
              "optionId": "ch_cfg_9_q3_opt4",
              "optionText": "Leaf nodes are labeled with terminal symbols or $\\epsilon$."
            },
            {
              "optionId": "ch_cfg_9_q3_opt5",
              "optionText": "If an internal node is labeled $A$ and its children are $X_1, X_2, \\dots, X_k$ (from left to right), then $A \\rightarrow X_1 X_2 \\dots X_k$ must be a production rule."
            },
            {
              "optionId": "ch_cfg_9_q3_opt6",
              "optionText": "The sequence of leaf nodes, read from left to right (ignoring $\\epsilon$ leaves if they don't contribute to the string), forms the derived string."
            },
            {
              "optionId": "ch_cfg_9_q3_opt7",
              "optionText": "A data structure used by a compiler during the syntax analysis (parsing) phase."
            },
            {
              "optionId": "ch_cfg_9_q3_opt8",
              "optionText": "It is unique for every string if the grammar is unambiguous."
            },
            {
              "optionId": "ch_cfg_9_q3_opt9",
              "optionText": "It is always a binary tree."
            },
            {
              "optionId": "ch_cfg_9_q3_opt10",
              "optionText": "It directly represents the state transitions of a finite automaton."
            }
          ],
          "correctOptionIds": ["ch_cfg_9_q3_opt1"],
          "explanationText": "A parse tree (or derivation tree) is **a graphical representation of how a string in the language can be derived from the start symbol using the production rules of a Context-Free Grammar**. \nThe root of the tree is labeled with the start symbol. Internal nodes are labeled with non-terminals, and their children represent the right-hand side of a production rule applied to that non-terminal. \nLeaf nodes are labeled with terminal symbols or $\\epsilon$. The sequence of leaves, read from left to right, yields the derived string. Parse trees are crucial in syntax analysis (parsing) to understand the structure of a program or sentence according to the grammar.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null,
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": []
        },
        {
          "questionId": "ch_cfg_9_q4",
          "questionText": "What does it mean for a Context-Free Grammar to be **ambiguous**?",
          "options": [
            {
              "optionId": "ch_cfg_9_q4_opt1",
              "optionText": "There is at least one string in the language generated by the grammar that has **more than one distinct parse tree**."
            },
            {
              "optionId": "ch_cfg_9_q4_opt2",
              "optionText": "Equivalently, there is at least one string that has more than one leftmost derivation or more than one rightmost derivation."
            },
            {
              "optionId": "ch_cfg_9_q4_opt3",
              "optionText": "Ambiguity is generally undesirable for programming language grammars because it means a piece of code could be interpreted in multiple ways by a parser."
            },
            {
              "optionId": "ch_cfg_9_q4_opt4",
              "optionText": "The grammar contains production rules that are too complex."
            },
            {
              "optionId": "ch_cfg_9_q4_opt5",
              "optionText": "The grammar can generate an infinite number of strings."
            },
            {
              "optionId": "ch_cfg_9_q4_opt6",
              "optionText": "It is impossible to determine if a given string belongs to the language of an ambiguous grammar."
            },
            {
              "optionId": "ch_cfg_9_q4_opt7",
              "optionText": "An example is the 'dangling else' problem in some programming language constructs if not handled carefully in the grammar."
            },
            {
              "optionId": "ch_cfg_9_q4_opt8",
              "optionText": "Ambiguity can often be resolved by rewriting the grammar, for example, by introducing precedence levels for operators in expression grammars."
            },
            {
              "optionId": "ch_cfg_9_q4_opt9",
              "optionText": "All grammars that include recursive rules like $E \\rightarrow E + E$ are inherently ambiguous without further rules."
            },
            {
              "optionId": "ch_cfg_9_q4_opt10",
              "optionText": "A grammar is ambiguous if its start symbol can derive $\\epsilon$."
            }
          ],
          "correctOptionIds": ["ch_cfg_9_q4_opt1"],
          "explanationText": "A Context-Free Grammar is **ambiguous if there is at least one string in the language it generates that has more than one distinct parse tree**. Equivalently, an ambiguous grammar allows for more than one distinct leftmost derivation (or more than one distinct rightmost derivation) for at least one string. Ambiguity is problematic for programming language parsers because it means a single piece of code could have multiple valid structural interpretations, leading to undefined behavior unless the ambiguity is resolved (e.g., by rewriting the grammar or using disambiguation rules).",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_cfg_9_q5",
          "questionText": "Which of the following language types, often involving recursion or matching pairs across arbitrary distances, is typically definable by a Context-Free Grammar but **NOT** by Regular Expressions?",
          "options": [
            {
              "optionId": "ch_cfg_9_q5_opt1",
              "optionText": "Languages requiring matching pairs of symbols over arbitrary distances, like $L = \\{a^n b^n \\mid n \\ge 0\\}$."
            },
            {
              "optionId": "ch_cfg_9_q5_opt2",
              "optionText": "The language of all strings consisting of only 'a's (i.e., $a^*$)."
            },
            {
              "optionId": "ch_cfg_9_q5_opt3",
              "optionText": "The language of email addresses."
            },
            {
              "optionId": "ch_cfg_9_q5_opt4",
              "optionText": "The language of all strings ending in '01' over $\\Sigma = \\{0, 1\\}$."
            },
            {
              "optionId": "ch_cfg_9_q5_opt5",
              "optionText": "The language of identifiers in a programming language (e.g., starts with a letter, followed by letters or digits)."
            },
            {
              "optionId": "ch_cfg_9_q5_opt6",
              "optionText": "The language of simple numerical constants (e.g., sequences of digits)."
            },
            {
              "optionId": "ch_cfg_9_q5_opt7",
              "optionText": "Any finite language, such as $\\{'cat', 'dog', 'mouse'\\}$."
            },
            {
              "optionId": "ch_cfg_9_q5_opt8",
              "optionText": "The language $L = \\{a^n b^m c^k \\mid n,m,k \\ge 0\\}$ (any number of a's, then b's, then c's)."
            },
            {
              "optionId": "ch_cfg_9_q5_opt9",
              "optionText": "Languages that require checking if the number of $a$'s is equal to the number of $b$'s and equal to the number of $c$'s ($a^n b^n c^n$)."
            },
            {
              "optionId": "ch_cfg_9_q5_opt10",
              "optionText": "Languages recognized by Deterministic Finite Automata (DFAs)."
            }
          ],
          "correctOptionIds": ["ch_cfg_9_q5_opt1"],
          "explanationText": "Context-Free Grammars (CFGs) can define languages that Regular Expressions (REs) cannot, particularly those requiring unbounded counting or memory for matching nested structures. A prime example is **languages requiring matching pairs of symbols over arbitrary distances, like $L = \\{a^n b^n \\mid n \\ge 0\\}$**. This language needs to 'remember' the count of 'a's to match it with 'b's, which is beyond the capability of REs/FSMs. Other examples include balanced parentheses or the core syntax of most programming languages. The language $a^n b^n c^n$ (option `ch_cfg_9_q5_opt9`) is context-sensitive, not context-free. The other listed languages are typically regular.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_cfg_9_q6",
          "questionText": "What is the _common layered structure of non-terminals_ typically used in an arithmetic expression grammar to enforce operator precedence (e.g., multiplication before addition)?",
          "options": [
            {
              "optionId": "ch_cfg_9_q6_opt1",
              "optionText": "By using a single non-terminal `Expr` and relying on the parser to handle precedence."
            },
            {
              "optionId": "ch_cfg_9_q6_opt2",
              "optionText": "The effect of such layering is that operators with higher precedence (like `*`) are grouped more tightly during parsing because their associated non-terminals (e.g., `Factor`) are expanded first."
            },
            {
              "optionId": "ch_cfg_9_q6_opt3",
              "optionText": "Lower precedence operators (like `+`) are handled by rules that combine constructs representing higher precedence operations (e.g., an `Expression` combining `Term`s)."
            },
            {
              "optionId": "ch_cfg_9_q6_opt4",
              "optionText": "Left-associativity for operators like `+` and `*` is enforced by right-recursive rules like $E \\rightarrow T + E$."
            },
            {
              "optionId": "ch_cfg_9_q6_opt5",
              "optionText": "Parentheses $(E)$ are typically treated as a terminal symbol directly."
            },
            {
              "optionId": "ch_cfg_9_q6_opt6",
              "optionText": "By using a Finite State Machine to parse the expressions first."
            },
            {
              "optionId": "ch_cfg_9_q6_opt7",
              "optionText": "Simply adding more rules always makes the grammar unambiguous and enforces precedence."
            },
            {
              "optionId": "ch_cfg_9_q6_opt8",
              "optionText": "The rule $E \\rightarrow E + E \\mid E * E \\mid id$ inherently enforces correct precedence."
            },
            {
              "optionId": "ch_cfg_9_q6_opt9",
              "optionText": "The parser (e.g., an LR parser) automatically resolves precedence without specific grammar structuring for it."
            },
            {
              "optionId": "ch_cfg_9_q6_opt10",
              "optionText": "A common structure is: `Expression` (handles lowest precedence, e.g., +, -) $\\rightarrow$ `Term` (handles medium precedence, e.g., *, /) $\\rightarrow$ `Factor` (handles highest precedence, e.g., id, number, (`Expression`))."
            }
          ],
          "correctOptionIds": ["ch_cfg_9_q6_opt10"],
          "explanationText": "Operator precedence in expression grammars is typically enforced by structuring the grammar into layers of non-terminals. **A common such structure is: `Expression` (for lowest precedence, e.g., +, -) derives a `Term`; a `Term` (for medium precedence, e.g., _, /) derives a `Factor`; and a `Factor` (for highest precedence, e.g., identifiers, literals, or a parenthesized `Expression`) serves as the base.** This hierarchy ensures that operations defined by rules for 'deeper' non-terminals (like `Factor`) are effectively grouped before those for 'shallower' non-terminals (like `Expression`). Option `ch_cfg_9_q6_opt2` describes the _effect* of this layering correctly, but `ch_cfg_9_q6_opt10` describes the structure itself.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null,
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": []
        },
        {
          "questionId": "ch_cfg_9_q7",
          "questionText": "What is **Backus-Naur Form (BNF)** primarily used for in computer science?",
          "options": [
            {
              "optionId": "ch_cfg_9_q7_opt1",
              "optionText": "As a formal notation for describing the syntax of context-free languages, especially programming languages."
            },
            {
              "optionId": "ch_cfg_9_q7_opt2",
              "optionText": "It is a common way to write down production rules for Context-Free Grammars."
            },
            {
              "optionId": "ch_cfg_9_q7_opt3",
              "optionText": "BNF typically uses `::=` instead of `$\\rightarrow$` to separate the left-hand side (a non-terminal) from the right-hand side of a production."
            },
            {
              "optionId": "ch_cfg_9_q7_opt4",
              "optionText": "Alternatives on the right-hand side are often separated by a vertical bar `|`."
            },
            {
              "optionId": "ch_cfg_9_q7_opt5",
              "optionText": "Non-terminals are often enclosed in angle brackets (e.g., `<expression>`)."
            },
            {
              "optionId": "ch_cfg_9_q7_opt6",
              "optionText": "To describe regular expressions."
            },
            {
              "optionId": "ch_cfg_9_q7_opt7",
              "optionText": "To specify the semantics (meaning) of programming language constructs."
            },
            {
              "optionId": "ch_cfg_9_q7_opt8",
              "optionText": "As a programming language itself."
            },
            {
              "optionId": "ch_cfg_9_q7_opt9",
              "optionText": "To define the state transitions of a Finite State Machine."
            },
            {
              "optionId": "ch_cfg_9_q7_opt10",
              "optionText": "Extended BNF (EBNF) introduces additional notations for repetition (like `*` or `{...}`) and optionals (like `[...]`)."
            }
          ],
          "correctOptionIds": ["ch_cfg_9_q7_opt1"],
          "explanationText": "**Backus-Naur Form (BNF) is primarily used as a formal notation (a metasyntax) for describing the syntax of context-free languages, particularly for specifying the grammar of programming languages**. It provides a standardized way to write down the production rules of a Context-Free Grammar. Common BNF conventions include using `::=` for production rules (instead of an arrow), `|` to separate alternatives for a non-terminal, and often enclosing non-terminals in angle brackets (e.g., `<statement>`). BNF describes syntax, not semantics (meaning). Extended BNF (EBNF) adds further conciseness.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_cfg_9_q8",
          "questionText": "In a Context-Free Grammar (CFG), a **derivation** is a sequence of steps transforming the start symbol into a string of terminals. Which of the following statements _best defines a single step_ in any valid derivation?",
          "options": [
            {
              "optionId": "ch_cfg_9_q8_opt1",
              "optionText": "In each step, a non-terminal in the current sentential form is replaced by one of the right-hand sides of a production rule for that non-terminal."
            },
            {
              "optionId": "ch_cfg_9_q8_opt2",
              "optionText": "A **leftmost derivation** is one where, at each step, the leftmost non-terminal in the sentential form is chosen for replacement."
            },
            {
              "optionId": "ch_cfg_9_q8_opt3",
              "optionText": "A **rightmost derivation** is one where, at each step, the rightmost non-terminal is chosen for replacement."
            },
            {
              "optionId": "ch_cfg_9_q8_opt4",
              "optionText": "A derivation is complete when the sentential form consists only of terminal symbols."
            },
            {
              "optionId": "ch_cfg_9_q8_opt5",
              "optionText": "An unambiguous grammar has exactly one leftmost and one rightmost derivation for every string in its language."
            },
            {
              "optionId": "ch_cfg_9_q8_opt6",
              "optionText": "A derivation must always replace terminals with non-terminals."
            },
            {
              "optionId": "ch_cfg_9_q8_opt7",
              "optionText": "The number of steps in a derivation is always equal to the length of the derived string."
            },
            {
              "optionId": "ch_cfg_9_q8_opt8",
              "optionText": "A single derivation step can replace multiple non-terminals simultaneously."
            },
            {
              "optionId": "ch_cfg_9_q8_opt9",
              "optionText": "The sentential forms in a derivation can contain a mix of terminals and non-terminals."
            },
            {
              "optionId": "ch_cfg_9_q8_opt10",
              "optionText": "Different derivations (e.g., choosing different non-terminals to expand when multiple exist) can still lead to the same parse tree if the order of applying independent rules is just permuted."
            }
          ],
          "correctOptionIds": ["ch_cfg_9_q8_opt1"],
          "explanationText": "A single step in any valid derivation within a CFG involves: **in the current sentential form (a string of terminals and/or non-terminals), a non-terminal is chosen and replaced by one of the right-hand sides of a production rule defined for that non-terminal**. A derivation starts with the start symbol and is complete when the sentential form consists only of terminal symbols. Specific strategies like leftmost derivation (always replacing the leftmost non-terminal) or rightmost derivation (always replacing the rightmost) are used to standardize the process and relate derivations to parse trees.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_cfg_9_q9",
          "questionText": "Consider the grammar $S \\rightarrow SS \\mid a$. What is the _primary characteristic_ of this grammar regarding its ability to generate strings?",
          "options": [
            {
              "optionId": "ch_cfg_9_q9_opt1",
              "optionText": "The string `a` can be generated: $S \\Rightarrow a$."
            },
            {
              "optionId": "ch_cfg_9_q9_opt2",
              "optionText": "The string `aa` can be generated: $S \\Rightarrow SS \\Rightarrow aS \\Rightarrow aa$."
            },
            {
              "optionId": "ch_cfg_9_q9_opt3",
              "optionText": "The string `aaa` can be generated."
            },
            {
              "optionId": "ch_cfg_9_q9_opt4",
              "optionText": "This grammar generates the language $L = \\{a^n \\mid n \\ge 1\\}$ (one or more `a`'s)."
            },
            {
              "optionId": "ch_cfg_9_q9_opt5",
              "optionText": "The grammar is **ambiguous** because a string like `aaa` has multiple parse trees."
            },
            {
              "optionId": "ch_cfg_9_q9_opt6",
              "optionText": "For `aaa`: Tree 1 via $S \\Rightarrow SS \\Rightarrow aS \\Rightarrow aSS \\Rightarrow aaS \\Rightarrow aaa$ (expanding first S then its first S)."
            },
            {
              "optionId": "ch_cfg_9_q9_opt7",
              "optionText": "For `aaa`: Tree 2 via $S \\Rightarrow SS \\Rightarrow SSS \\Rightarrow aSS \\Rightarrow aaS \\Rightarrow aaa$ (expanding S into SS first)."
            },
            {
              "optionId": "ch_cfg_9_q9_opt8",
              "optionText": "The grammar is unambiguous because each rule is simple."
            },
            {
              "optionId": "ch_cfg_9_q9_opt9",
              "optionText": "The empty string $\\epsilon$ cannot be generated."
            },
            {
              "optionId": "ch_cfg_9_q9_opt10",
              "optionText": "This grammar is equivalent to $S \\rightarrow aS \\mid a$."
            }
          ],
          "correctOptionIds": ["ch_cfg_9_q9_opt5"],
          "explanationText": "The grammar $S \\rightarrow SS \\mid a$ generates the language of one or more 'a's (i.e., $a^+$). For example, $S \\Rightarrow a$; $S \\Rightarrow  SS \n \\Rightarrow aS \\Rightarrow aa$; $ S \\Rightarrow SS \\Rightarrow SSS \\Rightarrow aSS \\Rightarrow aaS \\Rightarrow aaa$. A primary characteristic of this specific grammar is that **it is ambiguous**. For example, the string 'aaa' can be derived in multiple ways leading to different parse trees: one corresponding to $(S S) S \\Rightarrow (a S) S \\Rightarrow (a a) S \\Rightarrow aaa$ and another corresponding to $S (S S) \\Rightarrow S (a S) \\Rightarrow S (a a) \\Rightarrow aaa$. These group the 'a's differently, showing ambiguity. An unambiguous grammar for $a^+$ would be $S \\rightarrow aS \\mid a$.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null,
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": []
        },
        {
          "questionId": "ch_cfg_9_q10",
          "questionText": "How does the expressive power of Context-Free Grammars (CFGs) compare to that of Regular Expressions (REs) in defining languages?",
          "options": [
            {
              "optionId": "ch_cfg_9_q10_opt1",
              "optionText": "CFGs are **strictly more expressive** than REs; the set of regular languages is a proper subset of the set of context-free languages."
            },
            {
              "optionId": "ch_cfg_9_q10_opt2",
              "optionText": "Every regular language can be described by a CFG."
            },
            {
              "optionId": "ch_cfg_9_q10_opt3",
              "optionText": "There exist context-free languages (e.g., $a^n b^n$) that are not regular."
            },
            {
              "optionId": "ch_cfg_9_q10_opt4",
              "optionText": "REs are strictly more expressive than CFGs."
            },
            {
              "optionId": "ch_cfg_9_q10_opt5",
              "optionText": "CFGs and REs have equivalent expressive power."
            },
            {
              "optionId": "ch_cfg_9_q10_opt6",
              "optionText": "CFGs can handle nested structures which REs typically cannot."
            },
            {
              "optionId": "ch_cfg_9_q10_opt7",
              "optionText": "The machine model for REs is a Finite Automaton; for CFGs, it's a Pushdown Automaton."
            },
            {
              "optionId": "ch_cfg_9_q10_opt8",
              "optionText": "CFGs are used to define the syntax of tokens (like identifiers), while REs define the overall program structure."
            },
            {
              "optionId": "ch_cfg_9_q10_opt9",
              "optionText": "Right-linear or left-linear CFGs generate exactly the regular languages."
            },
            {
              "optionId": "ch_cfg_9_q10_opt10",
              "optionText": "The Chomsky Hierarchy places regular languages at Type 3 and context-free languages at Type 2."
            }
          ],
          "correctOptionIds": ["ch_cfg_9_q10_opt1"],
          "explanationText": "**Context-Free Grammars (CFGs) are strictly more expressive than Regular Expressions (REs)**. This means that the set of languages that can be described by REs (the regular languages) is a proper subset of the languages that can be described by CFGs (the context-free languages). While every regular language can be defined by a CFG (specifically, by a right-linear or left-linear grammar), there are context-free languages, such as $L = \\{a^n b^n \\mid n \\ge 0\\}$ or languages with balanced parentheses, that cannot be defined by any RE. CFGs can handle recursive, nested structures that REs cannot. The Chomsky Hierarchy formalizes this, placing regular languages at Type 3 and context-free languages at Type 2.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "questionId": "ch_cfg_9_q11",
          "questionText": "What is the _most fundamental role_ of an $\\epsilon$ (empty string) production, such as $A \\rightarrow \\epsilon$, in a Context-Free Grammar?",
          "options": [
            {
              "optionId": "ch_cfg_9_q11_opt1",
              "optionText": "It allows a non-terminal $A$ to be erased or to derive the empty string."
            },
            {
              "optionId": "ch_cfg_9_q11_opt2",
              "optionText": "It is essential for defining optional parts of a language structure (e.g., an optional else clause)."
            },
            {
              "optionId": "ch_cfg_9_q11_opt3",
              "optionText": "It serves as a base case in recursive productions to terminate a derivation."
            },
            {
              "optionId": "ch_cfg_9_q11_opt4",
              "optionText": "For example, in $S \\rightarrow aS \\mid \\epsilon$, the $\\epsilon$-production allows generation of $a^*$ (zero or more $a$'s)."
            },
            {
              "optionId": "ch_cfg_9_q11_opt5",
              "optionText": "It always makes a grammar ambiguous."
            },
            {
              "optionId": "ch_cfg_9_q11_opt6",
              "optionText": "It means the non-terminal $A$ must produce at least one symbol."
            },
            {
              "optionId": "ch_cfg_9_q11_opt7",
              "optionText": "It is equivalent to a production $A \\rightarrow \text{''}$ (empty quotes)."
            },
            {
              "optionId": "ch_cfg_9_q11_opt8",
              "optionText": "Grammars without $\\epsilon$-productions can only generate languages that do not contain the empty string (unless the start symbol itself is $\\epsilon$ and has no other productions, which is trivial)."
            },
            {
              "optionId": "ch_cfg_9_q11_opt9",
              "optionText": "It can sometimes be eliminated from a grammar (except if $\\epsilon$ is in the language) without changing the language generated (apart from $\\epsilon$ itself)."
            },
            {
              "optionId": "ch_cfg_9_q11_opt10",
              "optionText": "It represents an error state in the grammar."
            }
          ],
          "correctOptionIds": ["ch_cfg_9_q11_opt1"],
          "explanationText": "The most fundamental role of an $\\epsilon$-production ($A \\rightarrow \\epsilon$) in a CFG is that **it allows a non-terminal $A$ to be erased from a sentential form, or equivalently, to derive the empty string $\\epsilon$**. This capability is crucial for several reasons: it can serve as a base case to terminate recursive derivations (e.g., in $S \\rightarrow aS \\mid \\epsilon$ to generate $a$), and it allows for the definition of optional syntactic constructs (e.g., an optional 'else' part in an if-statement can be modeled by a non-terminal that can derive 'else block' or $\\epsilon$). While $\\epsilon$-productions can sometimes contribute to ambiguity, they are a standard and essential feature of CFGs.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null,
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": []
        },
        {
          "questionId": "ch_cfg_9_q12",
          "questionText": "In compiler design, the syntax of tokens (like identifiers or numbers) is typically described by regular expressions, while the overall program structure (statements, expressions) is described by a CFG. What is the _primary reason_ for this common division of tasks?",
          "options": [
            {
              "optionId": "ch_cfg_9_q12_opt1",
              "optionText": "Regular expressions are sufficient for the simpler, non-nested structure of individual tokens."
            },
            {
              "optionId": "ch_cfg_9_q12_opt2",
              "optionText": "CFGs are needed to handle the potentially recursive and nested structures of program constructs like expressions with parentheses, or nested blocks."
            },
            {
              "optionId": "ch_cfg_9_q12_opt3",
              "optionText": "This separation forms the basis of a typical compiler's two-phase approach: lexical analysis (scanning for tokens using RE/FSM principles) followed by syntax analysis (parsing the token stream using CFG/PDA principles)."
            },
            {
              "optionId": "ch_cfg_9_q12_opt4",
              "optionText": "It's more efficient to use FSMs (derived from REs) for token recognition than to use full CFG parsing for every character sequence."
            },
            {
              "optionId": "ch_cfg_9_q12_opt5",
              "optionText": "CFGs are too powerful and complex for simple token structures."
            },
            {
              "optionId": "ch_cfg_9_q12_opt6",
              "optionText": "Regular expressions cannot handle any form of recursion."
            },
            {
              "optionId": "ch_cfg_9_q12_opt7",
              "optionText": "The terminals in the CFG for program structure are often the token types identified by the lexical analyzer (e.g., `IDENTIFIER`, `NUMBER`, `PLUS_OP`)."
            },
            {
              "optionId": "ch_cfg_9_q12_opt8",
              "optionText": "This division simplifies the design of both the lexical analyzer and the parser."
            },
            {
              "optionId": "ch_cfg_9_q12_opt9",
              "optionText": "Regular expressions are actually a subset of CFGs in terms of descriptive power."
            },
            {
              "optionId": "ch_cfg_9_q12_opt10",
              "optionText": "CFGs are only used for natural language processing, not programming languages."
            }
          ],
          "correctOptionIds": ["ch_cfg_9_q12_opt3"],
          "explanationText": "The primary reason for this division is that **this separation forms the basis of a typical compiler's two-phase approach: lexical analysis (scanning for tokens using RE/FSM principles) followed by syntax analysis (parsing the token stream using CFG/PDA principles)**. Regular expressions are well-suited for the simpler, non-recursive patterns of individual tokens (like identifiers or numbers), and FSMs (derived from REs) can recognize these tokens efficiently. Context-Free Grammars are then used to define the more complex, potentially recursive and nested grammatical structure of the program (like expressions, statements, blocks) from the sequence of tokens provided by the lexical analyzer. This division simplifies the overall compiler design and makes each phase more manageable and efficient.",
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "questionId": "ch_cfg_9_q1_partA",
          "questionText": "In the 4-tuple formal definition of a Context-Free Grammar (CFG) $(N, \\Sigma, P, S)$, what does the component $N$ (sometimes $V$) represent?",
          "options": [
            {
              "optionId": "ch_cfg_9_q1_partA_opt1",
              "optionText": "A set of **terminal symbols**."
            },
            {
              "optionId": "ch_cfg_9_q1_partA_opt2",
              "optionText": "A set of **non-terminal symbols** (or variables)."
            },
            {
              "optionId": "ch_cfg_9_q1_partA_opt3",
              "optionText": "A set of **production rules**."
            },
            {
              "optionId": "ch_cfg_9_q1_partA_opt4",
              "optionText": "A designated **start symbol**."
            },
            {
              "optionId": "ch_cfg_9_q1_partA_opt5",
              "optionText": "The language generated by the CFG."
            },
            {
              "optionId": "ch_cfg_9_q1_partA_opt6",
              "optionText": "The alphabet of the generated language."
            },
            {
              "optionId": "ch_cfg_9_q1_partA_opt7",
              "optionText": "A parse tree for a string."
            },
            {
              "optionId": "ch_cfg_9_q1_partA_opt8",
              "optionText": "A derivation sequence."
            },
            {
              "optionId": "ch_cfg_9_q1_partA_opt9",
              "optionText": "A finite set of states."
            },
            {
              "optionId": "ch_cfg_9_q1_partA_opt10",
              "optionText": "The empty string $\\epsilon$."
            }
          ],
          "correctOptionIds": ["ch_cfg_9_q1_partA_opt2"],
          "explanationText": "In the formal definition of a Context-Free Grammar $(N, \\Sigma, P, S)$, the component $N$ (also often denoted $V$) represents **a finite set of non-terminal symbols** (or variables). These are syntactic categories that are used in derivations and must eventually be replaced by sequences of terminals according to the production rules.",
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "questionId": "ch_cfg_9_q1_partB",
          "questionText": "What is the role of production rules ($P$) in a Context-Free Grammar (CFG) defined as $(N, \\Sigma, P, S)$?",
          "options": [
            {
              "optionId": "ch_cfg_9_q1_partB_opt1",
              "optionText": "They define the set of terminal symbols."
            },
            {
              "optionId": "ch_cfg_9_q1_partB_opt2",
              "optionText": "They define the set of non-terminal symbols."
            },
            {
              "optionId": "ch_cfg_9_q1_partB_opt3",
              "optionText": "They specify how non-terminals can be replaced by strings of terminals and/or non-terminals."
            },
            {
              "optionId": "ch_cfg_9_q1_partB_opt4",
              "optionText": "They designate the start symbol of the grammar."
            },
            {
              "optionId": "ch_cfg_9_q1_partB_opt5",
              "optionText": "They are always of the form $A \\rightarrow a$, where $A$ is non-terminal and $a$ is terminal."
            },
            {
              "optionId": "ch_cfg_9_q1_partB_opt6",
              "optionText": "They ensure the grammar is unambiguous."
            },
            {
              "optionId": "ch_cfg_9_q1_partB_opt7",
              "optionText": "They are only used to derive the empty string."
            },
            {
              "optionId": "ch_cfg_9_q1_partB_opt8",
              "optionText": "They define the order of operations in expressions."
            },
            {
              "optionId": "ch_cfg_9_q1_partB_opt9",
              "optionText": "Each rule must have exactly one non-terminal on its right-hand side."
            },
            {
              "optionId": "ch_cfg_9_q1_partB_opt10",
              "optionText": "They are similar to state transitions in a Finite Automaton."
            }
          ],
          "correctOptionIds": ["ch_cfg_9_q1_partB_opt3"],
          "explanationText": "Production rules ($P$) in a Context-Free Grammar **specify how non-terminal symbols can be replaced by strings consisting of terminals and/or other non-terminals**. Each rule is typically of the form $A \\rightarrow \\beta$, where $A$ is a single non-terminal symbol, and $\\beta$ is a sequence of zero or more terminals and non-terminals. These rules are applied iteratively to derive strings in the language generated by the grammar.",
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        },
        {
          "status": "not_attempted",
          "timesAnsweredCorrectly": 0,
          "timesAnsweredIncorrectly": 0,
          "historyOfIncorrectSelections": [],
          "srsLevel": 0,
          "nextReviewAt": null,
          "shownIncorrectOptionIds": [],
          "questionId": "ch_cfg_9_q1_partC",
          "questionText": "In a Context-Free Grammar (CFG) formally defined as $(N, \\Sigma, P, S)$, what is the purpose of the start symbol $S$?",
          "options": [
            {
              "optionId": "ch_cfg_9_q1_partC_opt1",
              "optionText": "It is the set of all terminal symbols in the grammar."
            },
            {
              "optionId": "ch_cfg_9_q1_partC_opt2",
              "optionText": "It is a special non-terminal symbol from which all derivations of strings in the language begin."
            },
            {
              "optionId": "ch_cfg_9_q1_partC_opt3",
              "optionText": "It represents the set of all production rules."
            },
            {
              "optionId": "ch_cfg_9_q1_partC_opt4",
              "optionText": "It is always the first symbol on the right-hand side of any production rule."
            },
            {
              "optionId": "ch_cfg_9_q1_partC_opt5",
              "optionText": "It must be a terminal symbol."
            },
            {
              "optionId": "ch_cfg_9_q1_partC_opt6",
              "optionText": "It indicates the end of a derivation."
            },
            {
              "optionId": "ch_cfg_9_q1_partC_opt7",
              "optionText": "It is used to define operator precedence."
            },
            {
              "optionId": "ch_cfg_9_q1_partC_opt8",
              "optionText": "A grammar can have multiple start symbols."
            },
            {
              "optionId": "ch_cfg_9_q1_partC_opt9",
              "optionText": "The start symbol must derive the empty string $\\epsilon$."
            },
            {
              "optionId": "ch_cfg_9_q1_partC_opt10",
              "optionText": "It is equivalent to the initial state of a Finite Automaton."
            }
          ],
          "correctOptionIds": ["ch_cfg_9_q1_partC_opt2"],
          "explanationText": "The start symbol $S$ in a Context-Free Grammar $(N, \\Sigma, P, S)$ is **a special non-terminal symbol (i.e., $S \\in N$) from which all derivations of strings belonging to the language must begin**. It is the root of any parse tree for a string in the language.",
          "lastSelectedOptionId": null,
          "lastAttemptedAt": null
        }
      ],
      "totalQuestions": 15,
      "answeredQuestions": 0,
      "correctAnswers": 0,
      "isCompleted": false
    }
  ]
}
